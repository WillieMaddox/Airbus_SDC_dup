{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "from collections import Counter\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage.util import montage\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from sdcdup.utils import overlap_tag_pairs\n",
    "from sdcdup.utils import overlap_tag_maps\n",
    "from sdcdup.utils import generate_overlap_tag_slices\n",
    "from sdcdup.utils import generate_tag_pair_lookup\n",
    "from sdcdup.utils import channel_shift\n",
    "from sdcdup.utils import load_duplicate_truth\n",
    "from sdcdup.utils import update_duplicate_truth\n",
    "from sdcdup.utils import update_tile_cliques\n",
    "\n",
    "from sdcdup.features.image_features import SDCImageContainer\n",
    "from sdcdup.features.image_features import load_image_overlap_properties\n",
    "from sdcdup.models.dupnet import load_checkpoint\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "EPS = np.finfo(np.float32).eps\n",
    "\n",
    "RED = (244, 67, 54) #F44336 \n",
    "GREEN = (76, 175, 80) #4CAF50 \n",
    "LIGHT_BLUE = (3, 169, 244) #03A9F4\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title\n",
    "\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "montage_pad = lambda x, *args, **kwargs: montage(x, padding_width=10, *args, **kwargs)\n",
    "zeros_mask = np.zeros((256*3, 256*3, 1), dtype=np.float32)\n",
    "\n",
    "train_image_dir = 'data/raw/train_768/'\n",
    "image_md5hash_grids_file = 'data/interim/image_md5hash_grids.pkl'\n",
    "image_bm0hash_grids_file = 'data/interim/image_bm0hash_grids.pkl'\n",
    "image_cm0hash_grids_file = 'data/interim/image_cm0hash_grids.pkl'\n",
    "image_greycop_grids_file = 'data/interim/image_greycop_grids.pkl'\n",
    "image_entropy_grids_file = 'data/interim/image_entropy_grids.pkl'\n",
    "image_issolid_grids_file = 'data/interim/image_issolid_grids.pkl'\n",
    "image_shipcnt_grids_file = 'data/interim/image_shipcnt_grids.pkl'\n",
    "\n",
    "overlap_tag_slices = generate_overlap_tag_slices()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgMod:\n",
    "    \"\"\"\n",
    "    Reads a single image to be modified by hls.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.img_id = filename.split('/')[-1]\n",
    "\n",
    "        self._hls_chan = None\n",
    "        self._hls_gain = None\n",
    "\n",
    "        self._parent_bgr = None\n",
    "        self._parent_hls = None\n",
    "        self._parent_rgb = None\n",
    "        self._cv2_hls = None\n",
    "        self._cv2_bgr = None\n",
    "        self._cv2_rgb = None\n",
    "\n",
    "    def brightness_shift(self, chan, gain):\n",
    "        self._hls_chan = chan\n",
    "        self._hls_gain = gain\n",
    "        self._cv2_hls = None\n",
    "        return self.cv2_rgb\n",
    "    \n",
    "    def scale(self, minval, maxval):\n",
    "        m = 255.0 * (maxval - minval)\n",
    "        res = m * (self.parent_bgr - minval)\n",
    "        return np.around(res).astype(np.uint8)\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.parent_bgr.shape\n",
    "    \n",
    "    @property\n",
    "    def parent_bgr(self):\n",
    "        if self._parent_bgr is None:\n",
    "            self._parent_bgr = cv2.imread(self.filename)\n",
    "        return self._parent_bgr\n",
    "\n",
    "    @property\n",
    "    def parent_hls(self):\n",
    "        if self._parent_hls is None:\n",
    "            self._parent_hls = self.to_hls(self.parent_bgr)\n",
    "        return self._parent_hls\n",
    "\n",
    "    @property\n",
    "    def parent_rgb(self):\n",
    "        if self._parent_rgb is None:\n",
    "            self._parent_rgb = self.to_rgb(self.parent_bgr)\n",
    "        return self._parent_rgb\n",
    "\n",
    "    @property\n",
    "    def cv2_hls(self):\n",
    "        if self._cv2_hls is None:\n",
    "            if self._hls_gain is None:\n",
    "                self._cv2_hls = self.parent_hls\n",
    "            else:\n",
    "                self._cv2_hls = channel_shift(self.parent_hls, self._hls_chan, self._hls_gain)\n",
    "        return self._cv2_hls\n",
    "\n",
    "    @property\n",
    "    def cv2_bgr(self):\n",
    "        if self._cv2_bgr is None:\n",
    "            self._cv2_bgr = self.to_bgr(self.cv2_hls)\n",
    "        return self._cv2_bgr\n",
    "\n",
    "    @property\n",
    "    def cv2_rgb(self):\n",
    "        if self._cv2_rgb is None:\n",
    "            self._cv2_rgb = self.to_rgb(self.cv2_bgr)\n",
    "        return self._cv2_rgb\n",
    "\n",
    "    def to_hls(self, bgr):\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2HLS_FULL)\n",
    "\n",
    "    def to_bgr(self, hls):\n",
    "        return cv2.cvtColor(hls, cv2.COLOR_HLS2BGR_FULL)\n",
    "\n",
    "    def to_rgb(self, bgr):\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdcic = SDCImageContainer()\n",
    "sdcic.preprocess_image_properties(\n",
    "    image_md5hash_grids_file,\n",
    "    image_bm0hash_grids_file,\n",
    "    image_cm0hash_grids_file,\n",
    "    image_greycop_grids_file,\n",
    "    image_entropy_grids_file,\n",
    "    image_issolid_grids_file)\n",
    "sdcic.preprocess_label_properties(\n",
    "    image_shipcnt_grids_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth = load_duplicate_truth()\n",
    "print(len(dup_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_types = ['bmh', 'cmh', 'con', 'hom', 'eng', 'cor', 'epy', 'enp', 'pix', 'px0', 'shp']\n",
    "n_matching_tiles_list = [9, 6, 4, 3, 2, 1]\n",
    "overlap_image_maps = load_image_overlap_properties(n_matching_tiles_list)\n",
    "print(len(overlap_image_maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "img_overlap_index_maps = generate_tag_pair_lookup()\n",
    "TilePairs = namedtuple('TilePairs', 'img1_id img2_id img1_overlap_tag overlap_idx idx1 idx2')\n",
    "\n",
    "def get_img(img_id):\n",
    "    return cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    \n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, tile_pairs, \n",
    "                 image_transform=None,\n",
    "                 in_shape=(6, 256, 256), \n",
    "                 out_shape=(1,)):\n",
    "\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.sz = 256\n",
    "        self.tile_pairs = tile_pairs\n",
    "        self.image_transform = image_transform\n",
    "        self.ij = ((0, 0), (0, 1), (0, 2),\n",
    "                   (1, 0), (1, 1), (1, 2),\n",
    "                   (2, 0), (2, 1), (2, 2))\n",
    "        \n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return len(self.tile_pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one sample of data\"\"\"\n",
    "        tp = self.tile_pairs[index]\n",
    "        \n",
    "        img1 = get_img(tp.img1_id)\n",
    "        img2 = get_img(tp.img2_id)\n",
    "        \n",
    "        tile1 = cv2.cvtColor(self.get_tile(img1, *self.ij[tp.idx1]), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        tile2 = cv2.cvtColor(self.get_tile(img2, *self.ij[tp.idx2]), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        \n",
    "        X = np.dstack([tile1, tile2])\n",
    "        X = X.transpose((2, 0, 1))\n",
    "        X = torch.from_numpy(X)\n",
    "        return X\n",
    "    \n",
    "    def get_tile(self, img, i, j):\n",
    "        return img[i * self.sz:(i + 1) * self.sz, j * self.sz:(j + 1) * self.sz, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return x.view(-1, 6, 256, 256).to(device)\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_pairs = []\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    for img1_overlap_tag in overlap_maps:\n",
    "#         if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "#             continue\n",
    "        for overlap_idx, (idx1, idx2) in enumerate(img_overlap_index_maps[img1_overlap_tag]):\n",
    "            tile_pairs.append(TilePairs(img1_id, img2_id, img1_overlap_tag, overlap_idx, idx1, idx2))\n",
    "print(len(tile_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(tile_pairs)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=256, num_workers=20)\n",
    "test_dl = WrappedDataLoader(test_dl, preprocess)\n",
    "print(len(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint('models/dup_model.best.pth')\n",
    "model.cuda()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yprobs0 = [model(xb) for xb in tqdm_notebook(test_dl)]\n",
    "    yprobs = np.vstack([l.cpu() for l in yprobs0]).reshape(-1)\n",
    "    print(len(yprobs0), yprobs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprobs_c = np.where(np.abs(yprobs - 0.5) < 0.472)[0]\n",
    "print(yprobs_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_weak_pred = False\n",
    "weak_preds = []\n",
    "overlap_cnn_tile_scores = {}\n",
    "for ii, (tp, yprob) in enumerate(zip(tile_pairs, yprobs)):\n",
    "    if ii in yprobs_c:\n",
    "        is_weak_pred = True\n",
    "    if (tp.img1_id, tp.img2_id) not in overlap_cnn_tile_scores:\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)] = {}\n",
    "    if tp.img1_overlap_tag not in overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)]:\n",
    "        n_overlapping_tiles = len(img_overlap_index_maps[tp.img1_overlap_tag])\n",
    "        cnn_scores = [None] * n_overlapping_tiles\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag] = cnn_scores\n",
    "    overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag][tp.overlap_idx] = yprob\n",
    "    if tp.overlap_idx == n_overlapping_tiles - 1 and is_weak_pred:\n",
    "        weak_preds.append((tp.img1_id, tp.img2_id, tp.img1_overlap_tag))\n",
    "        is_weak_pred = False\n",
    "\n",
    "len(weak_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlaps with ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untested_image_pairs_with_ship_masks = []\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    # TODO: Find out which remaining tile pairs have masks but aren't in dup_truth.\n",
    "\n",
    "    mask1 = sdcic.tile_shipcnt_grids[img1_id]\n",
    "    mask2 = sdcic.tile_shipcnt_grids[img2_id]\n",
    "    \n",
    "    has_mask1 = np.sum(mask1) > 0\n",
    "    has_mask2 = np.sum(mask2) > 0\n",
    "\n",
    "    if not (has_mask1 and has_mask2):\n",
    "        continue\n",
    "\n",
    "    for img1_overlap_tag in overlap_maps:\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "        untested_image_pairs_with_ship_masks.append((img1_id, img2_id))\n",
    "        break\n",
    "\n",
    "len(overlap_image_maps), len(untested_image_pairs_with_ship_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untested_overlaps_with_ship_masks = []\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    # TODO: Find out which remaining tile pairs have masks but aren't in dup_truth.\n",
    "\n",
    "    mask1 = sdcic.tile_shipcnt_grids[img1_id]\n",
    "    mask2 = sdcic.tile_shipcnt_grids[img2_id]\n",
    "    \n",
    "    has_mask1 = np.sum(mask1) > 0\n",
    "    has_mask2 = np.sum(mask2) > 0\n",
    "\n",
    "    if not (has_mask1 and has_mask2):\n",
    "        continue\n",
    "\n",
    "    for img1_overlap_tag in overlap_maps:\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "\n",
    "        mask1_slice_total = np.sum(mask1[overlap_tag_maps[img1_overlap_tag]])\n",
    "        mask2_slice_total = np.sum(mask2[overlap_tag_maps[overlap_tag_pairs[img1_overlap_tag]]])\n",
    "\n",
    "        if mask1_slice_total + mask2_slice_total < 1:\n",
    "            continue\n",
    "\n",
    "        untested_overlaps_with_ship_masks.append((img1_id, img2_id, img1_overlap_tag))\n",
    "\n",
    "len(overlap_image_maps), len(untested_overlaps_with_ship_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlapping images using hashlib\n",
    "Update: The values between two supposedly exact 256x256 crops are not exact (See below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md5hash_dict = defaultdict(list)\n",
    "img_ids = os.listdir(train_image_dir)\n",
    "\n",
    "for img_id in tqdm_notebook(img_ids):\n",
    "    for h in sdcic.tile_md5hash_grids[img_id]:\n",
    "        md5hash_dict[h].append(img_id)\n",
    "\n",
    "dup_counts_dict = defaultdict(int)\n",
    "for key, dups in md5hash_dict.items():\n",
    "    dup_counts_dict[len(dups)] += 1\n",
    "\n",
    "sorted_bin_sizes = sorted(dup_counts_dict.items())\n",
    "print('n images with k duplicates')\n",
    "print('(k, n)')\n",
    "sorted_bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 9\n",
    "skip = 365\n",
    "ii = 0\n",
    "jj = 0\n",
    "batch_limit = 9\n",
    "samples_images = np.empty((batch_limit, 768, 768, 3), dtype=np.float32)\n",
    "\n",
    "for hash_id, dups in md5hash_dict.items():\n",
    "    ii += 1\n",
    "    if len(dups) == batch_size:\n",
    "        dups0 = list(set(dups))\n",
    "        img_id = dups0[0]\n",
    "        idx = sdcic.tile_md5hash_grids[img_id].tolist().index(hash_id)\n",
    "        print(hash_id, len(dups), ii, sdcic.tile_entropy_grids[img_id][idx])\n",
    "        if jj == min(dup_counts_dict[len(dups)], skip):\n",
    "            break\n",
    "        jj += 1\n",
    "\n",
    "for i, c_img_id in enumerate(dups0[:batch_limit]):\n",
    "    c_img = cv2.cvtColor(sdcic.get_img(c_img_id), cv2.COLOR_BGR2RGB)\n",
    "    samples_images[i] = c_img.astype(np.float32) / 255.0\n",
    "\n",
    "batch_rgb = montage_rgb(samples_images)\n",
    "print(samples_images.shape)\n",
    "print(batch_rgb.shape, batch_rgb.dtype)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16, 16))\n",
    "ax.imshow(batch_rgb, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlapping images using cv2.img_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm0hash_dict = defaultdict(list)\n",
    "img_ids = os.listdir(train_image_dir)\n",
    "\n",
    "for img_id in tqdm_notebook(img_ids):\n",
    "    for h in sdcic.tile_bm0hash_grids[img_id]:\n",
    "        bm0hash_dict[tuple(h)].append(img_id)  # hex\n",
    "\n",
    "dup_counts_dict = defaultdict(int)\n",
    "for key, dups in bm0hash_dict.items():\n",
    "    dup_counts_dict[len(dups)] += 1\n",
    "\n",
    "sorted_bin_sizes = sorted(dup_counts_dict.items())\n",
    "print('n images with k duplicates')\n",
    "print('(k, n)')\n",
    "sorted_bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 18\n",
    "skip = 5\n",
    "ii = 0\n",
    "jj = 0\n",
    "batch_limit = 9\n",
    "samples_images = np.empty((batch_limit, 768, 768, 3), dtype=np.float32)\n",
    "\n",
    "for hash_id, dups in bm0hash_dict.items():\n",
    "    ii += 1\n",
    "    if len(dups) == batch_size:\n",
    "        dups0 = list(set(dups))\n",
    "        img_id = dups0[0]\n",
    "        idx = np.where(np.all(sdcic.tile_bm0hash_grids[img_id] == np.asarray(hash_id), axis=1))[0]\n",
    "        print(hash_id, len(dups), ii, sdcic.tile_entropy_grids[img_id][idx])\n",
    "        if jj == min(dup_counts_dict[len(dups)], skip):\n",
    "            break\n",
    "        jj += 1\n",
    "\n",
    "for i, c_img_id in enumerate(dups0[:batch_limit]):\n",
    "    c_img = cv2.cvtColor(sdcic.get_img(c_img_id), cv2.COLOR_BGR2RGB)\n",
    "    samples_images[i] = c_img.astype(np.float32) / 255.0\n",
    "\n",
    "batch_rgb = montage_rgb(samples_images)\n",
    "print(samples_images.shape)\n",
    "print(batch_rgb.shape, batch_rgb.dtype)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16, 16))\n",
    "ax.imshow(batch_rgb, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "# plt.savefig(os.path.join('models', BASE_MODEL, f\"{train_meta_filebase}_{score_str}_batch_{BATCH_NUM}.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we explore dup detection using image gradients and cross entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_entropy(ctr, img_size=1769472):  # 768x768x3\n",
    "    ctr_norm = {k: v / img_size for k, v in sorted(ctr.items())}\n",
    "    ctr_entropy = {k: -v * np.log(v) for k, v in ctr_norm.items()}\n",
    "    entropy = np.sum([k * v for k, v in ctr_entropy.items()])\n",
    "    return entropy\n",
    "\n",
    "def get_entropy(img_id):\n",
    "    img = cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    img_grad = np.gradient(img.astype(np.int), axis=(0, 1))\n",
    "    entropy_list = []\n",
    "    for channel_grad in img_grad:\n",
    "        ctr = Counter(np.abs(channel_grad).flatten())\n",
    "        entropy_list.append(get_channel_entropy(ctr, img.size))\n",
    "    return np.array(entropy_list)\n",
    "\n",
    "def get_entropy1(img_id):\n",
    "    img = cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    img_grad = np.gradient(img.astype(np.int), 0.5, axis=(0, 1))\n",
    "    entropy_list = []\n",
    "    for channel_grad in img_grad:\n",
    "        ctr = Counter(np.abs(channel_grad).astype(np.uint8).flatten())\n",
    "        entropy_list.append(ctr)\n",
    "    return entropy_list\n",
    "\n",
    "def get_entropy2(img1_id, img2_id):\n",
    "    entropy1_list = get_entropy1(img1_id)\n",
    "    entropy2_list = get_entropy1(img2_id)\n",
    "    entropy_list = []\n",
    "    for ctr1, ctr2 in zip(entropy1_list, entropy2_list):\n",
    "        ctr = (ctr1 - ctr2) + (ctr2 - ctr1)\n",
    "        entropy_list.append(get_channel_entropy(ctr))\n",
    "    return np.array(entropy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_lim0 = 0\n",
    "score_lim1 = 1\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    if img1_id > img2_id:\n",
    "        # sanity check\n",
    "        raise ValueError(f'img1_id ({img1_id}) should be lexicographically smaller than img2_id ({img2_id})')\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) not in dup_truth:\n",
    "            continue\n",
    "        \n",
    "        is_dup = dup_truth[(img1_id, img2_id, img1_overlap_tag)]\n",
    "\n",
    "        if is_dup == 0 and np.max(scores.enp) > score_lim0:\n",
    "            score_lim0 = np.max(scores.enp)\n",
    "            print_score = True\n",
    "        elif is_dup == 1 and np.max(scores.enp) < score_lim1:\n",
    "            score_lim1 = np.max(scores.enp)\n",
    "            print_score = True\n",
    "        else:\n",
    "            print_score = False\n",
    "\n",
    "        if print_score:\n",
    "            img1_entropy_vec = get_entropy(img1_id)\n",
    "            img2_entropy_vec = get_entropy(img2_id)\n",
    "            img1_entropy_vec_norm = np.linalg.norm(img1_entropy_vec)\n",
    "            img2_entropy_vec_norm = np.linalg.norm(img2_entropy_vec)\n",
    "            n_vec = np.max([img1_entropy_vec_norm, img2_entropy_vec_norm])\n",
    "            img1_scaled_vec = img1_entropy_vec / n_vec\n",
    "            img2_scaled_vec = img2_entropy_vec / n_vec\n",
    "            grad_score = 1.0 - np.linalg.norm(img1_scaled_vec - img2_scaled_vec)\n",
    "\n",
    "            entropy2 = get_entropy2(img1_id, img2_id)\n",
    "            entropy2_norm = np.linalg.norm(entropy2)\n",
    "            \n",
    "            print('')\n",
    "            print(f'{is_dup}, {min(scores.bmh):7.5f}, {min(scores.cmh):7.5f}, {grad_score:7.5f}, {entropy2_norm}')\n",
    "            print(img1_id, img1_entropy_vec, f'{img1_entropy_vec_norm}')\n",
    "            print(img2_id, img2_entropy_vec, f'{img2_entropy_vec_norm}')\n",
    "            print(get_entropy(img1_id))\n",
    "            print(get_entropy(img2_id))\n",
    "            print(entropy2)\n",
    "            print(np.max(scores.enp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_id = '691d5afc2.jpg'\n",
    "img2_id = '56417e7af.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_entropy_vec = get_entropy(img1_id)\n",
    "img2_entropy_vec = get_entropy(img2_id)\n",
    "img1_entropy_vec_norm = np.linalg.norm(img1_entropy_vec)\n",
    "img2_entropy_vec_norm = np.linalg.norm(img2_entropy_vec)\n",
    "n_vec = np.max([img1_entropy_vec_norm, img1_entropy_vec_norm])\n",
    "img1_scaled_vec = img1_entropy_vec / n_vec\n",
    "img2_scaled_vec = img2_entropy_vec / n_vec\n",
    "print('')\n",
    "print(img1_id, img1_entropy_vec, f'{img1_entropy_vec_norm}')\n",
    "print(img2_id, img2_entropy_vec, f'{img1_entropy_vec_norm}')\n",
    "print(f'{np.linalg.norm(img1_scaled_vec - img2_scaled_vec)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/dup_blacklist_6.csv', sep=', ')\n",
    "for idx, row in df.iterrows():\n",
    "    print(idx)\n",
    "    img1_entropy_vec = get_entropy(row['ImageId1'])\n",
    "    img1_entropy_vec_u = img1_entropy_vec / np.linalg.norm(img1_entropy_vec)\n",
    "    print(row['ImageId1'], img1_entropy_vec)\n",
    "    img2_entropy_vec = get_entropy(row['ImageId2'])\n",
    "    img2_entropy_vec_u = img2_entropy_vec / np.linalg.norm(img2_entropy_vec)\n",
    "    print(row['ImageId2'], img2_entropy_vec)\n",
    "    print(np.dot(img1_entropy_vec_u, img2_entropy_vec_u), np.linalg.norm(img1_entropy_vec - img2_entropy_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search for reasonable thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh_scores = defaultdict()\n",
    "cmh_scores = defaultdict()\n",
    "pix_scores = defaultdict(int)\n",
    "\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    if img1_id > img2_id:\n",
    "        # sanity check\n",
    "        raise ValueError(f'img1_id ({img1_id}) should be lexicographically smaller than img2_id ({img2_id})')\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "\n",
    "        for i in range(len(scores.bmh)):\n",
    "            idx = (img1_id, img2_id, img1_overlap_tag, i)\n",
    "            bmh_scores[idx] = scores.bmh[i]\n",
    "            cmh_scores[idx] = scores.cmh[i]\n",
    "            pix_scores[idx] = scores.pix[i]\n",
    "\n",
    "overlap_scores_df = pd.DataFrame()\n",
    "overlap_scores_df['bmh'] = pd.Series(bmh_scores)\n",
    "overlap_scores_df['cmh'] = pd.Series(cmh_scores)\n",
    "overlap_scores_df['pix'] = pd.Series(pix_scores)\n",
    "\n",
    "overlap_scores_df.describe(percentiles=[.01, .05, .1, .25, .5, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh_arr = []\n",
    "cmh_arr = []\n",
    "con_arr = []\n",
    "hom_arr = []\n",
    "eng_arr = []\n",
    "cor_arr = []\n",
    "epy_arr = []\n",
    "enp_arr = []\n",
    "pix_arr = []\n",
    "px0_arr = []\n",
    "shp_arr = []\n",
    "\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "\n",
    "        bmh_arr += list(scores.bmh)\n",
    "        cmh_arr += list(scores.cmh)\n",
    "        con_arr += list(scores.con)\n",
    "        hom_arr += list(scores.hom)\n",
    "        eng_arr += list(scores.eng)\n",
    "        cor_arr += list(scores.cor)\n",
    "        epy_arr += list(scores.epy)\n",
    "        enp_arr += list(scores.enp)\n",
    "        pix_arr += list(scores.pix)\n",
    "        px0_arr += list(scores.px0)\n",
    "        shp_arr += list(scores.shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_limits_df = pd.DataFrame()\n",
    "overlap_limits_df['bmh'] = pd.Series(bmh_arr)\n",
    "overlap_limits_df['cmh'] = pd.Series(cmh_arr)\n",
    "overlap_limits_df['con'] = pd.Series(con_arr)\n",
    "overlap_limits_df['hom'] = pd.Series(hom_arr)\n",
    "overlap_limits_df['eng'] = pd.Series(eng_arr)\n",
    "overlap_limits_df['cor'] = pd.Series(cor_arr)\n",
    "overlap_limits_df['epy'] = pd.Series(epy_arr)\n",
    "overlap_limits_df['enp'] = pd.Series(enp_arr)\n",
    "overlap_limits_df['pix'] = pd.Series(pix_arr)\n",
    "overlap_limits_df['px0'] = pd.Series(px0_arr)\n",
    "overlap_limits_df['shp'] = pd.Series(shp_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_limits_df.describe(percentiles=[.001, .01, .02, .05, .1, .25, .5, .75, .9, .95, .98, .99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_limits_df.describe(percentiles=[.1, .25, .5, .75, .9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  |-----|--------------|-----|\n",
    "# min  lower          upper  max\n",
    "\n",
    "metric_tags = ['bmh', 'cmh', 'con', 'hom', 'eng', 'cor', 'epy', 'enp', 'pix', 'px0', 'shp']\n",
    "Overlap_Scores_Lower_Limit = namedtuple('overlap_scores_lower_limit', metric_tags)\n",
    "Overlap_Scores_Upper_Limit = namedtuple('overlap_scores_upper_limit', metric_tags)\n",
    "\n",
    "osl_lower = Overlap_Scores_Lower_Limit(0., 0., 1e-5, 18e-6, 8e-6, 2e-6, 2e-6, 0.9995, 141, 0, 0)\n",
    "osl_upper = Overlap_Scores_Upper_Limit(1., 1., 8e-5, 1.5e-4, 1e-4, 2e-5, 2e-5, 0.99993, 1859, 1e7, 1e7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "Overlap_Idx_Scores = namedtuple('overlap_idx_scores', [\n",
    "    'idx', \n",
    "    'bmh_min', 'cmh_min', 'con_min', 'hom_min', 'eng_min', 'cor_min', 'epy_min', 'enp_min', 'pix_min', 'px0_min', 'shp_min', \n",
    "    'bmh_max', 'cmh_max', 'con_max', 'hom_max', 'eng_max', 'cor_max', 'epy_max', 'enp_max', 'pix_max', 'px0_max', 'shp_max'])\n",
    "\n",
    "bmh_min = 0\n",
    "cmh_min = 0\n",
    "con_min = 0\n",
    "hom_min = 0\n",
    "eng_min = 0\n",
    "cor_min = 0\n",
    "epy_min = 0\n",
    "enp_min = 0\n",
    "pix_min = 0\n",
    "px0_min = 0\n",
    "shp_min = 0\n",
    "\n",
    "bmh_max = 1\n",
    "cmh_max = 1\n",
    "con_max = 1\n",
    "hom_max = 1\n",
    "eng_max = 1\n",
    "cor_max = 1\n",
    "epy_max = 1\n",
    "enp_max = 1\n",
    "pix_max = 256*256*3*255\n",
    "px0_max = 256*256\n",
    "shp_max = 256*256\n",
    "\n",
    "bmh_min_hits = 0\n",
    "cmh_min_hits = 0\n",
    "con_min_hits = 0\n",
    "hom_min_hits = 0\n",
    "eng_min_hits = 0\n",
    "cor_min_hits = 0\n",
    "epy_min_hits = 0\n",
    "enp_min_hits = 0\n",
    "pix_min_hits = 0\n",
    "px0_min_hits = 0\n",
    "shp_min_hits = 0\n",
    "\n",
    "bmh_max_hits = 0\n",
    "cmh_max_hits = 0\n",
    "con_max_hits = 0\n",
    "hom_max_hits = 0\n",
    "eng_max_hits = 0\n",
    "cor_max_hits = 0\n",
    "epy_max_hits = 0\n",
    "enp_max_hits = 0\n",
    "pix_max_hits = 0\n",
    "px0_max_hits = 0\n",
    "shp_max_hits = 0\n",
    "\n",
    "flat_score_good = 0\n",
    "flat_score_bad = 0\n",
    "print_first_good = True\n",
    "print_first_bad = True\n",
    "n_not_dups = 0\n",
    "\n",
    "overlap_candidates = []\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "\n",
    "        constraint_hits = 0\n",
    "        \n",
    "        bmh_min = np.min(scores.bmh)\n",
    "        if bmh_min < osl_lower.bmh:\n",
    "            bmh_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        cmh_min = np.min(scores.cmh)\n",
    "        if cmh_min < osl_lower.cmh:\n",
    "            cmh_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        con_min = np.min(scores.con)\n",
    "        if con_min < osl_lower.con:\n",
    "            con_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        hom_min = np.min(scores.hom)\n",
    "        if hom_min < osl_lower.hom:\n",
    "            hom_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        eng_min = np.min(scores.eng)\n",
    "        if eng_min < osl_lower.eng:\n",
    "            eng_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        cor_min = np.min(scores.cor)\n",
    "        if cor_min < osl_lower.cor:\n",
    "            cor_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        epy_min = np.min(scores.epy)\n",
    "        if epy_min < osl_lower.epy:\n",
    "            epy_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        enp_min = np.min(scores.enp)\n",
    "        if enp_min < osl_lower.enp:\n",
    "            enp_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        pix_min = np.min(scores.pix)\n",
    "        if pix_min < osl_lower.pix:\n",
    "            pix_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        px0_min = np.min(scores.px0)\n",
    "        if px0_min < osl_lower.px0:\n",
    "            px0_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        shp_min = np.min(scores.shp)\n",
    "        if shp_min < osl_lower.shp:\n",
    "            shp_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "            \n",
    "        bmh_max = np.max(scores.bmh)\n",
    "        if bmh_max > osl_upper.bmh:\n",
    "            bmh_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        cmh_max = np.max(scores.cmh)\n",
    "        if cmh_max > osl_upper.cmh:\n",
    "            cmh_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        con_max = np.max(scores.con)\n",
    "        if con_max > osl_upper.con:\n",
    "            con_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        hom_max = np.max(scores.hom)\n",
    "        if hom_max > osl_upper.hom:\n",
    "            hom_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        eng_max = np.max(scores.eng)\n",
    "        if eng_max > osl_upper.eng:\n",
    "            eng_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        cor_max = np.max(scores.cor)\n",
    "        if cor_max > osl_upper.cor:\n",
    "            cor_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        epy_max = np.max(scores.epy)\n",
    "        if epy_max > osl_upper.epy:\n",
    "            epy_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        enp_max = np.max(scores.enp)\n",
    "        if enp_max > osl_upper.enp:\n",
    "            enp_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        pix_max = np.max(scores.pix)\n",
    "        if pix_max > osl_upper.pix:\n",
    "            pix_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        px0_max = np.max(scores.px0)\n",
    "        if px0_max > osl_upper.px0:\n",
    "            px0_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        shp_max = np.max(scores.shp)\n",
    "        if shp_max > osl_upper.shp:\n",
    "            shp_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "#         if constraint_hits < 0:\n",
    "#             continue\n",
    "            \n",
    "        idx = (img1_id, img2_id, img1_overlap_tag)\n",
    "        overlap_scores = Overlap_Idx_Scores(\n",
    "            idx, \n",
    "            bmh_min, cmh_min, con_min, hom_min, eng_min, cor_min, epy_min, enp_min, pix_min, px0_min, shp_min, \n",
    "            bmh_max, cmh_max, con_max, hom_max, eng_max, cor_max, epy_max, enp_max, pix_max, px0_max, shp_max)\n",
    "        overlap_candidates.append(overlap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print(len(overlap_candidates))\n",
    "print(bmh_min_hits, cmh_min_hits, con_min_hits, hom_min_hits, eng_min_hits, cor_min_hits, epy_min_hits, enp_min_hits, pix_min_hits)\n",
    "print(bmh_max_hits, cmh_max_hits, con_max_hits, hom_max_hits, eng_max_hits, cor_max_hits, epy_max_hits, enp_max_hits, pix_max_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dup_truth), n_not_dups, flat_score_good, flat_score_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use duplicate_truth.txt and image_md5hash_grids.pkl to find untested duplicate and non-duplicate tiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of flat hashes. \n",
    "(i.e. hashes for tiles where every pixel is the same color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_overlap_index_maps = generate_tag_pair_lookup()\n",
    "\n",
    "solid_hashes = set()\n",
    "for img_id, tile_issolid_grid in sdcic.tile_issolid_grids.items():\n",
    "    idxs = set(np.where(tile_issolid_grid >= 0)[0])\n",
    "    for idx in idxs:\n",
    "        if np.all(tile_issolid_grid[idx] >= 0):\n",
    "            solid_hashes.add(sdcic.tile_md5hash_grids[img_id][idx])\n",
    "\n",
    "print(solid_hashes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_hash_dup_dict = defaultdict(set)\n",
    "tile_hash_dif_dict = defaultdict(set)\n",
    "\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in dup_truth.items():\n",
    "    \n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if is_dup:\n",
    "\n",
    "            if tile1_hash in solid_hashes or tile2_hash in solid_hashes:\n",
    "                continue\n",
    "\n",
    "            tile_hash_dup_dict[tile1_hash].add(tile1_hash)\n",
    "            tile_hash_dup_dict[tile2_hash].add(tile2_hash)\n",
    "            tile_hash_dup_dict[tile1_hash].add(tile2_hash)\n",
    "            tile_hash_dup_dict[tile2_hash].add(tile1_hash)\n",
    "        \n",
    "        else:\n",
    "            if tile1_hash == tile2_hash:\n",
    "                continue\n",
    "\n",
    "            tile_hash_dif_dict[tile1_hash].add(tile2_hash)\n",
    "            tile_hash_dif_dict[tile2_hash].add(tile1_hash)\n",
    "            \n",
    "print(len(tile_hash_dup_dict), len(tile_hash_dif_dict))\n",
    "\n",
    "# Sanity check: hashes cannot be simultaneously \"a dup\" and \"not a dup\" of tile1_hash\n",
    "for tile1_hash in tile_hash_dup_dict:\n",
    "    if len(tile_hash_dup_dict[tile1_hash].intersection(tile_hash_dif_dict[tile1_hash])) != 0:\n",
    "        print(tile1_hash, tile_hash_dup_dict[tile1_hash], tile_hash_dif_dict[tile1_hash])\n",
    "    assert len(tile_hash_dup_dict[tile1_hash].intersection(tile_hash_dif_dict[tile1_hash])) == 0\n",
    "    \n",
    "# Sanity check: If B and C are dups of A, then make sure C not in tile_hash_dif_dict[B]\n",
    "for tile1_hash, tile1_dups in tile_hash_dup_dict.items():\n",
    "    for tile1_dup1 in sorted(tile1_dups):\n",
    "        for tile1_dup2 in sorted(tile1_dups):\n",
    "            if tile1_dup1 in tile_hash_dif_dict[tile1_dup2]:\n",
    "                print(tile1_hash, tile1_dup1, tile_hash_dif_dict[tile1_dup2])\n",
    "            assert tile1_dup1 not in tile_hash_dif_dict[tile1_dup2]\n",
    "\n",
    "# Now we should be able to form cliques: (i.e. If A == B and B == C, then A == C)\n",
    "for tile1_hash, tile1_dups in tile_hash_dup_dict.items():\n",
    "    for tile1_dup1 in sorted(tile1_dups):\n",
    "        for tile1_dup2 in sorted(tile1_dups):\n",
    "            if tile1_dup1 <= tile1_dup2:\n",
    "                continue\n",
    "            tile_hash_dup_dict[tile1_dup1].add(tile1_dup2)\n",
    "            tile_hash_dup_dict[tile1_dup2].add(tile1_dup1)\n",
    "\n",
    "neighbor_counts = Counter()\n",
    "for tile1_hash, tile1_dups in tile_hash_dup_dict.items():\n",
    "    neighbor_counts[len(tile1_dups)] += 1\n",
    "list(sorted(neighbor_counts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels_0 = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dif_dict[tile2_hash]:\n",
    "            assert tile2_hash in tile_hash_dif_dict[tile1_hash]\n",
    "            auto_overlap_labels_0[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "            break\n",
    "\n",
    "print(len(auto_overlap_labels_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels_1 = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dup_dict[tile2_hash]:\n",
    "            assert tile2_hash in tile_hash_dup_dict[tile1_hash]\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        auto_overlap_labels_1[(img1_id, img2_id, img1_overlap_tag)] = 1\n",
    "\n",
    "print(len(auto_overlap_labels_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cliques via networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_hash_dup_cliques = nx.Graph()\n",
    "tile_hash_dif_cliques = nx.Graph()\n",
    "\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in dup_truth.items():\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        if is_dup:\n",
    "            if tile1_hash in solid_hashes or tile2_hash in solid_hashes:\n",
    "                continue\n",
    "            update_tile_cliques(tile_hash_dup_cliques, tile1_hash, tile2_hash)\n",
    "        else:\n",
    "            if tile1_hash == tile2_hash:\n",
    "                continue\n",
    "            tile_hash_dif_cliques.add_edge(tile1_hash, tile2_hash)\n",
    "\n",
    "print(tile_hash_dup_cliques.number_of_nodes(), tile_hash_dif_cliques.number_of_nodes())\n",
    "\n",
    "neighbor_counts = Counter()\n",
    "for tile_hashes in nx.connected_components(tile_hash_dup_cliques):\n",
    "    neighbor_counts[len(tile_hashes)] += 1\n",
    "list(sorted(neighbor_counts.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels_0 = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dif_cliques and tile2_hash in set(nx.neighbors(tile_hash_dif_cliques, tile1_hash)):\n",
    "            auto_overlap_labels_0[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "            break\n",
    "\n",
    "print(len(auto_overlap_labels_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels_1 = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dup_cliques and tile2_hash in set(nx.neighbors(tile_hash_dup_cliques, tile1_hash)):\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        auto_overlap_labels_1[(img1_id, img2_id, img1_overlap_tag)] = 1\n",
    "\n",
    "print(len(auto_overlap_labels_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels = {}\n",
    "for key in auto_overlap_labels_0:\n",
    "    assert key not in auto_overlap_labels_1\n",
    "auto_overlap_labels.update(auto_overlap_labels_0)\n",
    "auto_overlap_labels.update(auto_overlap_labels_1)\n",
    "print(len(auto_overlap_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    if (img1_id, img2_id, img1_overlap_tag) in auto_overlap_labels:\n",
    "        continue\n",
    "    is_dup = 1\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dif_cliques and tile2_hash in set(nx.neighbors(tile_hash_dif_cliques, tile1_hash)):\n",
    "            is_dup = 0\n",
    "            break\n",
    "        elif tile1_hash in tile_hash_dup_cliques and tile2_hash in set(nx.neighbors(tile_hash_dup_cliques, tile1_hash)):\n",
    "            continue\n",
    "        else:\n",
    "            is_dup = -1\n",
    "\n",
    "    if is_dup == -1:\n",
    "        continue\n",
    "    \n",
    "    auto_overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = is_dup\n",
    "\n",
    "print(len(auto_overlap_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth = update_duplicate_truth(auto_overlap_labels, auto=True)\n",
    "len(dup_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the performance of DupNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = []\n",
    "tile_pairs = []\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in tqdm_notebook(dup_truth.items()):\n",
    "    for overlap_idx, (idx1, idx2) in enumerate(img_overlap_index_maps[img1_overlap_tag]):\n",
    "        tile_pairs.append(TilePairs(img1_id, img2_id, img1_overlap_tag, overlap_idx, idx1, idx2))\n",
    "        ytrue.append(is_dup)\n",
    "print(len(tile_pairs), sum(ytrue), len(ytrue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(tile_pairs)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=256, num_workers=12)\n",
    "test_dl = WrappedDataLoader(test_dl, preprocess)\n",
    "print(len(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint('models/dup_model.best.pth')\n",
    "model.cuda()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yprobs0 = [model(xb) for xb in tqdm_notebook(test_dl)]\n",
    "    yprobs = np.vstack([l.cpu() for l in yprobs0]).reshape(-1)\n",
    "    print(len(yprobs0), yprobs.shape, min(yprobs), max(yprobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_cnn_tile_scores = {}\n",
    "for tp, yprob in zip(tile_pairs, yprobs):\n",
    "    \n",
    "    if (tp.img1_id, tp.img2_id) not in overlap_cnn_tile_scores:\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)] = {}\n",
    "    \n",
    "    if tp.img1_overlap_tag not in overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)]:\n",
    "        n_overlapping_tiles = len(img_overlap_index_maps[tp.img1_overlap_tag])\n",
    "        cnn_scores = np.zeros(n_overlapping_tiles)\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag] = cnn_scores\n",
    "    \n",
    "    overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag][tp.overlap_idx] = yprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_Stats = namedtuple('dnn_stats', ['yprob', 'ypred', 'ytrue', 'loss', 'yconf', 'pix'])\n",
    "\n",
    "dup_dict = {}\n",
    "for (img1_id, img2_id, img1_overlap_tag), ytrue in tqdm_notebook(dup_truth.items()):\n",
    "    assert img1_id < img2_id\n",
    "\n",
    "    if (img1_id, img2_id, img1_overlap_tag) in dup_dict:\n",
    "        continue\n",
    "    if (img1_id, img2_id) not in overlap_image_maps:\n",
    "        continue\n",
    "    if img1_overlap_tag not in overlap_image_maps[(img1_id, img2_id)]:\n",
    "        continue\n",
    "    scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    if len(scores.pix) < 2:\n",
    "        continue\n",
    "    pix = max(scores.pix)\n",
    "#     if (img1_id, img2_id) not in overlap_cnn_tile_scores:\n",
    "#         continue\n",
    "#     if img1_overlap_tag not in overlap_cnn_tile_scores[(img1_id, img2_id)]:\n",
    "#         continue\n",
    "\n",
    "    dcnn_scores_raw = overlap_cnn_tile_scores[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    dcnn_conf_raw = np.abs((dcnn_scores_raw - 0.5) * 2) # confidence? (1: very, 0: not at all)\n",
    "    yconf = np.min(dcnn_conf_raw)\n",
    "    yprob = np.min(dcnn_scores_raw)\n",
    "    ypred = (yprob > 0.5) * 1\n",
    "    assert ypred <= 1\n",
    "    \n",
    "    if ytrue:\n",
    "        bce = - ytrue * np.log(yprob)\n",
    "    else:\n",
    "        bce = - (1 - ytrue) * np.log(1 - yprob)\n",
    "    \n",
    "    dup_dict[(img1_id, img2_id, img1_overlap_tag)] = DNN_Stats(yprob, ypred, ytrue, bce, yconf, pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_Stats2 = namedtuple('dnn_stats', ['key', 'yprob', 'ypred', 'ytrue', 'loss', 'yconf', 'pix'])\n",
    "dup_dict_flat = []\n",
    "for keys, dnns in tqdm_notebook(dup_dict.items()):\n",
    "    dup_dict_flat.append(DNN_Stats2(keys, dnns.yprob, dnns.ypred, dnns.ytrue, dnns.loss, dnns.yconf, dnns.pix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_correct = 0\n",
    "id_tags = []\n",
    "for dnns in tqdm_notebook(sorted(dup_dict_flat, key=operator.attrgetter('loss'), reverse=True)):\n",
    "\n",
    "    # Skip the ones the dnn got correct.\n",
    "    if dnns.ypred == dnns.ytrue:\n",
    "        n_correct += 1\n",
    "        continue\n",
    "        \n",
    "#     if dnns.key[2] != '08':\n",
    "#         continue\n",
    "#     if not dnns.ytrue:\n",
    "#         continue\n",
    "#     if (dnns.key[0], dnns.key[1]) not in overlap_image_maps:\n",
    "#         continue\n",
    "\n",
    "    if dnns.loss == np.nan:\n",
    "        print('nan ', dnns)\n",
    "        id_tags.append(dnns.key)\n",
    "        continue\n",
    "    if dnns.loss == np.inf:\n",
    "        print('+inf', dnns)\n",
    "        id_tags.append(dnns.key)\n",
    "        continue\n",
    "    if dnns.loss == -np.inf:\n",
    "        print('-inf', dnns)\n",
    "        id_tags.append(dnns.key)\n",
    "        continue\n",
    "        \n",
    "#     Skip the ones the dnn was certain about.\n",
    "#     if dnns.yprob < 0.01 or dnns.yprob > 0.99:\n",
    "#         continue\n",
    "\n",
    "    id_tags.append(dnns.key)\n",
    "len(id_tags), n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_counter = Counter()\n",
    "for img1_id, img2_id, img1_overlap_tag in id_tags:\n",
    "    tags_counter[img1_id] += 1\n",
    "    tags_counter[img2_id] += 1\n",
    "print(len(tags_counter))\n",
    "\n",
    "for k, v in sorted(tags_counter.items(), key=operator.itemgetter(0), reverse=False):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa = 0\n",
    "n_samples = 10\n",
    "use_median_shift = True\n",
    "\n",
    "test_files = id_tags[aa * n_samples: (aa + 1) * n_samples]#[::-1]\n",
    "for f in test_files:\n",
    "    print(f, '{:.5} {} {} {:.5} {:.5} {}'.format(*dup_dict[f]))\n",
    "\n",
    "dtick = 256\n",
    "n_ticks = 768 // dtick + 1\n",
    "ticks = [i * dtick for i in range(n_ticks)]\n",
    "\n",
    "fig, m_axs = plt.subplots(n_samples, 2, figsize = (12, 6 * n_samples))\n",
    "for ii, (img1_id, img2_id, img1_overlap_tag) in enumerate(test_files):\n",
    "    \n",
    "    scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    \n",
    "    (ax1, ax2) = m_axs[ii]\n",
    "    yprob, ypred, is_dup, loss, yconf, pix = dup_dict[(img1_id, img2_id, img1_overlap_tag)]\n",
    "    \n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "\n",
    "    slice1 = overlap_tag_slices[img1_overlap_tag]\n",
    "    slice2 = overlap_tag_slices[overlap_tag_pairs[img1_overlap_tag]]\n",
    "\n",
    "    m12 = np.median(np.vstack([imgmod1.parent_rgb[slice1], imgmod2.parent_rgb[slice2]]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "    \n",
    "    brightness_level = -100 if np.sum(m12) >= 384 else 100\n",
    "    img1 = imgmod1.brightness_shift('L', brightness_level)\n",
    "    img2 = imgmod2.brightness_shift('L', brightness_level)\n",
    "    \n",
    "    if use_median_shift:\n",
    "        img1_drop = imgmod1.parent_rgb - m12\n",
    "        img2_drop = imgmod2.parent_rgb - m12\n",
    "    else:        \n",
    "        img1_drop = imgmod1.parent_rgb\n",
    "        img2_drop = imgmod2.parent_rgb\n",
    "    \n",
    "    img1[slice1] = img1_drop[slice1]\n",
    "    img2[slice2] = img2_drop[slice2]\n",
    "\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(f'{img1_id} {yprob:6.4} ({is_dup})')\n",
    "    ax1.set_xticks(ticks)\n",
    "    ax1.set_yticks(ticks)\n",
    "\n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title(f'{img2_id} {loss:4.2f} {max(scores.pix)}')\n",
    "    ax2.set_xticks(ticks)\n",
    "    ax2.set_yticks(ticks)\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(os.path.join('temp', BASE_MODEL, f\"{train_meta_filebase}_{score_str}_batch_{BATCH_NUM}_row_{aa+1}.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}