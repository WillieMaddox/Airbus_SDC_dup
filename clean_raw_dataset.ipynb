{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import operator\n",
    "import h5py\n",
    "from collections import Counter\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage.util import montage\n",
    "import cv2\n",
    "from cv2 import img_hash\n",
    "import torch\n",
    "\n",
    "from sdcdup.utils import overlap_tag_pairs\n",
    "from sdcdup.utils import overlap_tag_maps\n",
    "from sdcdup.utils import generate_overlap_tag_slices\n",
    "from sdcdup.utils import boundingbox_corners\n",
    "from sdcdup.utils import generate_tag_pair_lookup\n",
    "from sdcdup.utils import fuzzy_compare\n",
    "from sdcdup.utils import get_tile\n",
    "from sdcdup.utils import get_hamming_distance_score\n",
    "from sdcdup.utils import channel_shift\n",
    "from sdcdup.utils import read_duplicate_truth\n",
    "from sdcdup.utils import update_duplicate_truth\n",
    "from sdcdup.utils import read_image_duplicate_tiles\n",
    "from sdcdup.utils import write_image_duplicate_tiles\n",
    "from sdcdup.utils import read_image_image_duplicate_tiles\n",
    "from sdcdup.utils import update_image_image_duplicate_tiles\n",
    "from sdcdup.utils import generate_overlap_tag_nines_mask\n",
    "\n",
    "from test_friend_circles import SDCImageContainer\n",
    "\n",
    "from dupnet import load_checkpoint\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "EPS = np.finfo(np.float32).eps\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title\n",
    "\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "montage_pad = lambda x, *args, **kwargs: montage(x, padding_width=10, *args, **kwargs)\n",
    "zeros_mask = np.zeros((256*3, 256*3, 1), dtype=np.float32)\n",
    "\n",
    "ship_dir = \"data/input\"\n",
    "train_image_dir = os.path.join(ship_dir, \"train_768\")\n",
    "train_mask_dir = os.path.join(ship_dir, 'train_masks_768')\n",
    "train_seg_file = os.path.join(ship_dir, \"fullmasks_768.h5\")\n",
    "image_greycop_grids_file = os.path.join(\"data\", \"image_greycop_grids.pkl\")\n",
    "image_md5hash_grids_file = os.path.join(\"data\", \"image_md5hash_grids.pkl\")\n",
    "image_bm0hash_grids_file = os.path.join(\"data\", \"image_bm0hash_grids.pkl\")\n",
    "image_cm0hash_grids_file = os.path.join(\"data\", \"image_cm0hash_grids.pkl\")\n",
    "image_entropy_grids_file = os.path.join(\"data\", \"image_entropy_grids.pkl\")\n",
    "image_duplicate_tiles_file = os.path.join(\"data\", \"image_duplicate_tiles.txt\")\n",
    "image_image_duplicate_tiles_file = os.path.join(\"data\", \"image_image_duplicate_tiles.txt\")\n",
    "duplicate_truth_file = os.path.join('data', 'duplicate_truth.txt')\n",
    "\n",
    "overlap_tag_slices = generate_overlap_tag_slices()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_entropy(ctr, img_size=1769472):  # 768x768x3\n",
    "    ctr_norm = {k: v / img_size for k, v in sorted(ctr.items())}\n",
    "    ctr_entropy = {k: -v * np.log(v) for k, v in ctr_norm.items()}\n",
    "    entropy = np.sum([k * v for k, v in ctr_entropy.items()])\n",
    "    return entropy\n",
    "\n",
    "def get_entropy(img_id):\n",
    "    img = cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    img_grad = np.gradient(img.astype(np.int), axis=(0, 1))\n",
    "    entropy_list = []\n",
    "    for channel_grad in img_grad:\n",
    "        ctr = Counter(np.abs(channel_grad).flatten())\n",
    "        entropy_list.append(get_channel_entropy(ctr, img.size))\n",
    "    return np.array(entropy_list)\n",
    "\n",
    "def get_entropy1(img_id):\n",
    "    img = cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    img_grad = np.gradient(img.astype(np.int), 0.5, axis=(0, 1))\n",
    "    entropy_list = []\n",
    "    for channel_grad in img_grad:\n",
    "        ctr = Counter(np.abs(channel_grad).astype(np.uint8).flatten())\n",
    "        entropy_list.append(ctr)\n",
    "    return entropy_list\n",
    "\n",
    "def get_entropy2(img1_id, img2_id):\n",
    "    entropy1_list = get_entropy1(img1_id)\n",
    "    entropy2_list = get_entropy1(img2_id)\n",
    "    entropy_list = []\n",
    "    for ctr1, ctr2 in zip(entropy1_list, entropy2_list):\n",
    "        ctr = (ctr1 - ctr2) + (ctr2 - ctr1)\n",
    "        entropy_list.append(get_channel_entropy(ctr))\n",
    "    return np.array(entropy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgMod:\n",
    "    \"\"\"\n",
    "    Reads a single image to be modified by hls.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.img_id = filename.split('/')[-1]\n",
    "\n",
    "        self._hls_chan = None\n",
    "        self._hls_gain = None\n",
    "\n",
    "        self._parent_bgr = None\n",
    "        self._parent_hls = None\n",
    "        self._parent_rgb = None\n",
    "        self._cv2_hls = None\n",
    "        self._cv2_bgr = None\n",
    "        self._cv2_rgb = None\n",
    "\n",
    "    def channel_shift(self, chan, gain):\n",
    "        self._hls_chan = chan\n",
    "        self._hls_gain = gain\n",
    "        self._cv2_hls = None\n",
    "        return self.cv2_rgb\n",
    "    \n",
    "    def scale(self, minval, maxval):\n",
    "        m = 255.0 * (maxval - minval)\n",
    "        res = m * (self.parent_bgr - minval)\n",
    "        return np.around(res).astype(np.uint8)\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.parent_bgr.shape\n",
    "    \n",
    "    @property\n",
    "    def parent_bgr(self):\n",
    "        if self._parent_bgr is None:\n",
    "            self._parent_bgr = cv2.imread(self.filename)\n",
    "        return self._parent_bgr\n",
    "\n",
    "    @property\n",
    "    def parent_hls(self):\n",
    "        if self._parent_hls is None:\n",
    "            self._parent_hls = self.to_hls(self.parent_bgr)\n",
    "        return self._parent_hls\n",
    "\n",
    "    @property\n",
    "    def parent_rgb(self):\n",
    "        if self._parent_rgb is None:\n",
    "            self._parent_rgb = self.to_rgb(self.parent_bgr)\n",
    "        return self._parent_rgb\n",
    "\n",
    "    @property\n",
    "    def cv2_hls(self):\n",
    "        if self._cv2_hls is None:\n",
    "            if self._hls_gain == None:\n",
    "                self._cv2_hls = self.parent_hls\n",
    "            else:\n",
    "                self._cv2_hls = channel_shift(self.parent_hls, self._hls_chan, self._hls_gain)\n",
    "        return self._cv2_hls\n",
    "\n",
    "    @property\n",
    "    def cv2_bgr(self):\n",
    "        if self._cv2_bgr is None:\n",
    "            self._cv2_bgr = self.to_bgr(self.cv2_hls)\n",
    "        return self._cv2_bgr\n",
    "\n",
    "    @property\n",
    "    def cv2_rgb(self):\n",
    "        if self._cv2_rgb is None:\n",
    "            self._cv2_rgb = self.to_rgb(self.cv2_bgr)\n",
    "        return self._cv2_rgb\n",
    "\n",
    "    def to_hls(self, bgr):\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2HLS_FULL)\n",
    "\n",
    "    def to_bgr(self, hls):\n",
    "        return cv2.cvtColor(hls, cv2.COLOR_HLS2BGR_FULL)\n",
    "\n",
    "    def to_rgb(self, bgr):\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdcic = SDCImageContainer(train_image_dir)\n",
    "sdcic.preprocess_image_properties(\n",
    "    image_greycop_grids_file,\n",
    "    image_md5hash_grids_file,\n",
    "    image_bm0hash_grids_file,\n",
    "    image_cm0hash_grids_file,\n",
    "    image_entropy_grids_file,\n",
    "    image_duplicate_tiles_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth = read_duplicate_truth(duplicate_truth_file)\n",
    "image_image_duplicate_tiles = read_image_image_duplicate_tiles(image_image_duplicate_tiles_file)\n",
    "overlap_tag_nines_mask = generate_overlap_tag_nines_mask()\n",
    "len(dup_truth), len(image_image_duplicate_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_image_properties(n_matching_tiles, overlap_image_maps):\n",
    "    overlap_bmh_tile_scores_file = os.path.join(\"data\", f\"overlap_bmh_tile_scores_{n_matching_tiles}.pkl\")\n",
    "    overlap_cmh_tile_scores_file = os.path.join(\"data\", f\"overlap_cmh_tile_scores_{n_matching_tiles}.pkl\")\n",
    "    overlap_gcm_tile_scores_file = os.path.join(\"data\", f\"overlap_gcm_tile_scores_{n_matching_tiles}.pkl\")\n",
    "    overlap_enp_tile_scores_file = os.path.join(\"data\", f\"overlap_enp_tile_scores_{n_matching_tiles}.pkl\")\n",
    "    overlap_pix_tile_scores_file = os.path.join(\"data\", f\"overlap_pix_tile_scores_{n_matching_tiles}.pkl\")\n",
    "    \n",
    "    df = pd.read_pickle(overlap_bmh_tile_scores_file)\n",
    "    overlap_bmh_tile_scores = {}\n",
    "    for img1_id, img2_id, img1_overlap_tag, *bmh_scores in tqdm_notebook(df.to_dict('split')['data']):\n",
    "        if (img1_id, img2_id) not in overlap_bmh_tile_scores:\n",
    "            overlap_bmh_tile_scores[(img1_id, img2_id)] = {}\n",
    "        overlap_bmh_tile_scores[(img1_id, img2_id)][img1_overlap_tag] = np.array(bmh_scores)\n",
    "\n",
    "    df = pd.read_pickle(overlap_cmh_tile_scores_file)\n",
    "    overlap_cmh_tile_scores = {}\n",
    "    for img1_id, img2_id, img1_overlap_tag, *cmh_scores in tqdm_notebook(df.to_dict('split')['data']):\n",
    "        if (img1_id, img2_id) not in overlap_cmh_tile_scores:\n",
    "            overlap_cmh_tile_scores[(img1_id, img2_id)] = {}\n",
    "        overlap_cmh_tile_scores[(img1_id, img2_id)][img1_overlap_tag] = np.array(cmh_scores)\n",
    "\n",
    "    df = pd.read_pickle(overlap_gcm_tile_scores_file)\n",
    "    overlap_gcm_tile_scores = {}\n",
    "    for img1_id, img2_id, img1_overlap_tag, *gcm_scores in tqdm_notebook(df.to_dict('split')['data']):\n",
    "        if (img1_id, img2_id) not in overlap_gcm_tile_scores:\n",
    "            overlap_gcm_tile_scores[(img1_id, img2_id)] = {}\n",
    "        overlap_gcm_tile_scores[(img1_id, img2_id)][img1_overlap_tag] = np.array(gcm_scores)\n",
    "\n",
    "    df = pd.read_pickle(overlap_enp_tile_scores_file)\n",
    "    overlap_enp_tile_scores = {}\n",
    "    for img1_id, img2_id, img1_overlap_tag, *enp_scores in tqdm_notebook(df.to_dict('split')['data']):\n",
    "        if (img1_id, img2_id) not in overlap_enp_tile_scores:\n",
    "            overlap_enp_tile_scores[(img1_id, img2_id)] = {}\n",
    "        overlap_enp_tile_scores[(img1_id, img2_id)][img1_overlap_tag] = np.array(enp_scores)\n",
    "\n",
    "    df = pd.read_pickle(overlap_pix_tile_scores_file)\n",
    "    overlap_pix_tile_scores = {}\n",
    "    for img1_id, img2_id, img1_overlap_tag, *pix_scores in tqdm_notebook(df.to_dict('split')['data']):\n",
    "        if (img1_id, img2_id) not in overlap_pix_tile_scores:\n",
    "            overlap_pix_tile_scores[(img1_id, img2_id)] = {}\n",
    "        overlap_pix_tile_scores[(img1_id, img2_id)][img1_overlap_tag] = np.array(pix_scores)\n",
    "\n",
    "    Overlap_Scores = namedtuple('overlap_scores', ['bmh', 'cmh', 'con', 'hom', 'eng', 'cor', 'epy', 'enp', 'pix'])\n",
    "    for (img1_id, img2_id), img1_overlap_tags in tqdm_notebook(sorted(overlap_bmh_tile_scores.items())):\n",
    "        for img1_overlap_tag in img1_overlap_tags:\n",
    "\n",
    "            bmh_scores = overlap_bmh_tile_scores[(img1_id, img2_id)][img1_overlap_tag]\n",
    "            cmh_scores = overlap_cmh_tile_scores[(img1_id, img2_id)][img1_overlap_tag]\n",
    "            con_scores = overlap_gcm_tile_scores[(img1_id, img2_id)][img1_overlap_tag][:, 0]\n",
    "            hom_scores = overlap_gcm_tile_scores[(img1_id, img2_id)][img1_overlap_tag][:, 1]\n",
    "            eng_scores = overlap_gcm_tile_scores[(img1_id, img2_id)][img1_overlap_tag][:, 2]\n",
    "            cor_scores = overlap_gcm_tile_scores[(img1_id, img2_id)][img1_overlap_tag][:, 3]\n",
    "            epy_scores = overlap_gcm_tile_scores[(img1_id, img2_id)][img1_overlap_tag][:, 4]\n",
    "            enp_scores = overlap_enp_tile_scores[(img1_id, img2_id)][img1_overlap_tag]\n",
    "            pix_scores = overlap_pix_tile_scores[(img1_id, img2_id)][img1_overlap_tag]\n",
    "\n",
    "            overlap_scores = Overlap_Scores(bmh_scores, cmh_scores, con_scores, hom_scores, eng_scores, cor_scores, epy_scores, enp_scores, pix_scores)\n",
    "\n",
    "            if (img1_id, img2_id) not in overlap_image_maps:\n",
    "                overlap_image_maps[(img1_id, img2_id)] = {}\n",
    "            overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag] = overlap_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_matching_tiles_list = [9, 6, 4, 3, 2]\n",
    "overlap_image_maps = {}\n",
    "for n_matching_tiles in n_matching_tiles_list:\n",
    "    load_image_image_properties(n_matching_tiles, overlap_image_maps)\n",
    "    print(len(overlap_image_maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "img_overlap_index_maps = generate_tag_pair_lookup()\n",
    "TilePairs = namedtuple('TilePairs', 'img1_id img2_id img1_overlap_tag overlap_idx idx1 idx2')\n",
    "\n",
    "def get_img(img_id):\n",
    "    return cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    \n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, tile_pairs, \n",
    "                 image_transform=None,\n",
    "                 in_shape=(6, 256, 256), \n",
    "                 out_shape=(1,)):\n",
    "\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.sz = 256\n",
    "        self.tile_pairs = tile_pairs\n",
    "        self.image_transform = image_transform\n",
    "        self.ij = ((0, 0), (0, 1), (0, 2),\n",
    "                   (1, 0), (1, 1), (1, 2),\n",
    "                   (2, 0), (2, 1), (2, 2))\n",
    "        \n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return len(self.tile_pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one sample of data\"\"\"\n",
    "        tp = self.tile_pairs[index]\n",
    "        \n",
    "        img1 = get_img(tp.img1_id)\n",
    "        img2 = get_img(tp.img2_id)\n",
    "        \n",
    "        tile1 = cv2.cvtColor(self.get_tile(img1, *self.ij[tp.idx1]), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        tile2 = cv2.cvtColor(self.get_tile(img2, *self.ij[tp.idx2]), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        \n",
    "        X = np.dstack([tile1, tile2])\n",
    "        X = X.transpose((2, 0, 1))\n",
    "        X = torch.from_numpy(X)\n",
    "        return X\n",
    "    \n",
    "    def get_tile(self, img, i, j):\n",
    "        return img[i * self.sz:(i + 1) * self.sz, j * self.sz:(j + 1) * self.sz, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return x.view(-1, 6, 256, 256).to(device)\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_pairs = []\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    for img1_overlap_tag in overlap_maps:\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "        for overlap_idx, (idx1, idx2) in enumerate(img_overlap_index_maps[img1_overlap_tag]):\n",
    "            tile_pairs.append(TilePairs(img1_id, img2_id, img1_overlap_tag, overlap_idx, idx1, idx2))\n",
    "\n",
    "print(len(tile_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(tile_pairs)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=256, num_workers=12)\n",
    "test_dl = WrappedDataLoader(test_dl, preprocess)\n",
    "print(len(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint('out/dup_model.last.pth')\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yprobs0 = [model(xb) for xb in tqdm_notebook(test_dl)]\n",
    "    print(len(yprobs0))\n",
    "    yprobs = np.vstack([l.cpu() for l in yprobs0]).reshape(-1)\n",
    "    print(yprobs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprobs_c = np.where(np.abs(yprobs - 0.5) < 0.47)[0]\n",
    "print(yprobs_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_weak_pred = False\n",
    "weak_preds = []\n",
    "overlap_cnn_tile_scores = {}\n",
    "for ii, (tp, yprob) in enumerate(zip(tile_pairs, yprobs)):\n",
    "    if ii in yprobs_c:\n",
    "        is_weak_pred = True\n",
    "    if (tp.img1_id, tp.img2_id) not in overlap_cnn_tile_scores:\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)] = {}\n",
    "    if tp.img1_overlap_tag not in overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)]:\n",
    "        n_overlapping_tiles = len(img_overlap_index_maps[tp.img1_overlap_tag])\n",
    "        cnn_scores = [None] * n_overlapping_tiles\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag] = cnn_scores\n",
    "    overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag][tp.overlap_idx] = yprob\n",
    "    if tp.overlap_idx == n_overlapping_tiles - 1 and is_weak_pred:\n",
    "        weak_preds.append((tp.img1_id, tp.img2_id, tp.img1_overlap_tag))\n",
    "        is_weak_pred = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weak_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlaps with ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untested_image_pairs_with_ship_masks = []\n",
    "with h5py.File(train_seg_file, 'r') as full_mask:\n",
    "    for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "        # TODO: Find out which remaining tile pairs have masks but aren't in dup_truth.\n",
    "        \n",
    "        has_mask1 = img1_id in full_mask\n",
    "        has_mask2 = img2_id in full_mask\n",
    "        if not (has_mask1 and has_mask2):\n",
    "            continue\n",
    "            \n",
    "        for img1_overlap_tag in overlap_maps:\n",
    "            if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "                continue\n",
    "            untested_image_pairs_with_ship_masks.append((img1_id, img2_id))\n",
    "            break\n",
    "\n",
    "len(overlap_image_maps), len(untested_image_pairs_with_ship_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untested_overlaps_with_ship_masks = []\n",
    "with h5py.File(train_seg_file, 'r') as full_mask:\n",
    "    for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "        # TODO: Find out which remaining tile pairs have masks but aren't in dup_truth.\n",
    "        \n",
    "        has_mask1 = img1_id in full_mask\n",
    "        has_mask2 = img2_id in full_mask\n",
    "        if not (has_mask1 and has_mask2):\n",
    "            continue\n",
    "            \n",
    "        for img1_overlap_tag in overlap_maps:\n",
    "            if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "                continue\n",
    "\n",
    "            mask1 = full_mask[img1_id][:] if has_mask1 else zeros_mask\n",
    "            mask2 = full_mask[img2_id][:] if has_mask2 else zeros_mask\n",
    "            \n",
    "            mask1_slice_total = np.sum(mask1[overlap_tag_slices[img1_overlap_tag]])\n",
    "            mask2_slice_total = np.sum(mask2[overlap_tag_slices[overlap_tag_pairs[img1_overlap_tag]]])\n",
    "            \n",
    "            if mask1_slice_total + mask2_slice_total < 1:\n",
    "                continue\n",
    "\n",
    "            untested_overlaps_with_ship_masks.append((img1_id, img2_id, img1_overlap_tag))\n",
    "\n",
    "len(overlap_image_maps), len(untested_overlaps_with_ship_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlapping images using hashlib\n",
    "Update: The values between two supposedly exact 256x256 crops are not exact (See below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md5hash_dict = defaultdict(list)\n",
    "img_ids = os.listdir(train_image_dir)\n",
    "\n",
    "for img_id in tqdm_notebook(img_ids):\n",
    "    for h in sdcic.tile_md5hash_grids[img_id]:\n",
    "        md5hash_dict[h].append(img_id)\n",
    "\n",
    "dup_counts_dict = defaultdict(int)\n",
    "for key, dups in md5hash_dict.items():\n",
    "    dup_counts_dict[len(dups)] += 1\n",
    "\n",
    "sorted_bin_sizes = sorted(dup_counts_dict.items())\n",
    "sorted_bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 9\n",
    "skip = 365\n",
    "ii = 0\n",
    "jj = 0\n",
    "batch_limit = 9\n",
    "samples_images = np.empty((batch_limit, 768, 768, 3), dtype=np.float32)\n",
    "\n",
    "for hash_id, dups in md5hash_dict.items():\n",
    "    ii += 1\n",
    "    if len(dups) == batch_size:\n",
    "        dups0 = list(set(dups))\n",
    "        img_id = dups0[0]\n",
    "        idx = sdcic.tile_md5hash_grids[img_id].index(hash_id)\n",
    "        print(hash_id, len(dups), ii, sdcic.tile_entropy_grids[img_id][idx])\n",
    "        if jj == min(dup_counts_dict[len(dups)], skip):\n",
    "            break\n",
    "        jj += 1\n",
    "\n",
    "for i, c_img_id in enumerate(dups0[:batch_limit]):\n",
    "    c_img = cv2.cvtColor(sdcic.get_img(c_img_id), cv2.COLOR_BGR2RGB)\n",
    "    samples_images[i] = c_img.astype(np.float32) / 255.0\n",
    "\n",
    "batch_rgb = montage_rgb(samples_images)\n",
    "print(samples_images.shape)\n",
    "print(batch_rgb.shape, batch_rgb.dtype)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16, 16))\n",
    "ax.imshow(batch_rgb, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "# plt.savefig(os.path.join('out', BASE_MODEL, f\"{train_meta_filebase}_{score_str}_batch_{BATCH_NUM}.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlapping images using cv2.img_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm0hash_dict = defaultdict(list)\n",
    "img_ids = os.listdir(train_image_dir)\n",
    "\n",
    "for img_id in tqdm_notebook(img_ids):\n",
    "    for h in sdcic.tile_bm0hash_grids[img_id]:\n",
    "        bm0hash_dict[tuple(h)].append(img_id)  # hex\n",
    "\n",
    "dup_counts_dict = defaultdict(int)\n",
    "for key, dups in bm0hash_dict.items():\n",
    "    dup_counts_dict[len(dups)] += 1\n",
    "\n",
    "sorted_bin_sizes = sorted(dup_counts_dict.items())\n",
    "sorted_bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 18\n",
    "skip = 5\n",
    "ii = 0\n",
    "jj = 0\n",
    "batch_limit = 9\n",
    "samples_images = np.empty((batch_limit, 768, 768, 3), dtype=np.float32)\n",
    "\n",
    "for hash_id, dups in bm0hash_dict.items():\n",
    "    ii += 1\n",
    "    if len(dups) == batch_size:\n",
    "        dups0 = list(set(dups))\n",
    "        img_id = dups0[0]\n",
    "        idx = sdcic.tile_bm0hash_grids[img_id].index(hash_id)\n",
    "        print(hash_id, len(dups), ii, sdcic.tile_entropy_grids[img_id][idx])\n",
    "        if jj == min(dup_counts_dict[len(dups)], skip):\n",
    "            break\n",
    "        jj += 1\n",
    "\n",
    "for i, c_img_id in enumerate(dups0[:batch_limit]):\n",
    "    c_img = cv2.cvtColor(sdcic.get_img(c_img_id), cv2.COLOR_BGR2RGB)\n",
    "    samples_images[i] = c_img.astype(np.float32) / 255.0\n",
    "\n",
    "batch_rgb = montage_rgb(samples_images)\n",
    "print(samples_images.shape)\n",
    "print(batch_rgb.shape, batch_rgb.dtype)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16, 16))\n",
    "ax.imshow(batch_rgb, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "# plt.savefig(os.path.join('out', BASE_MODEL, f\"{train_meta_filebase}_{score_str}_batch_{BATCH_NUM}.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we explore dup detection using image gradients and cross entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_lim0 = 0\n",
    "score_lim1 = 1\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    if img1_id > img2_id:\n",
    "        # sanity check\n",
    "        raise ValueError(f'img1_id ({img1_id}) should be lexicographically smaller than img2_id ({img2_id})')\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) not in dup_truth:\n",
    "            continue\n",
    "        \n",
    "        is_dup = dup_truth[(img1_id, img2_id, img1_overlap_tag)]\n",
    "\n",
    "        if is_dup == 0 and np.max(scores.enp) > score_lim0:\n",
    "            score_lim0 = np.max(scores.enp)\n",
    "            print_score = True\n",
    "        elif is_dup == 1 and np.max(scores.enp) < score_lim1:\n",
    "            score_lim1 = np.max(scores.enp)\n",
    "            print_score = True\n",
    "        else:\n",
    "            print_score = False\n",
    "\n",
    "        if print_score:\n",
    "            img1_entropy_vec = get_entropy(img1_id)\n",
    "            img2_entropy_vec = get_entropy(img2_id)\n",
    "            img1_entropy_vec_norm = np.linalg.norm(img1_entropy_vec)\n",
    "            img2_entropy_vec_norm = np.linalg.norm(img2_entropy_vec)\n",
    "            n_vec = np.max([img1_entropy_vec_norm, img2_entropy_vec_norm])\n",
    "            img1_scaled_vec = img1_entropy_vec / n_vec\n",
    "            img2_scaled_vec = img2_entropy_vec / n_vec\n",
    "            grad_score = 1.0 - np.linalg.norm(img1_scaled_vec - img2_scaled_vec)\n",
    "\n",
    "            entropy2 = get_entropy2(img1_id, img2_id)\n",
    "            entropy2_norm = np.linalg.norm(entropy2)\n",
    "            \n",
    "            print('')\n",
    "            print(f\"{is_dup}, {min(scores.bmh):7.5f}, {min(scores.cmh):7.5f}, {grad_score:7.5f}, {entropy2_norm}\")\n",
    "            print(img1_id, img1_entropy_vec, f\"{img1_entropy_vec_norm}\")\n",
    "            print(img2_id, img2_entropy_vec, f\"{img2_entropy_vec_norm}\")\n",
    "            print(get_entropy(img1_id))\n",
    "            print(get_entropy(img2_id))\n",
    "            print(entropy2)\n",
    "            print(np.max(scores.enp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_id = '691d5afc2.jpg'\n",
    "img2_id = '56417e7af.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_entropy_vec = get_entropy(img1_id)\n",
    "img2_entropy_vec = get_entropy(img2_id)\n",
    "img1_entropy_vec_norm = np.linalg.norm(img1_entropy_vec)\n",
    "img2_entropy_vec_norm = np.linalg.norm(img2_entropy_vec)\n",
    "n_vec = np.max([img1_entropy_vec_norm, img1_entropy_vec_norm])\n",
    "img1_scaled_vec = img1_entropy_vec / n_vec\n",
    "img2_scaled_vec = img2_entropy_vec / n_vec\n",
    "print('')\n",
    "print(img1_id, img1_entropy_vec, f\"{img1_entropy_vec_norm}\")\n",
    "print(img2_id, img2_entropy_vec, f\"{img1_entropy_vec_norm}\")\n",
    "print(f\"{np.linalg.norm(img1_scaled_vec - img2_scaled_vec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dup_blacklist_6.csv', sep=', ')\n",
    "for idx, row in df.iterrows():\n",
    "    print(idx)\n",
    "    img1_entropy_vec = get_entropy(row['ImageId1'])\n",
    "    img1_entropy_vec_u = img1_entropy_vec / np.linalg.norm(img1_entropy_vec)\n",
    "    print(row['ImageId1'], img1_entropy_vec)\n",
    "    img2_entropy_vec = get_entropy(row['ImageId2'])\n",
    "    img2_entropy_vec_u = img2_entropy_vec / np.linalg.norm(img2_entropy_vec)\n",
    "    print(row['ImageId2'], img2_entropy_vec)\n",
    "    print(np.dot(img1_entropy_vec_u, img2_entropy_vec_u), np.linalg.norm(img1_entropy_vec - img2_entropy_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search for reasonable thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh_scores = defaultdict()\n",
    "cmh_scores = defaultdict()\n",
    "pix_scores = defaultdict(int)\n",
    "\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    if img1_id > img2_id:\n",
    "        # sanity check\n",
    "        raise ValueError(f'img1_id ({img1_id}) should be lexicographically smaller than img2_id ({img2_id})')\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "\n",
    "        for i in range(len(scores.bmh)):\n",
    "            idx = (img1_id, img2_id, img1_overlap_tag, i)\n",
    "            bmh_scores[idx] = scores.bmh[i]\n",
    "            cmh_scores[idx] = scores.cmh[i]\n",
    "            pix_scores[idx] = scores.pix[i]\n",
    "\n",
    "overlap_scores_df = pd.DataFrame()\n",
    "overlap_scores_df['bmh'] = pd.Series(bmh_scores)\n",
    "overlap_scores_df['cmh'] = pd.Series(cmh_scores)\n",
    "overlap_scores_df['pix'] = pd.Series(pix_scores)\n",
    "\n",
    "overlap_scores_df.describe(percentiles=[.01, .05, .1, .25, .5, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh_arr = []\n",
    "cmh_arr = []\n",
    "con_arr = []\n",
    "hom_arr = []\n",
    "eng_arr = []\n",
    "cor_arr = []\n",
    "epy_arr = []\n",
    "enp_arr = []\n",
    "pix_arr = []\n",
    "\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "\n",
    "        bmh_arr += list(scores.bmh)\n",
    "        cmh_arr += list(scores.cmh)\n",
    "        con_arr += list(scores.con)\n",
    "        hom_arr += list(scores.hom)\n",
    "        eng_arr += list(scores.eng)\n",
    "        cor_arr += list(scores.cor)\n",
    "        epy_arr += list(scores.epy)\n",
    "        enp_arr += list(scores.enp)\n",
    "        pix_arr += list(scores.pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_limits_df = pd.DataFrame()\n",
    "overlap_limits_df['bmh'] = pd.Series(bmh_arr)\n",
    "overlap_limits_df['cmh'] = pd.Series(cmh_arr)\n",
    "overlap_limits_df['con'] = pd.Series(con_arr)\n",
    "overlap_limits_df['hom'] = pd.Series(hom_arr)\n",
    "overlap_limits_df['eng'] = pd.Series(eng_arr)\n",
    "overlap_limits_df['cor'] = pd.Series(cor_arr)\n",
    "overlap_limits_df['epy'] = pd.Series(epy_arr)\n",
    "overlap_limits_df['enp'] = pd.Series(enp_arr)\n",
    "overlap_limits_df['pix'] = pd.Series(pix_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_limits_df.describe(percentiles=[.001, .01, .02, .05, .1, .5, .9, .95, .98, .99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  |-----|--------------|-----|\n",
    "# min  lower          upper  max\n",
    "\n",
    "metric_tags = ['bmh', 'cmh', 'con', 'hom', 'eng', 'cor', 'epy', 'enp', 'pix']\n",
    "Overlap_Scores_Lower_Limit = namedtuple('overlap_scores_lower_limit', metric_tags)\n",
    "Overlap_Scores_Upper_Limit = namedtuple('overlap_scores_upper_limit', metric_tags)\n",
    "\n",
    "osl_lower = Overlap_Scores_Lower_Limit(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 50)\n",
    "osl_upper = Overlap_Scores_Upper_Limit(0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 4500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "Overlap_Idx_Scores = namedtuple('overlap_idx_scores', [\n",
    "    'idx', \n",
    "    'bmh_min', 'cmh_min', 'con_min', 'hom_min', 'eng_min', 'cor_min', 'epy_min', 'enp_min', 'pix_min', \n",
    "    'bmh_max', 'cmh_max', 'con_max', 'hom_max', 'eng_max', 'cor_max', 'epy_max', 'enp_max', 'pix_max'])\n",
    "\n",
    "bmh_min_hits = 0\n",
    "cmh_min_hits = 0\n",
    "con_min_hits = 0\n",
    "hom_min_hits = 0\n",
    "eng_min_hits = 0\n",
    "cor_min_hits = 0\n",
    "epy_min_hits = 0\n",
    "enp_min_hits = 0\n",
    "pix_min_hits = 0\n",
    "\n",
    "bmh_max_hits = 0\n",
    "cmh_max_hits = 0\n",
    "con_max_hits = 0\n",
    "hom_max_hits = 0\n",
    "eng_max_hits = 0\n",
    "cor_max_hits = 0\n",
    "epy_max_hits = 0\n",
    "enp_max_hits = 0\n",
    "pix_max_hits = 0\n",
    "\n",
    "flat_score_good = 0\n",
    "flat_score_bad = 0\n",
    "print_first_good = True\n",
    "print_first_bad = True\n",
    "tst1_ct = 0\n",
    "tst2_ct = 0\n",
    "tst3_ct = 0\n",
    "tst4_ct = 0\n",
    "tst5_ct = 0\n",
    "tst6_ct = 0\n",
    "tst7_ct = 0\n",
    "tst1 = False\n",
    "tst2 = False\n",
    "tst3 = False\n",
    "tst4 = False\n",
    "tst5 = False\n",
    "tst6 = False\n",
    "tst7 = False\n",
    "n_not_dups = 0\n",
    "\n",
    "overlap_candidates = []\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            \n",
    "#             if max(scores.pix) > 256*256*3*255 * 0.5:\n",
    "#                 continue\n",
    "            continue\n",
    "            is_dup = dup_truth[(img1_id, img2_id, img1_overlap_tag)]\n",
    "            \n",
    "            img1_nine, img2_nine = image_image_duplicate_tiles[(img1_id, img2_id)]\n",
    "            img1_mask = img1_nine[overlap_tag_nines_mask[img1_overlap_tag]]\n",
    "            img2_mask = img2_nine[overlap_tag_nines_mask[overlap_tag_pairs[img1_overlap_tag]]]\n",
    "            \n",
    "            img1_match_indices = np.where(img1_mask != 9)[0]\n",
    "            img2_match_indices = np.where(img2_mask != 9)[0]\n",
    "            img12_match_indices = np.intersect1d(img1_match_indices, img2_match_indices)\n",
    "            \n",
    "#             if len(img12_match_indices) == 0:\n",
    "#                 continue\n",
    "                \n",
    "            tst1 = np.any(img1_mask != img2_mask)\n",
    "            tst2 = max(scores.pix) > 10000\n",
    "            tst3 = np.all(img1_mask == img2_mask)\n",
    "            tst4 = max(scores.pix) > 100000\n",
    "#             tst5 = sum(scores.pyr[img12_match_indices]) == len(img12_match_indices)\n",
    "            tst6 = len(img12_match_indices) > 0\n",
    "            \n",
    "            if not is_dup:\n",
    "                n_not_dups += 1\n",
    "                if tst1:\n",
    "                    tst1_ct += 1\n",
    "                if tst2:\n",
    "                    tst2_ct += 1\n",
    "                if tst3:\n",
    "                    tst3_ct += 1\n",
    "                if tst4:\n",
    "                    tst4_ct += 1\n",
    "                if tst5:\n",
    "                    tst5_ct += 1\n",
    "                if tst6:\n",
    "                    tst6_ct += 1\n",
    "                \n",
    "            if tst1:\n",
    "                if is_dup:\n",
    "                    flat_score_bad += 1\n",
    "                    if print_first_bad:\n",
    "        \n",
    "                        print('hit1: bad', is_dup)\n",
    "                        print((img1_id, img2_id, img1_overlap_tag))\n",
    "                        print(img1_mask)\n",
    "                        print(img2_mask)\n",
    "                        print(img12_match_indices)\n",
    "                        print(img1_mask[img12_match_indices])\n",
    "                        print(scores.pyr)\n",
    "                        print(scores.pix)\n",
    "                        print_first_bad = False\n",
    "                else:\n",
    "                    flat_score_good += 1\n",
    "#                 continue\n",
    "                \n",
    "            if tst3 and tst4 and tst6:\n",
    "                if is_dup:\n",
    "                    flat_score_bad += 1\n",
    "                    if print_first_bad:\n",
    "        \n",
    "                        print('hit2: bad', is_dup)\n",
    "                        print((img1_id, img2_id, img1_overlap_tag))\n",
    "                        print(img1_mask)\n",
    "                        print(img2_mask)\n",
    "                        print(img12_match_indices)\n",
    "                        print(img1_mask[img12_match_indices])\n",
    "                        print(scores.pyr)\n",
    "                        print(scores.pix)\n",
    "                        print_first_bad = False\n",
    "                else:\n",
    "                    flat_score_good += 1\n",
    "#                 continue\n",
    "                \n",
    "            if tst5 and tst2 and tst6:\n",
    "                if is_dup:\n",
    "                    flat_score_bad += 1\n",
    "                    if print_first_bad:\n",
    "        \n",
    "                        print('hit3: bad', is_dup)\n",
    "                        print((img1_id, img2_id, img1_overlap_tag))\n",
    "                        print(img1_mask)\n",
    "                        print(img2_mask)\n",
    "                        print(img12_match_indices)\n",
    "                        print(img1_mask[img12_match_indices])\n",
    "                        print(scores.pyr)\n",
    "                        print(scores.pix)\n",
    "                        print_first_bad = False\n",
    "                else:\n",
    "                    flat_score_good += 1\n",
    "                    if print_first_good:\n",
    "        \n",
    "                        print('hit: good', is_dup)\n",
    "                        print((img1_id, img2_id, img1_overlap_tag))\n",
    "                        print(img1_mask)\n",
    "                        print(img2_mask)\n",
    "                        print(img12_match_indices)\n",
    "                        print(img1_mask[img12_match_indices])\n",
    "                        print(scores.pyr)\n",
    "                        print(scores.pix)\n",
    "                        print_first_good = False\n",
    "                \n",
    "#             continue\n",
    "\n",
    "    # This is here so I don't forget to address small 2 tile or 1 tile overlaps later.\n",
    "#     if len(img1_mask) <= 2:\n",
    "#         print(img1_mask, img2_mask)\n",
    "#         continue\n",
    "    \n",
    "    # (0, 3, 6) == (0, 3, 6) is exact duplicate\n",
    "#     if len(set(img1_mask)) == len(img1_mask) and np.all(img1_mask == img2_mask) and 9 not in img1_mask:\n",
    "#         continue\n",
    "    \n",
    "    # (0, 0, 0) == (0, 0, 0) skip probably is duplicate of white clouds, or blue border.\n",
    "#     if len(set(img1_mask) | set(img2_mask)) == 1 and 9 not in img1_mask:\n",
    "#         continue\n",
    "    \n",
    "    # (0, 0, 0) == (2, 2, 2) is NOT duplicate. probably white clouds overlap with blue boarder\n",
    "#     if len(set(img1_mask)) == 1 and len(set(img2_mask)) == 1 and set(img1_mask) != set(img2_mask) and 9 not in img1_mask and 9 not in img2_mask:\n",
    "#         continue\n",
    "        \n",
    "#     if len(set(img1_mask)) == 1 and len(set(img2_mask)) != 1 and 9 not in img1_mask:\n",
    "#         if set(img1_mask) != set(img2_mask):\n",
    "#         continue\n",
    "    \n",
    "#     if np.min(scores.enp) <= 0.995 or np.min(scores.enp) >= 0.999:\n",
    "#         continue\n",
    "\n",
    "        constraint_hits = 0\n",
    "        \n",
    "        bmh_min = np.min(scores.bmh)\n",
    "        if bmh_min < osl_lower.bmh:\n",
    "            bmh_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        cmh_min = np.min(scores.cmh)\n",
    "        if cmh_min < osl_lower.cmh:\n",
    "            cmh_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        con_min = np.min(scores.con)\n",
    "        if con_min < osl_lower.con:\n",
    "            con_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        hom_min = np.min(scores.hom)\n",
    "        if hom_min < osl_lower.hom:\n",
    "            hom_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        eng_min = np.min(scores.eng)\n",
    "        if eng_min < osl_lower.eng:\n",
    "            eng_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        cor_min = np.min(scores.cor)\n",
    "        if cor_min < osl_lower.cor:\n",
    "            cor_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        epy_min = np.min(scores.epy)\n",
    "        if epy_min < osl_lower.epy:\n",
    "            epy_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        enp_min = np.min(scores.enp)\n",
    "        if enp_min < osl_lower.enp:\n",
    "            enp_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        pix_min = np.min(scores.pix)\n",
    "        if pix_min < osl_lower.pix:\n",
    "            pix_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "            \n",
    "        bmh_max = np.max(scores.bmh)\n",
    "        if bmh_max > osl_upper.bmh:\n",
    "            bmh_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        cmh_max = np.max(scores.cmh)\n",
    "        if cmh_max > osl_upper.cmh:\n",
    "            cmh_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        con_max = np.max(scores.con)\n",
    "        if con_max > osl_upper.con:\n",
    "            con_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        hom_max = np.max(scores.hom)\n",
    "        if hom_max > osl_upper.hom:\n",
    "            hom_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        eng_max = np.max(scores.eng)\n",
    "        if eng_max > osl_upper.eng:\n",
    "            eng_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        cor_max = np.max(scores.cor)\n",
    "        if cor_max > osl_upper.cor:\n",
    "            cor_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        epy_max = np.max(scores.epy)\n",
    "        if epy_max > osl_upper.epy:\n",
    "            epy_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        enp_max = np.max(scores.enp)\n",
    "        if enp_max > osl_upper.enp:\n",
    "            enp_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        pix_max = np.max(scores.pix)\n",
    "        if pix_max > osl_upper.pix:\n",
    "            pix_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        if constraint_hits < 0:\n",
    "            continue\n",
    "            \n",
    "        idx = (img1_id, img2_id, img1_overlap_tag)\n",
    "        overlap_scores = Overlap_Idx_Scores(\n",
    "            idx, \n",
    "            bmh_min, cmh_min, con_min, hom_min, eng_min, cor_min, epy_min, enp_min, pix_min, \n",
    "            bmh_max, cmh_max, con_max, hom_max, eng_max, cor_max, epy_max, enp_max, pix_max)\n",
    "        overlap_candidates.append(overlap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print(len(overlap_candidates))\n",
    "print(bmh_min_hits, cmh_min_hits, con_min_hits, hom_min_hits, eng_min_hits, cor_min_hits, epy_min_hits, enp_min_hits, pix_min_hits)\n",
    "print(bmh_max_hits, cmh_max_hits, con_max_hits, hom_max_hits, eng_max_hits, cor_max_hits, epy_max_hits, enp_max_hits, pix_max_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dup_truth), n_not_dups, flat_score_good, flat_score_bad)\n",
    "print(tst1_ct, tst2_ct, tst3_ct, tst4_ct, tst5_ct, tst6_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_candidates = []\n",
    "for overlap_candidate in tqdm_notebook(sorted(overlap_candidates, key=operator.attrgetter('con_max', 'pix_max'), reverse=True)):\n",
    "    duplicate_candidates.append(overlap_candidate.idx)\n",
    "print(len(duplicate_candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an interactive widget for tagging duplicate overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import Button, Image, Layout, Box, HBox, VBox, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_iter = iter(duplicate_candidates)\n",
    "n_candidates = len(duplicate_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "img1_id = None\n",
    "img2_id = None\n",
    "img1_overlap_tag = None\n",
    "candidates_idx = 0\n",
    "box_layout = Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    align_items='stretch',\n",
    "                    width='100%')\n",
    "\n",
    "RED = (244, 67, 54) #F44336 \n",
    "GREEN = (76, 175, 80) #4CAF50 \n",
    "LIGHT_BLUE = (3, 169, 244) #03A9F4\n",
    "\n",
    "\n",
    "def get_next_img_pair():\n",
    "    global img1_id, img2_id, img1_overlap_tag, candidates_idx\n",
    "    n_skip = 0\n",
    "    i_skip = 0\n",
    "    while True:\n",
    "        img1_id, img2_id, img1_overlap_tag = next(candidates_iter)\n",
    "        candidates_idx += 1\n",
    "        \n",
    "        if i_skip < n_skip:\n",
    "            i_skip += 1\n",
    "            continue\n",
    "            \n",
    "        assert img1_id < img2_id\n",
    "        \n",
    "        if (img1_id, img2_id, img1_overlap_tag) in overlap_labels:\n",
    "            continue\n",
    "        \n",
    "#         if (img1_id, img2_id, img1_overlap_tag) in weak_preds:\n",
    "#             break\n",
    "#         else:\n",
    "#             continue\n",
    "        \n",
    "        scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "        \n",
    "        if max(scores.pix) > 256*256*3*255 * 0.33:\n",
    "            overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "            continue\n",
    "        \n",
    "        img1_nine, img2_nine = image_image_duplicate_tiles[(img1_id, img2_id)]\n",
    "        img1_mask = img1_nine[overlap_tag_nines_mask[img1_overlap_tag]]\n",
    "        img2_mask = img2_nine[overlap_tag_nines_mask[overlap_tag_pairs[img1_overlap_tag]]]\n",
    "\n",
    "        img1_match_indices = np.where(img1_mask != 9)[0]\n",
    "        img2_match_indices = np.where(img2_mask != 9)[0]\n",
    "        img12_match_indices = np.intersect1d(img1_match_indices, img2_match_indices)\n",
    "        \n",
    "        tst1 = np.any(img1_mask != img2_mask)\n",
    "        tst2 = max(scores.pix) > 10000\n",
    "        tst3 = np.all(img1_mask == img2_mask)\n",
    "        tst4 = max(scores.pix) > 100000\n",
    "        tst6 = len(img12_match_indices) > 0\n",
    "        tst7 = len(np.union1d(img1_mask[img1_match_indices], img2_mask[img2_match_indices])) == 1\n",
    "        tst8 = max(scores.pix) == 0\n",
    "        \n",
    "#         if tst1:\n",
    "#             overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "#             continue\n",
    "\n",
    "#         if tst3 and tst4 and tst6:\n",
    "#             overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "#             continue\n",
    "\n",
    "#         if tst7 and tst8: # perfect white on white\n",
    "#             continue\n",
    "\n",
    "        break\n",
    "\n",
    "    return img1_id, img2_id, img1_overlap_tag\n",
    "\n",
    "def draw_images(img1_id, img2_id, img1_overlap_tag):\n",
    "    global candidates_idx\n",
    "    \n",
    "    scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "    \n",
    "    dtick = 256\n",
    "    n_ticks = imgmod1.shape[1] // dtick + 1\n",
    "    ticks = [i * dtick for i in range(n_ticks)]\n",
    "\n",
    "    slice1 = overlap_tag_slices[img1_overlap_tag]\n",
    "    slice2 = overlap_tag_slices[overlap_tag_pairs[img1_overlap_tag]]\n",
    "\n",
    "    m12 = np.median(np.vstack([imgmod1.parent_rgb[slice1], imgmod2.parent_rgb[slice2]]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "    img1_drop = imgmod1.parent_rgb - m12\n",
    "    img2_drop = imgmod2.parent_rgb - m12\n",
    "        \n",
    "    brightness_level = -100 if np.sum(m12) >= 384 else 100\n",
    "    img1 = imgmod1.channel_shift('L', brightness_level)\n",
    "    img2 = imgmod2.channel_shift('L', brightness_level)\n",
    "    \n",
    "    img1_nine, img2_nine = image_image_duplicate_tiles[(img1_id, img2_id)]\n",
    "    img1_mask = img1_nine[overlap_tag_nines_mask[img1_overlap_tag]]\n",
    "    img2_mask = img2_nine[overlap_tag_nines_mask[overlap_tag_pairs[img1_overlap_tag]]]\n",
    "    img1_dups_str = ' '.join(list(map(str, img1_mask)))\n",
    "    img2_dups_str = ' '.join(list(map(str, img2_mask)))\n",
    "    \n",
    "    if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "        bbox_color = GREEN if dup_truth[(img1_id, img2_id, img1_overlap_tag)] else RED\n",
    "    else:\n",
    "        bbox_color = LIGHT_BLUE\n",
    "        \n",
    "    bbox_thickness = 4\n",
    "    offset = (bbox_thickness // 2) + 1\n",
    "    offset_array = np.array([[offset], [-offset]])\n",
    "    img1_bbox_pt1, img1_bbox_pt2 = boundingbox_corners[img1_overlap_tag] + offset_array\n",
    "    img2_bbox_pt1, img2_bbox_pt2 = boundingbox_corners[overlap_tag_pairs[img1_overlap_tag]] + offset_array\n",
    "    \n",
    "    img1[slice1] = img1_drop[slice1]\n",
    "    img2[slice2] = img2_drop[slice2]\n",
    "    cv2.rectangle(img1, tuple(img1_bbox_pt1), tuple(img1_bbox_pt2), bbox_color, bbox_thickness)\n",
    "    cv2.rectangle(img2, tuple(img2_bbox_pt1), tuple(img2_bbox_pt2), bbox_color, bbox_thickness)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    ax[0][0].imshow(img1)\n",
    "#     ax[0][0].set_title(f'{candidates_idx/n_candidates:6.3f} {img1_id} {min(scores.bmh):7.5f}')\n",
    "    ax[0][0].set_title(f'{img1_id} {min(scores.bmh):7.5f} {min(scores.cmh):7.5f}')\n",
    "    ax[0][0].set_xticks(ticks)\n",
    "    ax[0][0].set_yticks(ticks)\n",
    "\n",
    "    ax[0][1].imshow(img2)\n",
    "    ax[0][1].set_title(f'{img2_id} con: {min(scores.con):7.5f} {max(scores.con):7.5f}')\n",
    "    ax[0][1].set_xticks(ticks)\n",
    "    ax[0][1].set_yticks(ticks)\n",
    "    \n",
    "    img1[slice1] = imgmod1.parent_rgb[slice1]\n",
    "    img2[slice2] = imgmod2.parent_rgb[slice2]\n",
    "    cv2.rectangle(img1, tuple(img1_bbox_pt1), tuple(img1_bbox_pt2), bbox_color, bbox_thickness)\n",
    "    cv2.rectangle(img2, tuple(img2_bbox_pt1), tuple(img2_bbox_pt2), bbox_color, bbox_thickness)\n",
    "\n",
    "    ax[1][0].imshow(img1)\n",
    "    ax[1][0].set_title(f'({img1_dups_str}) hom: {np.min(scores.hom):7.5f} {np.max(scores.hom):7.5f}')\n",
    "    ax[1][0].set_xticks(ticks)\n",
    "    ax[1][0].set_yticks(ticks)\n",
    "\n",
    "    ax[1][1].imshow(img2)\n",
    "    ax[1][1].set_title(f'({img2_dups_str}) eng: {np.min(scores.eng):7.5f} {np.max(scores.eng):7.5f}')# {max(scores.pix)}')\n",
    "    ax[1][1].set_xticks(ticks)\n",
    "    ax[1][1].set_yticks(ticks)\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "def redraw(img1_id, img2_id, img1_overlap_tag):\n",
    "    out.clear_output(True)\n",
    "    with out:\n",
    "        ax = draw_images(img1_id, img2_id, img1_overlap_tag)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_button = Button(\n",
    "    description='Same',\n",
    "    disabled=False,\n",
    "    layout=Layout(flex='1 1 auto', width='auto'), \n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Overlays are the same',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "diff_button = Button(\n",
    "    description='Diff',\n",
    "    disabled=False,\n",
    "    layout=Layout(flex='1 1 auto', width='auto'), \n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Overlays are different',\n",
    "    icon='x'\n",
    ")\n",
    "\n",
    "skip_button = Button(\n",
    "    description='Skip',\n",
    "    disabled=False,\n",
    "    layout=Layout(flex='1 1 auto', width='auto'), \n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Not sure.  Skip for now.',\n",
    "    icon='?'\n",
    ")\n",
    "\n",
    "def on_same_button_clicked(b):\n",
    "    global img1_id, img2_id, img1_overlap_tag\n",
    "    overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = 1\n",
    "    img1_id, img2_id, img1_overlap_tag = get_next_img_pair()\n",
    "    redraw(img1_id, img2_id, img1_overlap_tag)\n",
    "    \n",
    "def on_diff_button_clicked(b):\n",
    "    global img1_id, img2_id, img1_overlap_tag\n",
    "    overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "    img1_id, img2_id, img1_overlap_tag = get_next_img_pair()\n",
    "    redraw(img1_id, img2_id, img1_overlap_tag)\n",
    "    \n",
    "def on_skip_button_clicked(b):\n",
    "    global img1_id, img2_id, img1_overlap_tag\n",
    "    img1_id, img2_id, img1_overlap_tag = get_next_img_pair()\n",
    "    redraw(img1_id, img2_id, img1_overlap_tag)\n",
    "\n",
    "same_button.on_click(on_same_button_clicked)\n",
    "diff_button.on_click(on_diff_button_clicked)\n",
    "skip_button.on_click(on_skip_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = Output()\n",
    "buttons_3 = Box(children=[same_button, diff_button, skip_button], layout=box_layout)\n",
    "display(VBox([out, buttons_3]))\n",
    "\n",
    "img1_id, img2_id, img1_overlap_tag = get_next_img_pair()\n",
    "with out:\n",
    "    ax = draw_images(img1_id, img2_id, img1_overlap_tag)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print details of current iteration\n",
    "scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print our progress\n",
    "len(overlap_labels), 100*len(overlap_labels)/len(duplicate_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undo last\n",
    "for k in overlap_labels:\n",
    "    continue\n",
    "print(k)\n",
    "del overlap_labels[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge overlap_labels into truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_duplicate_truth(duplicate_truth_file, overlap_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After we create image_duplicate_tiles.txt, lets check to see how many duplicate tiles we actually have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_duplicate_tiles = read_image_duplicate_tiles(image_duplicate_tiles_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_tiles = []\n",
    "dup_hashes = {}\n",
    "dup_files = []\n",
    "dup_counts = {}\n",
    "for img_id, img_dup9 in sdcic.image_duplicate_tiles.items():\n",
    "    img = None\n",
    "    c0 = Counter(img_dup9)\n",
    "    for i, c in c0.items():\n",
    "        if c == 1:\n",
    "            continue\n",
    "        for ii in np.where(img_dup9 == i)[0]:\n",
    "            new_hash = sdcic.tile_md5hash_grids[img_id][ii]\n",
    "            if new_hash in dup_hashes:\n",
    "                dup_counts[new_hash] += 1\n",
    "                if img_id not in dup_hashes[new_hash]:\n",
    "                    dup_hashes[new_hash][img_id] = []\n",
    "                dup_hashes[new_hash][img_id].append(ii)\n",
    "            else:\n",
    "                dup_counts[new_hash] = 1\n",
    "                dup_hashes[new_hash] = {}\n",
    "                dup_hashes[new_hash][img_id] = []\n",
    "                dup_hashes[new_hash][img_id].append(ii)\n",
    "                dup_files.append(img_id)\n",
    "                img = sdcic.get_img(img_id)\n",
    "                new_tile = sdcic.get_tile(img, ii)\n",
    "                dup_tiles.append(new_tile)\n",
    "                print(len(dup_files)-1, new_hash, img_id, ii)\n",
    "dup_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ii, dup_tile in enumerate(dup_tiles):\n",
    "    print(ii)\n",
    "    print(dup_tile[2, 2], dup_tile[2, -2])\n",
    "    print(dup_tile[-2, 2], dup_tile[-2, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "img1 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[0])), cv2.COLOR_BGR2RGB)\n",
    "ax1.imshow(img1)\n",
    "img2 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[5])), cv2.COLOR_BGR2RGB)\n",
    "ax2.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "img1 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[1])), cv2.COLOR_BGR2RGB)\n",
    "ax1.imshow(img1)\n",
    "img2 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[2])), cv2.COLOR_BGR2RGB)\n",
    "ax2.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "img1 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[3])), cv2.COLOR_BGR2RGB)\n",
    "ax1.imshow(img1)\n",
    "img2 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[4])), cv2.COLOR_BGR2RGB)\n",
    "ax2.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_tile = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "white_tile = black_tile + 255\n",
    "blue_tile = np.copy(black_tile) \n",
    "blue_tile[:, :, 0] = 255\n",
    "red_tile = np.copy(black_tile) \n",
    "red_tile[:, :, 2] = 255\n",
    "color_tiles = [black_tile, white_tile, blue_tile, red_tile]\n",
    "for color_tile in color_tiles:\n",
    "    print(img_hash.blockMeanHash(color_tile, mode=0)[0])\n",
    "    print(hashlib.md5(color_tile.tobytes()).hexdigest())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_images = ['03ffa7680.jpg', '8d5521663.jpg', '5a70ef013.jpg', '9a2f9d347.jpg', '37a912dca.jpg', '4add7aa1d.jpg', '3db3ef7cc.jpg', '73fec0637.jpg', '7df214d98.jpg', 'c2955cd21.jpg', 'de018b2a8.jpg', '8ce769141.jpg', 'fc0e22a0a.jpg', '770c46cd4.jpg', 'd6e432b79.jpg', 'd5d1b6fb8.jpg', '0e4d7dd93.jpg', '9ddeed533.jpg', 'addc11de0.jpg', '65418dfe4.jpg', '119d6a3d6.jpg', '1b287c905.jpg', 'b264b0f96.jpg', '996f92939.jpg', 'e5c3b1f59.jpg']\n",
    "fig, ax = plt.subplots(5, 5, figsize=(15, 15))\n",
    "for i, img_id in enumerate(black_images):\n",
    "    img = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, img_id)), cv2.COLOR_BGR2RGB)\n",
    "    ax[i // 5, i % 5].imshow(img)\n",
    "    ax[i // 5, i % 5].set_title(img_id)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the performance of DupNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = []\n",
    "tile_pairs = []\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in tqdm_notebook(dup_truth.items()):\n",
    "    for overlap_idx, (idx1, idx2) in enumerate(img_overlap_index_maps[img1_overlap_tag]):\n",
    "        tile_pairs.append(TilePairs(img1_id, img2_id, img1_overlap_tag, overlap_idx, idx1, idx2))\n",
    "        ytrue.append(is_dup)\n",
    "print(len(tile_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(tile_pairs)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=256, num_workers=12)\n",
    "test_dl = WrappedDataLoader(test_dl, preprocess)\n",
    "print(len(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint('out/dup_model.last.pth')\n",
    "model.cuda()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yprobs0 = [model(xb) for xb in tqdm_notebook(test_dl)]\n",
    "    yprobs = np.vstack([l.cpu() for l in yprobs0]).reshape(-1)\n",
    "print(len(yprobs0), yprobs.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_cnn_tile_scores = {}\n",
    "for tp, yprob in zip(tile_pairs, yprobs):\n",
    "    if (tp.img1_id, tp.img2_id) not in overlap_cnn_tile_scores:\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)] = {}\n",
    "    \n",
    "    if tp.img1_overlap_tag not in overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)]:\n",
    "        cnn_scores = np.zeros(len(img_overlap_index_maps[tp.img1_overlap_tag]))\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag] = cnn_scores\n",
    "    \n",
    "    overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag][tp.overlap_idx] = yprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_Stats = namedtuple('dnn_stats', ['yprob', 'ypred', 'ytrue', 'loss'])\n",
    "\n",
    "ii = 1\n",
    "dup_dict = {}\n",
    "for (img1_id, img2_id, img1_overlap_tag), ytrue in tqdm_notebook(dup_truth.items()):\n",
    "    ii += 1\n",
    "    assert img1_id < img2_id\n",
    "\n",
    "    if (img1_id, img2_id, img1_overlap_tag) in dup_dict:\n",
    "        continue\n",
    "    if (img1_id, img2_id) not in overlap_image_maps:\n",
    "        continue\n",
    "    if img1_overlap_tag not in overlap_image_maps[(img1_id, img2_id)]:\n",
    "        continue\n",
    "    scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    if len(scores.pix) < 2:\n",
    "        continue\n",
    "    \n",
    "    dcnn_scores_raw = overlap_cnn_tile_scores[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    dcnn_scores = (dcnn_scores_raw > 0.5) * 1\n",
    "    yprob = np.max(dcnn_scores_raw)\n",
    "    ypred = (yprob > 0.5) * 1\n",
    "    assert ypred <= 1\n",
    "    \n",
    "    if ytrue:\n",
    "        bce = - ytrue * np.log(yprob)\n",
    "    else:\n",
    "        bce = - (1 - ytrue) * np.log(1 - yprob)\n",
    "    \n",
    "    dup_dict[(img1_id, img2_id, img1_overlap_tag)] = DNN_Stats(yprob, ypred, ytrue, bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_Stats2 = namedtuple('dnn_stats', ['key', 'yprob', 'ypred', 'ytrue', 'loss'])\n",
    "dup_dict_flat = []\n",
    "for keys, dnns in tqdm_notebook(dup_dict.items()):\n",
    "    dup_dict_flat.append(DNN_Stats2(keys, dnns.yprob, dnns.ypred, dnns.ytrue, dnns.loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_tags = []\n",
    "for dnns in tqdm_notebook(sorted(dup_dict_flat, key=operator.attrgetter('loss'), reverse=True)):\n",
    "    if dnns.ytrue == dnns.ypred:\n",
    "        # Skip the ones the dnn got correct.\n",
    "        continue\n",
    "    id_tags.append(dnns.key)\n",
    "len(id_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_samples = 8\n",
    "aa = 0\n",
    "use_median_shift = True\n",
    "\n",
    "test_files = id_tags[aa * n_samples: (aa + 1) * n_samples]#[::-1]\n",
    "for f in test_files:\n",
    "    print(f, dup_dict[f])\n",
    "\n",
    "dtick = 256\n",
    "n_ticks = 768 // dtick + 1\n",
    "ticks = [i * dtick for i in range(n_ticks)]\n",
    "\n",
    "fig, m_axs = plt.subplots(n_samples, 2, figsize = (12, 6 * n_samples))\n",
    "for ii, (img1_id, img2_id, img1_overlap_tag) in enumerate(test_files):\n",
    "    (ax1, ax2) = m_axs[ii]\n",
    "    yprob, ypred, is_dup, loss = dup_dict[(img1_id, img2_id, img1_overlap_tag)]\n",
    "    \n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "\n",
    "    slice1 = overlap_tag_slices[img1_overlap_tag]\n",
    "    slice2 = overlap_tag_slices[overlap_tag_pairs[img1_overlap_tag]]\n",
    "\n",
    "    m12 = np.median(np.vstack([imgmod1.parent_rgb[slice1], imgmod2.parent_rgb[slice2]]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "    \n",
    "    brightness_level = -100 if np.sum(m12) >= 384 else 100\n",
    "    img1 = imgmod1.channel_shift('L', brightness_level)\n",
    "    img2 = imgmod2.channel_shift('L', brightness_level)\n",
    "    \n",
    "    if use_median_shift:\n",
    "        img1_drop = imgmod1.parent_rgb - m12\n",
    "        img2_drop = imgmod2.parent_rgb - m12\n",
    "    else:        \n",
    "        img1_drop = imgmod1.parent_rgb\n",
    "        img2_drop = imgmod2.parent_rgb\n",
    "    \n",
    "    img1[slice1] = img1_drop[slice1]\n",
    "    img2[slice2] = img2_drop[slice2]\n",
    "\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(f'{img1_id} {yprob:6.4} ({is_dup})')\n",
    "    ax1.set_xticks(ticks)\n",
    "    ax1.set_yticks(ticks)\n",
    "\n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title(f'{img2_id} {loss:4.2f}')\n",
    "    ax2.set_xticks(ticks)\n",
    "    ax2.set_yticks(ticks)\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(os.path.join('temp', BASE_MODEL, f\"{train_meta_filebase}_{score_str}_batch_{BATCH_NUM}_row_{aa+1}.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out a decision tree classifier for dup_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_maps = 0\n",
    "missing_tags = 0\n",
    "L = []\n",
    "X = []\n",
    "Y = []\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in dup_truth.items():\n",
    "    \n",
    "    if (img1_id, img2_id) not in overlap_image_maps:\n",
    "        missing_maps += 1\n",
    "        continue\n",
    "    overlap_maps = overlap_image_maps[(img1_id, img2_id)]\n",
    "    if img1_overlap_tag not in overlap_maps:\n",
    "        missing_tags += 1\n",
    "        continue\n",
    "    scores = overlap_maps[img1_overlap_tag]\n",
    "    if len(scores.pix) < 2:\n",
    "        continue\n",
    "    \n",
    "    L.append((img1_id, img2_id, img1_overlap_tag))\n",
    "    X.append([\n",
    "        dup_dict[(img1_id, img2_id, img1_overlap_tag)].ypred,\n",
    "        dup_dict[(img1_id, img2_id, img1_overlap_tag)].loss,\n",
    "#         min(scores.bmh),\n",
    "#         min(scores.cmh),\n",
    "#         max(scores.pix), \n",
    "#         min(scores.pyr),\n",
    "#         max(scores.enp),\n",
    "    ])\n",
    "    Y.append([is_dup])\n",
    "\n",
    "L = np.array(L)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "# X = [[0, 0], [1, 1]]\n",
    "# Y = [0, 1]\n",
    "\n",
    "print(missing_maps)\n",
    "print(missing_tags)\n",
    "print(len(X))\n",
    "print(len(Y), sum(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "dot_data = tree.export_graphviz(\n",
    "    clf, \n",
    "    out_file=None, \n",
    "    feature_names=[\n",
    "        'ypred',\n",
    "        'loss',\n",
    "#         'min(bmh)', \n",
    "#         'min(cmh)', \n",
    "#         'max(pix)', \n",
    "#         'min(pyr)', \n",
    "#         'max(enp)',\n",
    "    ], \n",
    "    filled=True, \n",
    "    rounded=True, \n",
    "    special_characters=True, \n",
    "    leaves_parallel=True) \n",
    "\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = clf.apply(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = np.where(all_nodes == 3)\n",
    "np.argmin(X[nodes]), np.min(X[nodes]), np.argmax(X[nodes]), np.max(X[nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 36\n",
    "print(L[nodes][idx], Y[nodes][idx], X[nodes][idx])\n",
    "print(overlap_image_maps[(L[nodes][idx][0], L[nodes][idx][1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "tricky_examples_9 = [\n",
    "    ['e28669903.jpg', 'ed2998ef7.jpg', '0022', 1],\n",
    "    ['66482462b.jpg', 'e2497099c.jpg', '0022', 1],\n",
    "    ['73fec0637.jpg', '8b0219c19.jpg', '0022', 0]]\n",
    "# 6\n",
    "tricky_examples_6 = [\n",
    "    ['d164aea52.jpg', 'fded6e12d.jpg', '0011', 1],\n",
    "    ['00ce2c1c0.jpg', '68ef625ba.jpg', '0122', 1],\n",
    "    ['01178499a.jpg', '7a7a0034a.jpg', '0012', 1],\n",
    "    ['012d8cca1.jpg', 'bc45cee87.jpg', '0021', 1],\n",
    "    ['089858a56.jpg', '903a8b121.jpg', '1022', 1],\n",
    "    ['1ebdf2f08.jpg', 'b1bfb768c.jpg', '0012', 1],  # [91.          0.99781223]\n",
    "    ['2323bf875.jpg', 'b5da61fce.jpg', '0021', 1],  # [2.05663500e+06 9.98277186e-01]\n",
    "    ['468bf9178.jpg', '6090b3a8b.jpg', '1022', 1],  # [1.30900000e+03 9.97640283e-01]\n",
    "    ['d843fc5ca.jpg', 'e805070df.jpg', '1022', 1],\n",
    "    ['0ef6cd331.jpg', 'e6a6f80cd.jpg', '1022', 0],  # [1.72270000e+04 9.98394555e-01]\n",
    "    ['d4f0aaa70.jpg', 'd84d4a78a.jpg', '0012', 0],  # [5.95230000e+04 9.98578088e-01] \n",
    "    ['7f2be2b0a.jpg', '84dcdc7af.jpg', '0021', 0]]\n",
    "\n",
    "# 4\n",
    "tricky_examples_4 = [\n",
    "    ['0a33ce967.jpg', '3964f0cee.jpg', '0011', 1],\n",
    "    ['0318fc519.jpg', 'b7feb225a.jpg', '1021', 1],\n",
    "    ['7234a3a53.jpg', 'dc6534704.jpg', '1021', 1],\n",
    "    ['de6fb187d.jpg', 'ea6dc23b7.jpg', '1021', 1],  # [223.           0.99544613]\n",
    "    ['000194a2d.jpg', '384765ab2.jpg', '1022', 1],\n",
    "    ['c3193fb05.jpg', 'cc68e7818.jpg', '0112', 0],  # [2.16300000e+04 9.98311792e-01]\n",
    "    ['331987f64.jpg', '4869b48b6.jpg', '0112', 0],\n",
    "    ['42f02a4a4.jpg', '7d31648ff.jpg', '1122', 0],\n",
    "    ['cd3c59923.jpg', 'efdd03319.jpg', '1021', 0],  # [6.70246000e+05 9.99894307e-01] \n",
    "    ['0c279107f.jpg', '3b1314d5d.jpg', '1021', 0]]\n",
    "\n",
    "# 3\n",
    "tricky_examples_3 = [\n",
    "    ['2f6c0deaa.jpg', 'e44a4f5b0.jpg', '0222', 1],  # [24.          0.99509307]\n",
    "    ['204906e27.jpg', '892a69b4b.jpg', '0002', 1],  # [6.31644000e+05 9.97614902e-01]\n",
    "    ['4c56d2f00.jpg', 'dcd94e973.jpg', '2022', 1],  # [6.31635000e+05 9.97534103e-01]\n",
    "    ['b645cd49b.jpg', 'f2e554691.jpg', '2022', 1],  # [3.76847000e+05 9.96659721e-01]\n",
    "    ['b998c7415.jpg', 'd4d26f700.jpg', '2022', 1],  # [3.76847000e+05 9.96680501e-01]\n",
    "    ['0ef6cd331.jpg', '3a9e579aa.jpg', '2022', 0],  # [1.62810000e+04 9.98394555e-01]\n",
    "    ['0ef6cd331.jpg', '813c8ec35.jpg', '0222', 0],  # [1.79442000e+05 9.98195859e-01]\n",
    "    ['813c8ec35.jpg', 'caa94ffc3.jpg', '0020', 0],  # [1.76759000e+05 9.99834742e-01]\n",
    "    ['0256ef90d.jpg', '46da51931.jpg', '0020', 0],  # [3.70260000e+05 9.99319673e-01]\n",
    "    ['a61b3e245.jpg', 'd84d4a78a.jpg', '2022', 0],  # [2.59134100e+06 9.99175738e-01]\n",
    "    ['0ee790381.jpg', 'ac87bcee5.jpg', '0020', 0],\n",
    "    ['2095da0cb.jpg', '45b1a4561.jpg', '2022', 0]]\n",
    "\n",
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_pair(img1_id, img2_id, img1_overlap_tag, is_dup):\n",
    "    \n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "    dcnn_scores_raw = gen_dcnn_scores(imgmod1.parent_rgb, imgmod2.parent_rgb, img1_overlap_tag, model)\n",
    "    print(dcnn_scores_raw)\n",
    "#     print(sdcic.tile_entropy_grids[img1_id])\n",
    "#     print(sdcic.tile_entropy_grids[img2_id])\n",
    "    print(is_dup, overlap_image_maps[(img1_id, img2_id)])\n",
    "    \n",
    "    dtick = 256\n",
    "    n_ticks = imgmod1.shape[1] // dtick + 1\n",
    "    ticks = [i * dtick for i in range(n_ticks)]\n",
    "\n",
    "    slice1 = overlap_tag_slices[img1_overlap_tag]\n",
    "    slice2 = overlap_tag_slices[overlap_tag_pairs[img1_overlap_tag]]\n",
    "\n",
    "    cmh2 = img_hash.colorMomentHash(imgmod1.parent_rgb[slice1])\n",
    "    cmh1 = img_hash.colorMomentHash(imgmod2.parent_rgb[slice2])\n",
    "    score0_norm = np.linalg.norm(cmh1 - cmh2)\n",
    "    score0_expnorm = np.exp(-score0_norm)\n",
    "    print(len(imgmod1.parent_rgb[slice1]), len(cmh1[0]))\n",
    "#     print(cmh1.reshape((6, 7)))\n",
    "#     print(cmh2.reshape((6, 7)))\n",
    "    print(score0_expnorm, score0_norm)\n",
    "    \n",
    "    m12 = np.median(np.vstack([imgmod1.parent_rgb[slice1], imgmod2.parent_rgb[slice2]]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "    \n",
    "    brightness_level = -100 if np.sum(m12) >= 384 else 100\n",
    "    img1 = imgmod1.channel_shift('L', brightness_level)\n",
    "    img2 = imgmod2.channel_shift('L', brightness_level)\n",
    "    \n",
    "    img1_drop = imgmod1.parent_rgb - m12\n",
    "    img2_drop = imgmod2.parent_rgb - m12\n",
    "    \n",
    "    img1[slice1] = img1_drop[slice1]\n",
    "    img2[slice2] = img2_drop[slice2]\n",
    "\n",
    "    img1_overlap_map = overlap_tag_maps[img1_overlap_tag]\n",
    "    img2_overlap_map = overlap_tag_maps[overlap_tag_pairs[img1_overlap_tag]]\n",
    "\n",
    "    img1_nine, img2_nine = image_image_duplicate_tiles[(img1_id, img2_id)]\n",
    "    img1_mask = img1_nine[overlap_tag_nines_mask[img1_overlap_tag]]\n",
    "    img2_mask = img2_nine[overlap_tag_nines_mask[overlap_tag_pairs[img1_overlap_tag]]]\n",
    "\n",
    "    print(img1_mask)\n",
    "    print(img2_mask)\n",
    "    \n",
    "    for idx1, idx2 in zip(img1_overlap_map, img2_overlap_map):\n",
    "        \n",
    "        print(f'tile {idx1} / tile {idx2}')\n",
    "        tile1 = get_tile(imgmod1.parent_rgb, idx1)\n",
    "        tile2 = get_tile(imgmod2.parent_rgb, idx2)\n",
    "        score0 = fuzzy_compare(tile1, tile2)\n",
    "        \n",
    "        bmh1_0 = img_hash.blockMeanHash(tile1)\n",
    "        bmh2_0 = img_hash.blockMeanHash(tile2)\n",
    "        score0_hamm = get_hamming_distance_score(bmh1_0, bmh2_0, normalize=True)\n",
    "#         print(bmh1_0)\n",
    "#         print(bmh2_0)\n",
    "\n",
    "        cmh1_0 = img_hash.colorMomentHash(tile1)\n",
    "        cmh2_0 = img_hash.colorMomentHash(tile2)\n",
    "        score0_norm = np.linalg.norm(cmh1_0 - cmh2_0)\n",
    "        score0_expnorm = np.exp(-score0_norm)\n",
    "#         print(cmh1_0.reshape((6, 7)))\n",
    "#         print(cmh2_0.reshape((6, 7)))\n",
    "        \n",
    "        tile1_drop = get_tile(img1_drop, idx1)\n",
    "        tile2_drop = get_tile(img2_drop, idx2)\n",
    "        score1 = fuzzy_compare(tile1_drop, tile2_drop)\n",
    "\n",
    "        bmh1_1 = img_hash.blockMeanHash(tile1_drop)\n",
    "        bmh2_1 = img_hash.blockMeanHash(tile2_drop)\n",
    "        score1_hamm = get_hamming_distance_score(bmh1_1, bmh2_1, normalize=True)\n",
    "#         print(bmh1_1)\n",
    "#         print(bmh2_1)\n",
    "        \n",
    "        cmh1_1 = img_hash.colorMomentHash(tile1_drop)\n",
    "        cmh2_1 = img_hash.colorMomentHash(tile2_drop)\n",
    "        score1_norm = np.linalg.norm(cmh1_1 - cmh2_1)\n",
    "        score1_expnorm = np.exp(-score1_norm)\n",
    "#         print(cmh1_1.reshape((6, 7)))\n",
    "#         print(cmh2_1.reshape((6, 7)))\n",
    "        \n",
    "        m12_tile = np.median(np.vstack([tile1, tile2]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "        tile1_drop = tile1 - m12_tile\n",
    "        tile2_drop = tile2 - m12_tile\n",
    "        score2 = fuzzy_compare(tile1_drop, tile2_drop)\n",
    "        \n",
    "        bmh1_2 = img_hash.blockMeanHash(tile1_drop)\n",
    "        bmh2_2 = img_hash.blockMeanHash(tile2_drop)\n",
    "        score2_hamm = get_hamming_distance_score(bmh1_2, bmh2_2, normalize=True)\n",
    "#         print(bmh1_2)\n",
    "#         print(bmh2_2)\n",
    "        \n",
    "        cmh1_2 = img_hash.colorMomentHash(tile1_drop)\n",
    "        cmh2_2 = img_hash.colorMomentHash(tile2_drop)\n",
    "        score2_norm = np.linalg.norm(cmh1_2 - cmh2_2)\n",
    "        score2_expnorm = np.exp(-score2_norm)\n",
    "#         print(cmh1_2.reshape((6, 7)))\n",
    "#         print(cmh2_2.reshape((6, 7)))\n",
    "        \n",
    "        print(f'{score0:10.8f}, {score0_hamm:10.8f}, {score0_norm:10.8f}, {score0_expnorm:10.8f}')\n",
    "        print(f'{score1:10.8f}, {score1_hamm:10.8f}, {score1_norm:10.8f}, {score1_expnorm:10.8f}', m12)\n",
    "        print(f'{score2:10.8f}, {score2_hamm:10.8f}, {score2_norm:10.8f}, {score2_expnorm:10.8f}', m12_tile)\n",
    "        \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "    \n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(f'{img1_id}')\n",
    "    ax1.set_xticks(ticks)\n",
    "    ax1.set_yticks(ticks)\n",
    "    \n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title(f'{img2_id}')\n",
    "    ax2.set_xticks(ticks)\n",
    "    ax2.set_yticks(ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_image_pair(*tricky_examples_6[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (img1_id, img2_id, img1_overlap_tag), (is_dup, tiles_score) in dup_dict.items():\n",
    "#     if is_dup < 0:\n",
    "#         continue\n",
    "    \n",
    "    filename = os.path.join('temp', f\"{img1_id}_{img2_id}\")\n",
    "    if os.path.exists(filename):\n",
    "        continue\n",
    "\n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "    \n",
    "    img1 = imgmod1.parent_rgb\n",
    "    img2 = imgmod2.parent_rgb\n",
    "    \n",
    "    dtick = 256\n",
    "    n_ticks = imgmod1.shape[1] // dtick + 1\n",
    "    ticks = [i * dtick for i in range(n_ticks)]\n",
    "\n",
    "\n",
    "    scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "    \n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(f'{img1_id} ({min(scores.bmh):7.5f})')\n",
    "    \n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title(f'{img2_id} ({min(scores.cmh):7.5f})')\n",
    "    \n",
    "    fig.savefig(filename)\n",
    "    fig.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
