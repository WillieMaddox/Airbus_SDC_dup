{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import operator\n",
    "from collections import Counter\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage.util import montage\n",
    "import cv2\n",
    "from cv2 import img_hash\n",
    "import torch\n",
    "\n",
    "from sdcdup.utils import overlap_tag_pairs\n",
    "from sdcdup.utils import overlap_tag_maps\n",
    "from sdcdup.utils import generate_overlap_tag_slices\n",
    "from sdcdup.utils import boundingbox_corners\n",
    "from sdcdup.utils import generate_tag_pair_lookup\n",
    "from sdcdup.utils import fuzzy_compare\n",
    "from sdcdup.utils import get_tile\n",
    "from sdcdup.utils import get_hamming_distance\n",
    "from sdcdup.utils import channel_shift\n",
    "from sdcdup.utils import load_duplicate_truth\n",
    "from sdcdup.utils import update_duplicate_truth\n",
    "from sdcdup.utils import update_tile_cliques\n",
    "\n",
    "from test_friend_circles import SDCImageContainer\n",
    "from test_friend_circles import load_image_overlap_properties\n",
    "from dupnet import load_checkpoint\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "EPS = np.finfo(np.float32).eps\n",
    "\n",
    "RED = (244, 67, 54) #F44336 \n",
    "GREEN = (76, 175, 80) #4CAF50 \n",
    "LIGHT_BLUE = (3, 169, 244) #03A9F4\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title\n",
    "\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "montage_pad = lambda x, *args, **kwargs: montage(x, padding_width=10, *args, **kwargs)\n",
    "zeros_mask = np.zeros((256*3, 256*3, 1), dtype=np.float32)\n",
    "\n",
    "train_image_dir = 'data/raw/train_768/'\n",
    "image_md5hash_grids_file = 'data/interim/image_md5hash_grids.pkl'\n",
    "image_bm0hash_grids_file = 'data/interim/image_bm0hash_grids.pkl'\n",
    "image_cm0hash_grids_file = 'data/interim/image_cm0hash_grids.pkl'\n",
    "image_greycop_grids_file = 'data/interim/image_greycop_grids.pkl'\n",
    "image_entropy_grids_file = 'data/interim/image_entropy_grids.pkl'\n",
    "image_issolid_grids_file = 'data/interim/image_issolid_grids.pkl'\n",
    "image_shipcnt_grids_file = 'data/interim/image_shipcnt_grids.pkl'\n",
    "\n",
    "overlap_tag_slices = generate_overlap_tag_slices()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgMod:\n",
    "    \"\"\"\n",
    "    Reads a single image to be modified by hls.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.img_id = filename.split('/')[-1]\n",
    "\n",
    "        self._hls_chan = None\n",
    "        self._hls_gain = None\n",
    "\n",
    "        self._parent_bgr = None\n",
    "        self._parent_hls = None\n",
    "        self._parent_rgb = None\n",
    "        self._cv2_hls = None\n",
    "        self._cv2_bgr = None\n",
    "        self._cv2_rgb = None\n",
    "\n",
    "    def channel_shift(self, chan, gain):\n",
    "        self._hls_chan = chan\n",
    "        self._hls_gain = gain\n",
    "        self._cv2_hls = None\n",
    "        return self.cv2_rgb\n",
    "    \n",
    "    def scale(self, minval, maxval):\n",
    "        m = 255.0 * (maxval - minval)\n",
    "        res = m * (self.parent_bgr - minval)\n",
    "        return np.around(res).astype(np.uint8)\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.parent_bgr.shape\n",
    "    \n",
    "    @property\n",
    "    def parent_bgr(self):\n",
    "        if self._parent_bgr is None:\n",
    "            self._parent_bgr = cv2.imread(self.filename)\n",
    "        return self._parent_bgr\n",
    "\n",
    "    @property\n",
    "    def parent_hls(self):\n",
    "        if self._parent_hls is None:\n",
    "            self._parent_hls = self.to_hls(self.parent_bgr)\n",
    "        return self._parent_hls\n",
    "\n",
    "    @property\n",
    "    def parent_rgb(self):\n",
    "        if self._parent_rgb is None:\n",
    "            self._parent_rgb = self.to_rgb(self.parent_bgr)\n",
    "        return self._parent_rgb\n",
    "\n",
    "    @property\n",
    "    def cv2_hls(self):\n",
    "        if self._cv2_hls is None:\n",
    "            if self._hls_gain == None:\n",
    "                self._cv2_hls = self.parent_hls\n",
    "            else:\n",
    "                self._cv2_hls = channel_shift(self.parent_hls, self._hls_chan, self._hls_gain)\n",
    "        return self._cv2_hls\n",
    "\n",
    "    @property\n",
    "    def cv2_bgr(self):\n",
    "        if self._cv2_bgr is None:\n",
    "            self._cv2_bgr = self.to_bgr(self.cv2_hls)\n",
    "        return self._cv2_bgr\n",
    "\n",
    "    @property\n",
    "    def cv2_rgb(self):\n",
    "        if self._cv2_rgb is None:\n",
    "            self._cv2_rgb = self.to_rgb(self.cv2_bgr)\n",
    "        return self._cv2_rgb\n",
    "\n",
    "    def to_hls(self, bgr):\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2HLS_FULL)\n",
    "\n",
    "    def to_bgr(self, hls):\n",
    "        return cv2.cvtColor(hls, cv2.COLOR_HLS2BGR_FULL)\n",
    "\n",
    "    def to_rgb(self, bgr):\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdcic = SDCImageContainer()\n",
    "sdcic.preprocess_image_properties(\n",
    "    image_md5hash_grids_file,\n",
    "    image_bm0hash_grids_file,\n",
    "    image_cm0hash_grids_file,\n",
    "    image_greycop_grids_file,\n",
    "    image_entropy_grids_file,\n",
    "    image_issolid_grids_file)\n",
    "sdcic.preprocess_label_properties(\n",
    "    image_shipcnt_grids_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth = load_duplicate_truth()\n",
    "print(len(dup_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_types = ['bmh', 'cmh', 'con', 'hom', 'eng', 'cor', 'epy', 'enp', 'pix', 'px0', 'shp']\n",
    "n_matching_tiles_list = [9, 6, 4, 3, 2, 1]\n",
    "overlap_image_maps = load_image_overlap_properties(n_matching_tiles_list)\n",
    "print(len(overlap_image_maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "img_overlap_index_maps = generate_tag_pair_lookup()\n",
    "TilePairs = namedtuple('TilePairs', 'img1_id img2_id img1_overlap_tag overlap_idx idx1 idx2')\n",
    "\n",
    "def get_img(img_id):\n",
    "    return cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    \n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, tile_pairs, \n",
    "                 image_transform=None,\n",
    "                 in_shape=(6, 256, 256), \n",
    "                 out_shape=(1,)):\n",
    "\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.sz = 256\n",
    "        self.tile_pairs = tile_pairs\n",
    "        self.image_transform = image_transform\n",
    "        self.ij = ((0, 0), (0, 1), (0, 2),\n",
    "                   (1, 0), (1, 1), (1, 2),\n",
    "                   (2, 0), (2, 1), (2, 2))\n",
    "        \n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return len(self.tile_pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one sample of data\"\"\"\n",
    "        tp = self.tile_pairs[index]\n",
    "        \n",
    "        img1 = get_img(tp.img1_id)\n",
    "        img2 = get_img(tp.img2_id)\n",
    "        \n",
    "        tile1 = cv2.cvtColor(self.get_tile(img1, *self.ij[tp.idx1]), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        tile2 = cv2.cvtColor(self.get_tile(img2, *self.ij[tp.idx2]), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        \n",
    "        X = np.dstack([tile1, tile2])\n",
    "        X = X.transpose((2, 0, 1))\n",
    "        X = torch.from_numpy(X)\n",
    "        return X\n",
    "    \n",
    "    def get_tile(self, img, i, j):\n",
    "        return img[i * self.sz:(i + 1) * self.sz, j * self.sz:(j + 1) * self.sz, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return x.view(-1, 6, 256, 256).to(device)\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_pairs = []\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    for img1_overlap_tag in overlap_maps:\n",
    "#         if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "#             continue\n",
    "        for overlap_idx, (idx1, idx2) in enumerate(img_overlap_index_maps[img1_overlap_tag]):\n",
    "            tile_pairs.append(TilePairs(img1_id, img2_id, img1_overlap_tag, overlap_idx, idx1, idx2))\n",
    "print(len(tile_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(tile_pairs)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=256, num_workers=20)\n",
    "test_dl = WrappedDataLoader(test_dl, preprocess)\n",
    "print(len(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint('models/dup_model.best.pth')\n",
    "model.cuda()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yprobs0 = [model(xb) for xb in tqdm_notebook(test_dl)]\n",
    "    yprobs = np.vstack([l.cpu() for l in yprobs0]).reshape(-1)\n",
    "    print(len(yprobs0), yprobs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprobs_c = np.where(np.abs(yprobs - 0.5) < 0.472)[0]\n",
    "print(yprobs_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_weak_pred = False\n",
    "weak_preds = []\n",
    "overlap_cnn_tile_scores = {}\n",
    "for ii, (tp, yprob) in enumerate(zip(tile_pairs, yprobs)):\n",
    "    if ii in yprobs_c:\n",
    "        is_weak_pred = True\n",
    "    if (tp.img1_id, tp.img2_id) not in overlap_cnn_tile_scores:\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)] = {}\n",
    "    if tp.img1_overlap_tag not in overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)]:\n",
    "        n_overlapping_tiles = len(img_overlap_index_maps[tp.img1_overlap_tag])\n",
    "        cnn_scores = [None] * n_overlapping_tiles\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag] = cnn_scores\n",
    "    overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag][tp.overlap_idx] = yprob\n",
    "    if tp.overlap_idx == n_overlapping_tiles - 1 and is_weak_pred:\n",
    "        weak_preds.append((tp.img1_id, tp.img2_id, tp.img1_overlap_tag))\n",
    "        is_weak_pred = False\n",
    "\n",
    "len(weak_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlaps with ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untested_image_pairs_with_ship_masks = []\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    # TODO: Find out which remaining tile pairs have masks but aren't in dup_truth.\n",
    "\n",
    "    mask1 = sdcic.tile_shipcnt_grids[img1_id]\n",
    "    mask2 = sdcic.tile_shipcnt_grids[img2_id]\n",
    "    \n",
    "    has_mask1 = np.sum(mask1) > 0\n",
    "    has_mask2 = np.sum(mask2) > 0\n",
    "\n",
    "    if not (has_mask1 and has_mask2):\n",
    "        continue\n",
    "\n",
    "    for img1_overlap_tag in overlap_maps:\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "        untested_image_pairs_with_ship_masks.append((img1_id, img2_id))\n",
    "        break\n",
    "\n",
    "len(overlap_image_maps), len(untested_image_pairs_with_ship_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untested_overlaps_with_ship_masks = []\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    # TODO: Find out which remaining tile pairs have masks but aren't in dup_truth.\n",
    "\n",
    "    mask1 = sdcic.tile_shipcnt_grids[img1_id]\n",
    "    mask2 = sdcic.tile_shipcnt_grids[img2_id]\n",
    "    \n",
    "    has_mask1 = np.sum(mask1) > 0\n",
    "    has_mask2 = np.sum(mask2) > 0\n",
    "\n",
    "    if not (has_mask1 and has_mask2):\n",
    "        continue\n",
    "\n",
    "    for img1_overlap_tag in overlap_maps:\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "\n",
    "        mask1_slice_total = np.sum(mask1[overlap_tag_maps[img1_overlap_tag]])\n",
    "        mask2_slice_total = np.sum(mask2[overlap_tag_maps[overlap_tag_pairs[img1_overlap_tag]]])\n",
    "\n",
    "        if mask1_slice_total + mask2_slice_total < 1:\n",
    "            continue\n",
    "\n",
    "        untested_overlaps_with_ship_masks.append((img1_id, img2_id, img1_overlap_tag))\n",
    "\n",
    "len(overlap_image_maps), len(untested_overlaps_with_ship_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlapping images using hashlib\n",
    "Update: The values between two supposedly exact 256x256 crops are not exact (See below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md5hash_dict = defaultdict(list)\n",
    "img_ids = os.listdir(train_image_dir)\n",
    "\n",
    "for img_id in tqdm_notebook(img_ids):\n",
    "    for h in sdcic.tile_md5hash_grids[img_id]:\n",
    "        md5hash_dict[h].append(img_id)\n",
    "\n",
    "dup_counts_dict = defaultdict(int)\n",
    "for key, dups in md5hash_dict.items():\n",
    "    dup_counts_dict[len(dups)] += 1\n",
    "\n",
    "sorted_bin_sizes = sorted(dup_counts_dict.items())\n",
    "print('n images with k duplicates')\n",
    "print('(k, n)')\n",
    "sorted_bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 9\n",
    "skip = 365\n",
    "ii = 0\n",
    "jj = 0\n",
    "batch_limit = 9\n",
    "samples_images = np.empty((batch_limit, 768, 768, 3), dtype=np.float32)\n",
    "\n",
    "for hash_id, dups in md5hash_dict.items():\n",
    "    ii += 1\n",
    "    if len(dups) == batch_size:\n",
    "        dups0 = list(set(dups))\n",
    "        img_id = dups0[0]\n",
    "        idx = sdcic.tile_md5hash_grids[img_id].tolist().index(hash_id)\n",
    "        print(hash_id, len(dups), ii, sdcic.tile_entropy_grids[img_id][idx])\n",
    "        if jj == min(dup_counts_dict[len(dups)], skip):\n",
    "            break\n",
    "        jj += 1\n",
    "\n",
    "for i, c_img_id in enumerate(dups0[:batch_limit]):\n",
    "    c_img = cv2.cvtColor(sdcic.get_img(c_img_id), cv2.COLOR_BGR2RGB)\n",
    "    samples_images[i] = c_img.astype(np.float32) / 255.0\n",
    "\n",
    "batch_rgb = montage_rgb(samples_images)\n",
    "print(samples_images.shape)\n",
    "print(batch_rgb.shape, batch_rgb.dtype)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16, 16))\n",
    "ax.imshow(batch_rgb, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlapping images using cv2.img_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm0hash_dict = defaultdict(list)\n",
    "img_ids = os.listdir(train_image_dir)\n",
    "\n",
    "for img_id in tqdm_notebook(img_ids):\n",
    "    for h in sdcic.tile_bm0hash_grids[img_id]:\n",
    "        bm0hash_dict[tuple(h)].append(img_id)  # hex\n",
    "\n",
    "dup_counts_dict = defaultdict(int)\n",
    "for key, dups in bm0hash_dict.items():\n",
    "    dup_counts_dict[len(dups)] += 1\n",
    "\n",
    "sorted_bin_sizes = sorted(dup_counts_dict.items())\n",
    "print('n images with k duplicates')\n",
    "print('(k, n)')\n",
    "sorted_bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 18\n",
    "skip = 5\n",
    "ii = 0\n",
    "jj = 0\n",
    "batch_limit = 9\n",
    "samples_images = np.empty((batch_limit, 768, 768, 3), dtype=np.float32)\n",
    "\n",
    "for hash_id, dups in bm0hash_dict.items():\n",
    "    ii += 1\n",
    "    if len(dups) == batch_size:\n",
    "        dups0 = list(set(dups))\n",
    "        img_id = dups0[0]\n",
    "        idx = np.where(np.all(sdcic.tile_bm0hash_grids[img_id] == np.asarray(hash_id), axis=1))[0]\n",
    "        print(hash_id, len(dups), ii, sdcic.tile_entropy_grids[img_id][idx])\n",
    "        if jj == min(dup_counts_dict[len(dups)], skip):\n",
    "            break\n",
    "        jj += 1\n",
    "\n",
    "for i, c_img_id in enumerate(dups0[:batch_limit]):\n",
    "    c_img = cv2.cvtColor(sdcic.get_img(c_img_id), cv2.COLOR_BGR2RGB)\n",
    "    samples_images[i] = c_img.astype(np.float32) / 255.0\n",
    "\n",
    "batch_rgb = montage_rgb(samples_images)\n",
    "print(samples_images.shape)\n",
    "print(batch_rgb.shape, batch_rgb.dtype)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16, 16))\n",
    "ax.imshow(batch_rgb, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "# plt.savefig(os.path.join('models', BASE_MODEL, f\"{train_meta_filebase}_{score_str}_batch_{BATCH_NUM}.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we explore dup detection using image gradients and cross entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_entropy(ctr, img_size=1769472):  # 768x768x3\n",
    "    ctr_norm = {k: v / img_size for k, v in sorted(ctr.items())}\n",
    "    ctr_entropy = {k: -v * np.log(v) for k, v in ctr_norm.items()}\n",
    "    entropy = np.sum([k * v for k, v in ctr_entropy.items()])\n",
    "    return entropy\n",
    "\n",
    "def get_entropy(img_id):\n",
    "    img = cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    img_grad = np.gradient(img.astype(np.int), axis=(0, 1))\n",
    "    entropy_list = []\n",
    "    for channel_grad in img_grad:\n",
    "        ctr = Counter(np.abs(channel_grad).flatten())\n",
    "        entropy_list.append(get_channel_entropy(ctr, img.size))\n",
    "    return np.array(entropy_list)\n",
    "\n",
    "def get_entropy1(img_id):\n",
    "    img = cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    img_grad = np.gradient(img.astype(np.int), 0.5, axis=(0, 1))\n",
    "    entropy_list = []\n",
    "    for channel_grad in img_grad:\n",
    "        ctr = Counter(np.abs(channel_grad).astype(np.uint8).flatten())\n",
    "        entropy_list.append(ctr)\n",
    "    return entropy_list\n",
    "\n",
    "def get_entropy2(img1_id, img2_id):\n",
    "    entropy1_list = get_entropy1(img1_id)\n",
    "    entropy2_list = get_entropy1(img2_id)\n",
    "    entropy_list = []\n",
    "    for ctr1, ctr2 in zip(entropy1_list, entropy2_list):\n",
    "        ctr = (ctr1 - ctr2) + (ctr2 - ctr1)\n",
    "        entropy_list.append(get_channel_entropy(ctr))\n",
    "    return np.array(entropy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_lim0 = 0\n",
    "score_lim1 = 1\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    if img1_id > img2_id:\n",
    "        # sanity check\n",
    "        raise ValueError(f'img1_id ({img1_id}) should be lexicographically smaller than img2_id ({img2_id})')\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) not in dup_truth:\n",
    "            continue\n",
    "        \n",
    "        is_dup = dup_truth[(img1_id, img2_id, img1_overlap_tag)]\n",
    "\n",
    "        if is_dup == 0 and np.max(scores.enp) > score_lim0:\n",
    "            score_lim0 = np.max(scores.enp)\n",
    "            print_score = True\n",
    "        elif is_dup == 1 and np.max(scores.enp) < score_lim1:\n",
    "            score_lim1 = np.max(scores.enp)\n",
    "            print_score = True\n",
    "        else:\n",
    "            print_score = False\n",
    "\n",
    "        if print_score:\n",
    "            img1_entropy_vec = get_entropy(img1_id)\n",
    "            img2_entropy_vec = get_entropy(img2_id)\n",
    "            img1_entropy_vec_norm = np.linalg.norm(img1_entropy_vec)\n",
    "            img2_entropy_vec_norm = np.linalg.norm(img2_entropy_vec)\n",
    "            n_vec = np.max([img1_entropy_vec_norm, img2_entropy_vec_norm])\n",
    "            img1_scaled_vec = img1_entropy_vec / n_vec\n",
    "            img2_scaled_vec = img2_entropy_vec / n_vec\n",
    "            grad_score = 1.0 - np.linalg.norm(img1_scaled_vec - img2_scaled_vec)\n",
    "\n",
    "            entropy2 = get_entropy2(img1_id, img2_id)\n",
    "            entropy2_norm = np.linalg.norm(entropy2)\n",
    "            \n",
    "            print('')\n",
    "            print(f'{is_dup}, {min(scores.bmh):7.5f}, {min(scores.cmh):7.5f}, {grad_score:7.5f}, {entropy2_norm}')\n",
    "            print(img1_id, img1_entropy_vec, f'{img1_entropy_vec_norm}')\n",
    "            print(img2_id, img2_entropy_vec, f'{img2_entropy_vec_norm}')\n",
    "            print(get_entropy(img1_id))\n",
    "            print(get_entropy(img2_id))\n",
    "            print(entropy2)\n",
    "            print(np.max(scores.enp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_id = '691d5afc2.jpg'\n",
    "img2_id = '56417e7af.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_entropy_vec = get_entropy(img1_id)\n",
    "img2_entropy_vec = get_entropy(img2_id)\n",
    "img1_entropy_vec_norm = np.linalg.norm(img1_entropy_vec)\n",
    "img2_entropy_vec_norm = np.linalg.norm(img2_entropy_vec)\n",
    "n_vec = np.max([img1_entropy_vec_norm, img1_entropy_vec_norm])\n",
    "img1_scaled_vec = img1_entropy_vec / n_vec\n",
    "img2_scaled_vec = img2_entropy_vec / n_vec\n",
    "print('')\n",
    "print(img1_id, img1_entropy_vec, f'{img1_entropy_vec_norm}')\n",
    "print(img2_id, img2_entropy_vec, f'{img1_entropy_vec_norm}')\n",
    "print(f'{np.linalg.norm(img1_scaled_vec - img2_scaled_vec)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/dup_blacklist_6.csv', sep=', ')\n",
    "for idx, row in df.iterrows():\n",
    "    print(idx)\n",
    "    img1_entropy_vec = get_entropy(row['ImageId1'])\n",
    "    img1_entropy_vec_u = img1_entropy_vec / np.linalg.norm(img1_entropy_vec)\n",
    "    print(row['ImageId1'], img1_entropy_vec)\n",
    "    img2_entropy_vec = get_entropy(row['ImageId2'])\n",
    "    img2_entropy_vec_u = img2_entropy_vec / np.linalg.norm(img2_entropy_vec)\n",
    "    print(row['ImageId2'], img2_entropy_vec)\n",
    "    print(np.dot(img1_entropy_vec_u, img2_entropy_vec_u), np.linalg.norm(img1_entropy_vec - img2_entropy_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search for reasonable thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh_scores = defaultdict()\n",
    "cmh_scores = defaultdict()\n",
    "pix_scores = defaultdict(int)\n",
    "\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    if img1_id > img2_id:\n",
    "        # sanity check\n",
    "        raise ValueError(f'img1_id ({img1_id}) should be lexicographically smaller than img2_id ({img2_id})')\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "\n",
    "        for i in range(len(scores.bmh)):\n",
    "            idx = (img1_id, img2_id, img1_overlap_tag, i)\n",
    "            bmh_scores[idx] = scores.bmh[i]\n",
    "            cmh_scores[idx] = scores.cmh[i]\n",
    "            pix_scores[idx] = scores.pix[i]\n",
    "\n",
    "overlap_scores_df = pd.DataFrame()\n",
    "overlap_scores_df['bmh'] = pd.Series(bmh_scores)\n",
    "overlap_scores_df['cmh'] = pd.Series(cmh_scores)\n",
    "overlap_scores_df['pix'] = pd.Series(pix_scores)\n",
    "\n",
    "overlap_scores_df.describe(percentiles=[.01, .05, .1, .25, .5, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmh_arr = []\n",
    "cmh_arr = []\n",
    "con_arr = []\n",
    "hom_arr = []\n",
    "eng_arr = []\n",
    "cor_arr = []\n",
    "epy_arr = []\n",
    "enp_arr = []\n",
    "pix_arr = []\n",
    "px0_arr = []\n",
    "shp_arr = []\n",
    "\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "\n",
    "        bmh_arr += list(scores.bmh)\n",
    "        cmh_arr += list(scores.cmh)\n",
    "        con_arr += list(scores.con)\n",
    "        hom_arr += list(scores.hom)\n",
    "        eng_arr += list(scores.eng)\n",
    "        cor_arr += list(scores.cor)\n",
    "        epy_arr += list(scores.epy)\n",
    "        enp_arr += list(scores.enp)\n",
    "        pix_arr += list(scores.pix)\n",
    "        px0_arr += list(scores.px0)\n",
    "        shp_arr += list(scores.shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_limits_df = pd.DataFrame()\n",
    "overlap_limits_df['bmh'] = pd.Series(bmh_arr)\n",
    "overlap_limits_df['cmh'] = pd.Series(cmh_arr)\n",
    "overlap_limits_df['con'] = pd.Series(con_arr)\n",
    "overlap_limits_df['hom'] = pd.Series(hom_arr)\n",
    "overlap_limits_df['eng'] = pd.Series(eng_arr)\n",
    "overlap_limits_df['cor'] = pd.Series(cor_arr)\n",
    "overlap_limits_df['epy'] = pd.Series(epy_arr)\n",
    "overlap_limits_df['enp'] = pd.Series(enp_arr)\n",
    "overlap_limits_df['pix'] = pd.Series(pix_arr)\n",
    "overlap_limits_df['px0'] = pd.Series(px0_arr)\n",
    "overlap_limits_df['shp'] = pd.Series(shp_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_limits_df.describe(percentiles=[.001, .01, .02, .05, .1, .25, .5, .75, .9, .95, .98, .99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_limits_df.describe(percentiles=[.1, .25, .5, .75, .9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  |-----|--------------|-----|\n",
    "# min  lower          upper  max\n",
    "\n",
    "metric_tags = ['bmh', 'cmh', 'con', 'hom', 'eng', 'cor', 'epy', 'enp', 'pix', 'px0', 'shp']\n",
    "Overlap_Scores_Lower_Limit = namedtuple('overlap_scores_lower_limit', metric_tags)\n",
    "Overlap_Scores_Upper_Limit = namedtuple('overlap_scores_upper_limit', metric_tags)\n",
    "\n",
    "osl_lower = Overlap_Scores_Lower_Limit(0., 0., 1e-5, 18e-6, 8e-6, 2e-6, 2e-6, 0.9995, 141, 0, 0)\n",
    "osl_upper = Overlap_Scores_Upper_Limit(1., 1., 8e-5, 1.5e-4, 1e-4, 2e-5, 2e-5, 0.99993, 1859, 1e7, 1e7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "Overlap_Idx_Scores = namedtuple('overlap_idx_scores', [\n",
    "    'idx', \n",
    "    'bmh_min', 'cmh_min', 'con_min', 'hom_min', 'eng_min', 'cor_min', 'epy_min', 'enp_min', 'pix_min', 'px0_min', 'shp_min', \n",
    "    'bmh_max', 'cmh_max', 'con_max', 'hom_max', 'eng_max', 'cor_max', 'epy_max', 'enp_max', 'pix_max', 'px0_max', 'shp_max'])\n",
    "\n",
    "bmh_min = 0\n",
    "cmh_min = 0\n",
    "con_min = 0\n",
    "hom_min = 0\n",
    "eng_min = 0\n",
    "cor_min = 0\n",
    "epy_min = 0\n",
    "enp_min = 0\n",
    "pix_min = 0\n",
    "px0_min = 0\n",
    "shp_min = 0\n",
    "\n",
    "bmh_max = 1\n",
    "cmh_max = 1\n",
    "con_max = 1\n",
    "hom_max = 1\n",
    "eng_max = 1\n",
    "cor_max = 1\n",
    "epy_max = 1\n",
    "enp_max = 1\n",
    "pix_max = 256*256*3*255\n",
    "px0_max = 256*256\n",
    "shp_max = 256*256\n",
    "\n",
    "bmh_min_hits = 0\n",
    "cmh_min_hits = 0\n",
    "con_min_hits = 0\n",
    "hom_min_hits = 0\n",
    "eng_min_hits = 0\n",
    "cor_min_hits = 0\n",
    "epy_min_hits = 0\n",
    "enp_min_hits = 0\n",
    "pix_min_hits = 0\n",
    "px0_min_hits = 0\n",
    "shp_min_hits = 0\n",
    "\n",
    "bmh_max_hits = 0\n",
    "cmh_max_hits = 0\n",
    "con_max_hits = 0\n",
    "hom_max_hits = 0\n",
    "eng_max_hits = 0\n",
    "cor_max_hits = 0\n",
    "epy_max_hits = 0\n",
    "enp_max_hits = 0\n",
    "pix_max_hits = 0\n",
    "px0_max_hits = 0\n",
    "shp_max_hits = 0\n",
    "\n",
    "flat_score_good = 0\n",
    "flat_score_bad = 0\n",
    "print_first_good = True\n",
    "print_first_bad = True\n",
    "n_not_dups = 0\n",
    "\n",
    "overlap_candidates = []\n",
    "for (img1_id, img2_id), overlap_maps in tqdm_notebook(overlap_image_maps.items()):\n",
    "    for img1_overlap_tag, scores in overlap_maps.items():\n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "\n",
    "        constraint_hits = 0\n",
    "        \n",
    "        bmh_min = np.min(scores.bmh)\n",
    "        if bmh_min < osl_lower.bmh:\n",
    "            bmh_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        cmh_min = np.min(scores.cmh)\n",
    "        if cmh_min < osl_lower.cmh:\n",
    "            cmh_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        con_min = np.min(scores.con)\n",
    "        if con_min < osl_lower.con:\n",
    "            con_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        hom_min = np.min(scores.hom)\n",
    "        if hom_min < osl_lower.hom:\n",
    "            hom_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        eng_min = np.min(scores.eng)\n",
    "        if eng_min < osl_lower.eng:\n",
    "            eng_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        cor_min = np.min(scores.cor)\n",
    "        if cor_min < osl_lower.cor:\n",
    "            cor_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        epy_min = np.min(scores.epy)\n",
    "        if epy_min < osl_lower.epy:\n",
    "            epy_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        enp_min = np.min(scores.enp)\n",
    "        if enp_min < osl_lower.enp:\n",
    "            enp_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        pix_min = np.min(scores.pix)\n",
    "        if pix_min < osl_lower.pix:\n",
    "            pix_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        px0_min = np.min(scores.px0)\n",
    "        if px0_min < osl_lower.px0:\n",
    "            px0_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        shp_min = np.min(scores.shp)\n",
    "        if shp_min < osl_lower.shp:\n",
    "            shp_min_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "            \n",
    "        bmh_max = np.max(scores.bmh)\n",
    "        if bmh_max > osl_upper.bmh:\n",
    "            bmh_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        cmh_max = np.max(scores.cmh)\n",
    "        if cmh_max > osl_upper.cmh:\n",
    "            cmh_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        con_max = np.max(scores.con)\n",
    "        if con_max > osl_upper.con:\n",
    "            con_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        hom_max = np.max(scores.hom)\n",
    "        if hom_max > osl_upper.hom:\n",
    "            hom_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "            \n",
    "        eng_max = np.max(scores.eng)\n",
    "        if eng_max > osl_upper.eng:\n",
    "            eng_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        cor_max = np.max(scores.cor)\n",
    "        if cor_max > osl_upper.cor:\n",
    "            cor_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        epy_max = np.max(scores.epy)\n",
    "        if epy_max > osl_upper.epy:\n",
    "            epy_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        enp_max = np.max(scores.enp)\n",
    "        if enp_max > osl_upper.enp:\n",
    "            enp_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        pix_max = np.max(scores.pix)\n",
    "        if pix_max > osl_upper.pix:\n",
    "            pix_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        px0_max = np.max(scores.px0)\n",
    "        if px0_max > osl_upper.px0:\n",
    "            px0_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "        shp_max = np.max(scores.shp)\n",
    "        if shp_max > osl_upper.shp:\n",
    "            shp_max_hits += 1\n",
    "            constraint_hits += 1\n",
    "\n",
    "#         if constraint_hits < 0:\n",
    "#             continue\n",
    "            \n",
    "        idx = (img1_id, img2_id, img1_overlap_tag)\n",
    "        overlap_scores = Overlap_Idx_Scores(\n",
    "            idx, \n",
    "            bmh_min, cmh_min, con_min, hom_min, eng_min, cor_min, epy_min, enp_min, pix_min, px0_min, shp_min, \n",
    "            bmh_max, cmh_max, con_max, hom_max, eng_max, cor_max, epy_max, enp_max, pix_max, px0_max, shp_max)\n",
    "        overlap_candidates.append(overlap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print(len(overlap_candidates))\n",
    "print(bmh_min_hits, cmh_min_hits, con_min_hits, hom_min_hits, eng_min_hits, cor_min_hits, epy_min_hits, enp_min_hits, pix_min_hits)\n",
    "print(bmh_max_hits, cmh_max_hits, con_max_hits, hom_max_hits, eng_max_hits, cor_max_hits, epy_max_hits, enp_max_hits, pix_max_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dup_truth), n_not_dups, flat_score_good, flat_score_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use duplicate_truth.txt and image_md5hash_grids.pkl to find untested duplicate and non-duplicate tiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of flat hashes. \n",
    "(i.e. hashes for tiles where every pixel is the same color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_overlap_index_maps = generate_tag_pair_lookup()\n",
    "\n",
    "solid_hashes = set()\n",
    "for img_id, tile_issolid_grid in sdcic.tile_issolid_grids.items():\n",
    "    idxs = set(np.where(tile_issolid_grid >= 0)[0])\n",
    "    for idx in idxs:\n",
    "        if np.all(tile_issolid_grid[idx] >= 0):\n",
    "            solid_hashes.add(sdcic.tile_md5hash_grids[img_id][idx])\n",
    "\n",
    "print(solid_hashes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_hash_dup_dict = defaultdict(set)\n",
    "tile_hash_dif_dict = defaultdict(set)\n",
    "\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in dup_truth.items():\n",
    "    \n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if is_dup:\n",
    "\n",
    "            if tile1_hash in solid_hashes or tile2_hash in solid_hashes:\n",
    "                continue\n",
    "\n",
    "            tile_hash_dup_dict[tile1_hash].add(tile1_hash)\n",
    "            tile_hash_dup_dict[tile2_hash].add(tile2_hash)\n",
    "            tile_hash_dup_dict[tile1_hash].add(tile2_hash)\n",
    "            tile_hash_dup_dict[tile2_hash].add(tile1_hash)\n",
    "        \n",
    "        else:\n",
    "            if tile1_hash == tile2_hash:\n",
    "                continue\n",
    "\n",
    "            tile_hash_dif_dict[tile1_hash].add(tile2_hash)\n",
    "            tile_hash_dif_dict[tile2_hash].add(tile1_hash)\n",
    "            \n",
    "print(len(tile_hash_dup_dict), len(tile_hash_dif_dict))\n",
    "\n",
    "# Sanity check: hashes cannot be simultaneously \"a dup\" and \"not a dup\" of tile1_hash\n",
    "for tile1_hash in tile_hash_dup_dict:\n",
    "    if len(tile_hash_dup_dict[tile1_hash].intersection(tile_hash_dif_dict[tile1_hash])) != 0:\n",
    "        print(tile1_hash, tile_hash_dup_dict[tile1_hash], tile_hash_dif_dict[tile1_hash])\n",
    "    assert len(tile_hash_dup_dict[tile1_hash].intersection(tile_hash_dif_dict[tile1_hash])) == 0\n",
    "    \n",
    "# Sanity check: If B and C are dups of A, then make sure C not in tile_hash_dif_dict[B]\n",
    "for tile1_hash, tile1_dups in tile_hash_dup_dict.items():\n",
    "    for tile1_dup1 in sorted(tile1_dups):\n",
    "        for tile1_dup2 in sorted(tile1_dups):\n",
    "            if tile1_dup1 in tile_hash_dif_dict[tile1_dup2]:\n",
    "                print(tile1_hash, tile1_dup1, tile_hash_dif_dict[tile1_dup2])\n",
    "            assert tile1_dup1 not in tile_hash_dif_dict[tile1_dup2]\n",
    "\n",
    "# Now we should be able to form cliques: (i.e. If A == B and B == C, then A == C)\n",
    "for tile1_hash, tile1_dups in tile_hash_dup_dict.items():\n",
    "    for tile1_dup1 in sorted(tile1_dups):\n",
    "        for tile1_dup2 in sorted(tile1_dups):\n",
    "            if tile1_dup1 <= tile1_dup2:\n",
    "                continue\n",
    "            tile_hash_dup_dict[tile1_dup1].add(tile1_dup2)\n",
    "            tile_hash_dup_dict[tile1_dup2].add(tile1_dup1)\n",
    "\n",
    "neighbor_counts = Counter()\n",
    "for tile1_hash, tile1_dups in tile_hash_dup_dict.items():\n",
    "    neighbor_counts[len(tile1_dups)] += 1\n",
    "list(sorted(neighbor_counts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels_0 = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dif_dict[tile2_hash]:\n",
    "            assert tile2_hash in tile_hash_dif_dict[tile1_hash]\n",
    "            auto_overlap_labels_0[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "            break\n",
    "\n",
    "print(len(auto_overlap_labels_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels_1 = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dup_dict[tile2_hash]:\n",
    "            assert tile2_hash in tile_hash_dup_dict[tile1_hash]\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        auto_overlap_labels_1[(img1_id, img2_id, img1_overlap_tag)] = 1\n",
    "\n",
    "print(len(auto_overlap_labels_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cliques via networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_hash_dup_cliques = nx.Graph()\n",
    "tile_hash_dif_cliques = nx.Graph()\n",
    "\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in dup_truth.items():\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        if is_dup:\n",
    "            if tile1_hash in solid_hashes or tile2_hash in solid_hashes:\n",
    "                continue\n",
    "            update_tile_cliques(tile_hash_dup_cliques, tile1_hash, tile2_hash)\n",
    "        else:\n",
    "            if tile1_hash == tile2_hash:\n",
    "                continue\n",
    "            tile_hash_dif_cliques.add_edge(tile1_hash, tile2_hash)\n",
    "\n",
    "print(tile_hash_dup_cliques.number_of_nodes(), tile_hash_dif_cliques.number_of_nodes())\n",
    "\n",
    "neighbor_counts = Counter()\n",
    "for tile_hashes in nx.connected_components(tile_hash_dup_cliques):\n",
    "    neighbor_counts[len(tile_hashes)] += 1\n",
    "list(sorted(neighbor_counts.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels_0 = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dif_cliques and tile2_hash in set(nx.neighbors(tile_hash_dif_cliques, tile1_hash)):\n",
    "            auto_overlap_labels_0[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "            break\n",
    "\n",
    "print(len(auto_overlap_labels_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels_1 = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dup_cliques and tile2_hash in set(nx.neighbors(tile_hash_dup_cliques, tile1_hash)):\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        auto_overlap_labels_1[(img1_id, img2_id, img1_overlap_tag)] = 1\n",
    "\n",
    "print(len(auto_overlap_labels_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels = {}\n",
    "for key in auto_overlap_labels_0:\n",
    "    assert key not in auto_overlap_labels_1\n",
    "auto_overlap_labels.update(auto_overlap_labels_0)\n",
    "auto_overlap_labels.update(auto_overlap_labels_1)\n",
    "print(len(auto_overlap_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    if (img1_id, img2_id, img1_overlap_tag) in auto_overlap_labels:\n",
    "        continue\n",
    "    is_dup = 1\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dif_cliques and tile2_hash in set(nx.neighbors(tile_hash_dif_cliques, tile1_hash)):\n",
    "            is_dup = 0\n",
    "            break\n",
    "        elif tile1_hash in tile_hash_dup_cliques and tile2_hash in set(nx.neighbors(tile_hash_dup_cliques, tile1_hash)):\n",
    "            continue\n",
    "        else:\n",
    "            is_dup = -1\n",
    "\n",
    "    if is_dup == -1:\n",
    "        continue\n",
    "    \n",
    "    auto_overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = is_dup\n",
    "\n",
    "print(len(auto_overlap_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth = update_duplicate_truth(auto_overlap_labels, auto=True)\n",
    "len(dup_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_candidates = []\n",
    "for candidate in tqdm_notebook(sorted(overlap_candidates, key=operator.attrgetter('px0_max', 'shp_max'), reverse=True)):\n",
    "    duplicate_candidates.append(candidate.idx)\n",
    "print(len(duplicate_candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an interactive widget for tagging duplicate overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import Button, Image, Layout, Box, HBox, VBox, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_iter = iter(duplicate_candidates)\n",
    "n_candidates = len(duplicate_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_labels = {}\n",
    "auto_overlap_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "img1_id = None\n",
    "img2_id = None\n",
    "img1_overlap_tag = None\n",
    "candidates_idx = 0\n",
    "box_layout = Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    align_items='stretch',\n",
    "                    width='100%')\n",
    "\n",
    "white_tile_hash = '0139c6c3'\n",
    "\n",
    "def get_next_img_pair():\n",
    "    global img1_id, img2_id, img1_overlap_tag, candidates_idx\n",
    "    n_skip = 0\n",
    "    i_skip = 0\n",
    "    \n",
    "    while True:\n",
    "        img1_id, img2_id, img1_overlap_tag = next(candidates_iter)\n",
    "        candidates_idx += 1\n",
    "        \n",
    "        if i_skip < n_skip:\n",
    "            i_skip += 1\n",
    "            continue\n",
    "            \n",
    "        assert img1_id < img2_id\n",
    "        \n",
    "        if (img1_id, img2_id, img1_overlap_tag) in overlap_labels:\n",
    "            continue\n",
    "        \n",
    "        if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "            continue\n",
    "        \n",
    "#         if (img1_id, img2_id, img1_overlap_tag) in weak_preds:\n",
    "#             break\n",
    "#         else:\n",
    "#             continue\n",
    "        \n",
    "        is_dup = 1\n",
    "        for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "\n",
    "            tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "            tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "\n",
    "            if tile1_hash in tile_hash_dif_cliques and tile2_hash in set(nx.neighbors(tile_hash_dif_cliques, tile1_hash)):\n",
    "                is_dup = 0\n",
    "                break\n",
    "            elif tile1_hash in tile_hash_dup_cliques and tile2_hash in set(nx.neighbors(tile_hash_dup_cliques, tile1_hash)):\n",
    "                continue\n",
    "            else:\n",
    "                is_dup = -1\n",
    "\n",
    "        if is_dup == 1:\n",
    "            auto_overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = 1\n",
    "            update_tile_hash_dup_cliques(img1_id, img2_id, img1_overlap_tag)\n",
    "            continue\n",
    "        elif is_dup == 0:\n",
    "            auto_overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "            update_tile_hash_dif_cliques(img1_id, img2_id, img1_overlap_tag)\n",
    "            continue\n",
    "            \n",
    "#         scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "        \n",
    "#         if max(scores.pix) > 256*256*3*255 * 0.33:\n",
    "#             auto_overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "#             continue\n",
    "        \n",
    "#         tst5a = np.all(white_tile_hash == sdcic.tile_md5hash_grids[img1_id][img1_overlap_map])\n",
    "#         tst5b = np.all(white_tile_hash == sdcic.tile_md5hash_grids[img2_id][img2_overlap_map])\n",
    "#         tst8 = max(scores.pix) == 0\n",
    "        \n",
    "#         if tst5a and tst5b and tst8: # perfect white on white\n",
    "#             continue\n",
    "\n",
    "#         if tst5a or tst5b: # perfect white on any\n",
    "#             continue\n",
    "\n",
    "        break\n",
    "\n",
    "    return img1_id, img2_id, img1_overlap_tag\n",
    "\n",
    "def draw_images(img1_id, img2_id, img1_overlap_tag):\n",
    "    global candidates_idx\n",
    "    \n",
    "    scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "    \n",
    "    dtick = 256\n",
    "    n_ticks = imgmod1.shape[1] // dtick + 1\n",
    "    ticks = [i * dtick for i in range(n_ticks)]\n",
    "\n",
    "    slice1 = overlap_tag_slices[img1_overlap_tag]\n",
    "    slice2 = overlap_tag_slices[overlap_tag_pairs[img1_overlap_tag]]\n",
    "\n",
    "    m12 = np.median(np.vstack([imgmod1.parent_rgb[slice1], imgmod2.parent_rgb[slice2]]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "    img1_drop = imgmod1.parent_rgb - m12\n",
    "    img2_drop = imgmod2.parent_rgb - m12\n",
    "        \n",
    "    brightness_level = -100 if np.sum(m12) >= 384 else 100\n",
    "    img1 = imgmod1.channel_shift('L', brightness_level)\n",
    "    img2 = imgmod2.channel_shift('L', brightness_level)\n",
    "    \n",
    "    if (img1_id, img2_id, img1_overlap_tag) in dup_truth:\n",
    "        bbox_color = GREEN if dup_truth[(img1_id, img2_id, img1_overlap_tag)] else RED\n",
    "    else:\n",
    "        bbox_color = LIGHT_BLUE\n",
    "        \n",
    "    bbox_thickness = 5\n",
    "    offset = (bbox_thickness // 2) + 1\n",
    "    offset_array = np.array([[offset], [-offset]])\n",
    "    img1_bbox_pt1, img1_bbox_pt2 = boundingbox_corners[img1_overlap_tag] + offset_array\n",
    "    img2_bbox_pt1, img2_bbox_pt2 = boundingbox_corners[overlap_tag_pairs[img1_overlap_tag]] + offset_array\n",
    "    \n",
    "    img1[slice1] = img1_drop[slice1]\n",
    "    img2[slice2] = img2_drop[slice2]\n",
    "    cv2.rectangle(img1, tuple(img1_bbox_pt1), tuple(img1_bbox_pt2), bbox_color, bbox_thickness)\n",
    "    cv2.rectangle(img2, tuple(img2_bbox_pt1), tuple(img2_bbox_pt2), bbox_color, bbox_thickness)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    ax[0][0].imshow(img1)\n",
    "#     ax[0][0].set_title(f'{candidates_idx/n_candidates:6.3f} {img1_id} {np.min(scores.bmh):7.5f}')\n",
    "    ax[0][0].set_title(f'{img1_id} bmh: {np.min(scores.bmh):7.5f} cmh: {np.min(scores.cmh):7.5f}')\n",
    "    ax[0][0].set_xticks(ticks)\n",
    "    ax[0][0].set_yticks(ticks)\n",
    "\n",
    "    ax[0][1].imshow(img2)\n",
    "    ax[0][1].set_title(f'{img2_id} hom: {np.min(scores.hom):7.5f} eng: {np.min(scores.eng):7.5f}')\n",
    "    ax[0][1].set_xticks(ticks)\n",
    "    ax[0][1].set_yticks(ticks)\n",
    "    \n",
    "    img1[slice1] = imgmod1.parent_rgb[slice1]\n",
    "    img2[slice2] = imgmod2.parent_rgb[slice2]\n",
    "    cv2.rectangle(img1, tuple(img1_bbox_pt1), tuple(img1_bbox_pt2), bbox_color, bbox_thickness)\n",
    "    cv2.rectangle(img2, tuple(img2_bbox_pt1), tuple(img2_bbox_pt2), bbox_color, bbox_thickness)\n",
    "\n",
    "    ax[1][0].imshow(img1)\n",
    "    ax[1][0].set_title(f'con: {np.min(scores.con):7.5f} cor: {np.min(scores.cor):7.5f}')\n",
    "    ax[1][0].set_xticks(ticks)\n",
    "    ax[1][0].set_yticks(ticks)\n",
    "\n",
    "    ax[1][1].imshow(img2)\n",
    "    ax[1][1].set_title(f'epy: {np.min(scores.epy):5.3f} enp: {np.min(scores.enp):5.3f} {np.max(scores.pix)}')\n",
    "    ax[1][1].set_xticks(ticks)\n",
    "    ax[1][1].set_yticks(ticks)\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "def redraw(img1_id, img2_id, img1_overlap_tag):\n",
    "    out.clear_output(True)\n",
    "    with out:\n",
    "        ax = draw_images(img1_id, img2_id, img1_overlap_tag)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tile_hash_dup_cliques(img1_id, img2_id, img1_overlap_tag):\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        if tile1_hash in solid_hashes or tile2_hash in solid_hashes:\n",
    "            continue\n",
    "        update_tile_cliques(tile_hash_dup_cliques, tile1_hash, tile2_hash)\n",
    "\n",
    "\n",
    "def update_tile_hash_dif_cliques(img1_id, img2_id, img1_overlap_tag):\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        if tile1_hash == tile2_hash:\n",
    "            continue\n",
    "        tile_hash_dif_cliques.add_edge(tile1_hash, tile2_hash)\n",
    "\n",
    "\n",
    "same_button = Button(\n",
    "    description='Same',\n",
    "    disabled=False,\n",
    "    layout=Layout(flex='1 1 auto', width='auto'), \n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Overlays are the same',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "diff_button = Button(\n",
    "    description='Diff',\n",
    "    disabled=False,\n",
    "    layout=Layout(flex='1 1 auto', width='auto'), \n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Overlays are different',\n",
    "    icon='x'\n",
    ")\n",
    "\n",
    "skip_button = Button(\n",
    "    description='Skip',\n",
    "    disabled=False,\n",
    "    layout=Layout(flex='1 1 auto', width='auto'), \n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Not sure.  Skip for now.',\n",
    "    icon='?'\n",
    ")\n",
    "\n",
    "def on_same_button_clicked(b):\n",
    "    global img1_id, img2_id, img1_overlap_tag\n",
    "    overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = 1\n",
    "    \n",
    "    update_tile_hash_dup_cliques(img1_id, img2_id, img1_overlap_tag)\n",
    "    \n",
    "    img1_id, img2_id, img1_overlap_tag = get_next_img_pair()\n",
    "    redraw(img1_id, img2_id, img1_overlap_tag)\n",
    "    \n",
    "def on_diff_button_clicked(b):\n",
    "    global img1_id, img2_id, img1_overlap_tag\n",
    "    overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "    \n",
    "    update_tile_hash_dif_cliques(img1_id, img2_id, img1_overlap_tag)\n",
    "    \n",
    "    img1_id, img2_id, img1_overlap_tag = get_next_img_pair()\n",
    "    redraw(img1_id, img2_id, img1_overlap_tag)\n",
    "    \n",
    "def on_skip_button_clicked(b):\n",
    "    global img1_id, img2_id, img1_overlap_tag\n",
    "    img1_id, img2_id, img1_overlap_tag = get_next_img_pair()\n",
    "    redraw(img1_id, img2_id, img1_overlap_tag)\n",
    "\n",
    "same_button.on_click(on_same_button_clicked)\n",
    "diff_button.on_click(on_diff_button_clicked)\n",
    "skip_button.on_click(on_skip_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = Output()\n",
    "buttons_3 = Box(children=[same_button, diff_button, skip_button], layout=box_layout)\n",
    "display(VBox([out, buttons_3]))\n",
    "\n",
    "img1_id, img2_id, img1_overlap_tag = get_next_img_pair()\n",
    "with out:\n",
    "    ax = draw_images(img1_id, img2_id, img1_overlap_tag)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print details of current iteration\n",
    "scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print our progress\n",
    "len(overlap_labels), len(auto_overlap_labels), candidates_idx, n_candidates, 100*len(overlap_labels)/n_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undo last\n",
    "for k in overlap_labels:\n",
    "    continue\n",
    "print(k)\n",
    "del overlap_labels[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge overlap_labels into truth\n",
    "print(len(dup_truth))\n",
    "dup_truth = update_duplicate_truth(overlap_labels, auto=False)\n",
    "print(len(dup_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, overlap_label in enumerate(overlap_labels):\n",
    "    if overlap_labels[overlap_label] == 1:\n",
    "        print(ii, overlap_label, overlap_labels[overlap_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels_0 = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    \n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    assert img1_id < img2_id\n",
    "    if (img1_id, img2_id, img1_overlap_tag) in overlap_labels:\n",
    "        continue\n",
    "    if (img1_id, img2_id, img1_overlap_tag) in auto_overlap_labels_0:\n",
    "        continue\n",
    "\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dif_cliques and tile2_hash in set(nx.neighbors(tile_hash_dif_cliques, tile1_hash)):\n",
    "            auto_overlap_labels_0[(img1_id, img2_id, img1_overlap_tag)] = 0\n",
    "            break\n",
    "\n",
    "print(len(auto_overlap_labels_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels_1 = {}\n",
    "\n",
    "for candidate in overlap_candidates:\n",
    "    \n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    assert img1_id < img2_id\n",
    "    if (img1_id, img2_id, img1_overlap_tag) in overlap_labels:\n",
    "        continue\n",
    "    if (img1_id, img2_id, img1_overlap_tag) in auto_overlap_labels_1:\n",
    "        continue\n",
    "\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dup_cliques and tile2_hash in set(nx.neighbors(tile_hash_dup_cliques, tile1_hash)):\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        auto_overlap_labels_1[(img1_id, img2_id, img1_overlap_tag)] = 1\n",
    "\n",
    "print(len(auto_overlap_labels_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_overlap_labels = {}\n",
    "for key in auto_overlap_labels_0:\n",
    "    assert key not in auto_overlap_labels_1\n",
    "auto_overlap_labels.update(auto_overlap_labels_0)\n",
    "auto_overlap_labels.update(auto_overlap_labels_1)\n",
    "print(len(auto_overlap_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're stopping early from labelling, you can run this to pick up any unvisited overlaps that our cliques would have gotten\n",
    "for candidate in candidates_iter:\n",
    "    img1_id, img2_id, img1_overlap_tag = candidate.idx\n",
    "    \n",
    "    if (img1_id, img2_id, img1_overlap_tag) in auto_overlap_labels:\n",
    "        continue\n",
    "\n",
    "    is_dup = 1\n",
    "    for idx1, idx2 in img_overlap_index_maps[img1_overlap_tag]:\n",
    "        \n",
    "        tile1_hash = sdcic.tile_md5hash_grids[img1_id][idx1]\n",
    "        tile2_hash = sdcic.tile_md5hash_grids[img2_id][idx2]\n",
    "        \n",
    "        if tile1_hash in tile_hash_dif_cliques and tile2_hash in set(nx.neighbors(tile_hash_dif_cliques, tile1_hash)):\n",
    "            is_dup = 0\n",
    "            break\n",
    "        elif tile1_hash in tile_hash_dup_cliques and tile2_hash in set(nx.neighbors(tile_hash_dup_cliques, tile1_hash)):\n",
    "            continue\n",
    "        else:\n",
    "            is_dup = -1\n",
    "\n",
    "    if is_dup == -1:\n",
    "        continue\n",
    "    \n",
    "    auto_overlap_labels[(img1_id, img2_id, img1_overlap_tag)] = is_dup\n",
    "        \n",
    "print(len(auto_overlap_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth = update_duplicate_truth(auto_overlap_labels, auto=True)\n",
    "print(len(dup_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the performance of DupNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = []\n",
    "tile_pairs = []\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in tqdm_notebook(dup_truth.items()):\n",
    "    for overlap_idx, (idx1, idx2) in enumerate(img_overlap_index_maps[img1_overlap_tag]):\n",
    "        tile_pairs.append(TilePairs(img1_id, img2_id, img1_overlap_tag, overlap_idx, idx1, idx2))\n",
    "        ytrue.append(is_dup)\n",
    "print(len(tile_pairs), sum(ytrue), len(ytrue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(tile_pairs)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=256, num_workers=12)\n",
    "test_dl = WrappedDataLoader(test_dl, preprocess)\n",
    "print(len(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint('models/dup_model.best.pth')\n",
    "model.cuda()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yprobs0 = [model(xb) for xb in tqdm_notebook(test_dl)]\n",
    "    yprobs = np.vstack([l.cpu() for l in yprobs0]).reshape(-1)\n",
    "    print(len(yprobs0), yprobs.shape, min(yprobs), max(yprobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_cnn_tile_scores = {}\n",
    "for tp, yprob in zip(tile_pairs, yprobs):\n",
    "    \n",
    "    if (tp.img1_id, tp.img2_id) not in overlap_cnn_tile_scores:\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)] = {}\n",
    "    \n",
    "    if tp.img1_overlap_tag not in overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)]:\n",
    "        n_overlapping_tiles = len(img_overlap_index_maps[tp.img1_overlap_tag])\n",
    "        cnn_scores = np.zeros(n_overlapping_tiles)\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag] = cnn_scores\n",
    "    \n",
    "    overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag][tp.overlap_idx] = yprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_Stats = namedtuple('dnn_stats', ['yprob', 'ypred', 'ytrue', 'loss', 'yconf', 'pix'])\n",
    "\n",
    "dup_dict = {}\n",
    "for (img1_id, img2_id, img1_overlap_tag), ytrue in tqdm_notebook(dup_truth.items()):\n",
    "    assert img1_id < img2_id\n",
    "\n",
    "    if (img1_id, img2_id, img1_overlap_tag) in dup_dict:\n",
    "        continue\n",
    "    if (img1_id, img2_id) not in overlap_image_maps:\n",
    "        continue\n",
    "    if img1_overlap_tag not in overlap_image_maps[(img1_id, img2_id)]:\n",
    "        continue\n",
    "    scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    if len(scores.pix) < 2:\n",
    "        continue\n",
    "    pix = max(scores.pix)\n",
    "#     if (img1_id, img2_id) not in overlap_cnn_tile_scores:\n",
    "#         continue\n",
    "#     if img1_overlap_tag not in overlap_cnn_tile_scores[(img1_id, img2_id)]:\n",
    "#         continue\n",
    "\n",
    "    dcnn_scores_raw = overlap_cnn_tile_scores[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    dcnn_conf_raw = np.abs((dcnn_scores_raw - 0.5) * 2) # confidence? (1: very, 0: not at all)\n",
    "    yconf = np.min(dcnn_conf_raw)\n",
    "    yprob = np.min(dcnn_scores_raw)\n",
    "    ypred = (yprob > 0.5) * 1\n",
    "    assert ypred <= 1\n",
    "    \n",
    "    if ytrue:\n",
    "        bce = - ytrue * np.log(yprob)\n",
    "    else:\n",
    "        bce = - (1 - ytrue) * np.log(1 - yprob)\n",
    "    \n",
    "    dup_dict[(img1_id, img2_id, img1_overlap_tag)] = DNN_Stats(yprob, ypred, ytrue, bce, yconf, pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_Stats2 = namedtuple('dnn_stats', ['key', 'yprob', 'ypred', 'ytrue', 'loss', 'yconf', 'pix'])\n",
    "dup_dict_flat = []\n",
    "for keys, dnns in tqdm_notebook(dup_dict.items()):\n",
    "    dup_dict_flat.append(DNN_Stats2(keys, dnns.yprob, dnns.ypred, dnns.ytrue, dnns.loss, dnns.yconf, dnns.pix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_correct = 0\n",
    "id_tags = []\n",
    "for dnns in tqdm_notebook(sorted(dup_dict_flat, key=operator.attrgetter('loss'), reverse=True)):\n",
    "\n",
    "    # Skip the ones the dnn got correct.\n",
    "    if dnns.ypred == dnns.ytrue:\n",
    "        n_correct += 1\n",
    "        continue\n",
    "        \n",
    "#     if dnns.key[2] != '08':\n",
    "#         continue\n",
    "#     if not dnns.ytrue:\n",
    "#         continue\n",
    "#     if (dnns.key[0], dnns.key[1]) not in overlap_image_maps:\n",
    "#         continue\n",
    "\n",
    "    if dnns.loss == np.nan:\n",
    "        print('nan ', dnns)\n",
    "        id_tags.append(dnns.key)\n",
    "        continue\n",
    "    if dnns.loss == np.inf:\n",
    "        print('+inf', dnns)\n",
    "        id_tags.append(dnns.key)\n",
    "        continue\n",
    "    if dnns.loss == -np.inf:\n",
    "        print('-inf', dnns)\n",
    "        id_tags.append(dnns.key)\n",
    "        continue\n",
    "        \n",
    "#     Skip the ones the dnn was certain about.\n",
    "#     if dnns.yprob < 0.01 or dnns.yprob > 0.99:\n",
    "#         continue\n",
    "\n",
    "    id_tags.append(dnns.key)\n",
    "len(id_tags), n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_counter = Counter()\n",
    "for img1_id, img2_id, img1_overlap_tag in id_tags:\n",
    "    tags_counter[img1_id] += 1\n",
    "    tags_counter[img2_id] += 1\n",
    "print(len(tags_counter))\n",
    "\n",
    "for k, v in sorted(tags_counter.items(), key=operator.itemgetter(0), reverse=False):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa = 0\n",
    "n_samples = 10\n",
    "use_median_shift = True\n",
    "\n",
    "test_files = id_tags[aa * n_samples: (aa + 1) * n_samples]#[::-1]\n",
    "for f in test_files:\n",
    "    print(f, '{:.5} {} {} {:.5} {:.5} {}'.format(*dup_dict[f]))\n",
    "\n",
    "dtick = 256\n",
    "n_ticks = 768 // dtick + 1\n",
    "ticks = [i * dtick for i in range(n_ticks)]\n",
    "\n",
    "fig, m_axs = plt.subplots(n_samples, 2, figsize = (12, 6 * n_samples))\n",
    "for ii, (img1_id, img2_id, img1_overlap_tag) in enumerate(test_files):\n",
    "    \n",
    "    scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    \n",
    "    (ax1, ax2) = m_axs[ii]\n",
    "    yprob, ypred, is_dup, loss, yconf, pix = dup_dict[(img1_id, img2_id, img1_overlap_tag)]\n",
    "    \n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "\n",
    "    slice1 = overlap_tag_slices[img1_overlap_tag]\n",
    "    slice2 = overlap_tag_slices[overlap_tag_pairs[img1_overlap_tag]]\n",
    "\n",
    "    m12 = np.median(np.vstack([imgmod1.parent_rgb[slice1], imgmod2.parent_rgb[slice2]]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "    \n",
    "    brightness_level = -100 if np.sum(m12) >= 384 else 100\n",
    "    img1 = imgmod1.channel_shift('L', brightness_level)\n",
    "    img2 = imgmod2.channel_shift('L', brightness_level)\n",
    "    \n",
    "    if use_median_shift:\n",
    "        img1_drop = imgmod1.parent_rgb - m12\n",
    "        img2_drop = imgmod2.parent_rgb - m12\n",
    "    else:        \n",
    "        img1_drop = imgmod1.parent_rgb\n",
    "        img2_drop = imgmod2.parent_rgb\n",
    "    \n",
    "    img1[slice1] = img1_drop[slice1]\n",
    "    img2[slice2] = img2_drop[slice2]\n",
    "\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(f'{img1_id} {yprob:6.4} ({is_dup})')\n",
    "    ax1.set_xticks(ticks)\n",
    "    ax1.set_yticks(ticks)\n",
    "\n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title(f'{img2_id} {loss:4.2f} {max(scores.pix)}')\n",
    "    ax2.set_xticks(ticks)\n",
    "    ax2.set_yticks(ticks)\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(os.path.join('temp', BASE_MODEL, f\"{train_meta_filebase}_{score_str}_batch_{BATCH_NUM}_row_{aa+1}.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out a decision tree classifier for dup_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_maps = 0\n",
    "missing_tags = 0\n",
    "L = []\n",
    "X = []\n",
    "Y = []\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in dup_truth.items():\n",
    "    \n",
    "    if (img1_id, img2_id) not in overlap_image_maps:\n",
    "        missing_maps += 1\n",
    "        continue\n",
    "    overlap_maps = overlap_image_maps[(img1_id, img2_id)]\n",
    "    if img1_overlap_tag not in overlap_maps:\n",
    "        missing_tags += 1\n",
    "        continue\n",
    "    scores = overlap_maps[img1_overlap_tag]\n",
    "    if len(scores.pix) < 2:\n",
    "        continue\n",
    "    \n",
    "    L.append((img1_id, img2_id, img1_overlap_tag))\n",
    "    X.append([\n",
    "        dup_dict[(img1_id, img2_id, img1_overlap_tag)].ypred,\n",
    "        dup_dict[(img1_id, img2_id, img1_overlap_tag)].loss,\n",
    "#         min(scores.bmh),\n",
    "#         min(scores.cmh),\n",
    "#         max(scores.pix), \n",
    "#         min(scores.pyr),\n",
    "#         max(scores.enp),\n",
    "    ])\n",
    "    Y.append([is_dup])\n",
    "\n",
    "L = np.array(L)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "# X = [[0, 0], [1, 1]]\n",
    "# Y = [0, 1]\n",
    "\n",
    "print(missing_maps)\n",
    "print(missing_tags)\n",
    "print(len(X))\n",
    "print(len(Y), sum(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "dot_data = tree.export_graphviz(\n",
    "    clf, \n",
    "    out_file=None, \n",
    "    feature_names=[\n",
    "        'ypred',\n",
    "        'loss',\n",
    "#         'min(bmh)', \n",
    "#         'min(cmh)', \n",
    "#         'max(pix)', \n",
    "#         'min(pyr)', \n",
    "#         'max(enp)',\n",
    "    ], \n",
    "    filled=True, \n",
    "    rounded=True, \n",
    "    special_characters=True, \n",
    "    leaves_parallel=True) \n",
    "\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = clf.apply(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = np.where(all_nodes == 3)\n",
    "np.argmin(X[nodes]), np.min(X[nodes]), np.argmax(X[nodes]), np.max(X[nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 36\n",
    "print(L[nodes][idx], Y[nodes][idx], X[nodes][idx])\n",
    "print(overlap_image_maps[(L[nodes][idx][0], L[nodes][idx][1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tricky_examples_9 = [\n",
    "    ['e28669903.jpg', 'ed2998ef7.jpg', '08', 1],\n",
    "    ['66482462b.jpg', 'e2497099c.jpg', '08', 1],\n",
    "    ['73fec0637.jpg', '8b0219c19.jpg', '08', 0],\n",
    "]\n",
    "\n",
    "tricky_examples_6 = [\n",
    "    ['00ce2c1c0.jpg', '68ef625ba.jpg', '18', 1],\n",
    "    ['01178499a.jpg', '7a7a0034a.jpg', '05', 1],\n",
    "    ['1ebdf2f08.jpg', 'b1bfb768c.jpg', '05', 1],  # [91.          0.99781223]\n",
    "    ['d4f0aaa70.jpg', 'd84d4a78a.jpg', '05', 0],  # [5.95230000e+04 9.98578088e-01] \n",
    "    ['012d8cca1.jpg', 'bc45cee87.jpg', '07', 1],\n",
    "    ['2323bf875.jpg', 'b5da61fce.jpg', '07', 1],  # [2.05663500e+06 9.98277186e-01]\n",
    "    ['7f2be2b0a.jpg', '84dcdc7af.jpg', '07', 0],\n",
    "    ['089858a56.jpg', '903a8b121.jpg', '38', 1],\n",
    "    ['468bf9178.jpg', '6090b3a8b.jpg', '38', 1],  # [1.30900000e+03 9.97640283e-01]\n",
    "    ['d843fc5ca.jpg', 'e805070df.jpg', '38', 1],\n",
    "    ['000194a2d.jpg', '384765ab2.jpg', '38', 1],\n",
    "    ['0ef6cd331.jpg', 'e6a6f80cd.jpg', '38', 0],  # [1.72270000e+04 9.98394555e-01]\n",
    "]\n",
    "\n",
    "tricky_examples_4 = [\n",
    "    ['0a33ce967.jpg', '3964f0cee.jpg', '04', 1],\n",
    "    ['d164aea52.jpg', 'fded6e12d.jpg', '04', 1],\n",
    "    ['c3193fb05.jpg', 'cc68e7818.jpg', '15', 0],  # [2.16300000e+04 9.98311792e-01]\n",
    "    ['331987f64.jpg', '4869b48b6.jpg', '15', 0],\n",
    "    ['0318fc519.jpg', 'b7feb225a.jpg', '37', 1],\n",
    "    ['7234a3a53.jpg', 'dc6534704.jpg', '37', 1],\n",
    "    ['de6fb187d.jpg', 'ea6dc23b7.jpg', '37', 1],  # [223.           0.99544613]\n",
    "    ['cd3c59923.jpg', 'efdd03319.jpg', '37', 0],  # [6.70246000e+05 9.99894307e-01] \n",
    "    ['0c279107f.jpg', '3b1314d5d.jpg', '37', 0],\n",
    "    ['42f02a4a4.jpg', '7d31648ff.jpg', '58', 0],  # '48' ???\n",
    "]\n",
    "\n",
    "tricky_examples_3 = [\n",
    "    ['204906e27.jpg', '892a69b4b.jpg', '02', 1],  # [6.31644000e+05 9.97614902e-01]\n",
    "    ['813c8ec35.jpg', 'caa94ffc3.jpg', '06', 0],  # [1.76759000e+05 9.99834742e-01]\n",
    "    ['0256ef90d.jpg', '46da51931.jpg', '06', 0],  # [3.70260000e+05 9.99319673e-01]\n",
    "    ['0ee790381.jpg', 'ac87bcee5.jpg', '06', 0],\n",
    "    ['2f6c0deaa.jpg', 'e44a4f5b0.jpg', '28', 1],  # [24.          0.99509307]\n",
    "    ['0ef6cd331.jpg', '813c8ec35.jpg', '28', 0],  # [1.79442000e+05 9.98195859e-01]\n",
    "    ['4c56d2f00.jpg', 'dcd94e973.jpg', '68', 1],  # [6.31635000e+05 9.97534103e-01]\n",
    "    ['b645cd49b.jpg', 'f2e554691.jpg', '68', 1],  # [3.76847000e+05 9.96659721e-01]\n",
    "    ['b998c7415.jpg', 'd4d26f700.jpg', '68', 1],  # [3.76847000e+05 9.96680501e-01]\n",
    "    ['0ef6cd331.jpg', '3a9e579aa.jpg', '68', 0],  # [1.62810000e+04 9.98394555e-01]\n",
    "    ['a61b3e245.jpg', 'd84d4a78a.jpg', '68', 0],  # [2.59134100e+06 9.99175738e-01]\n",
    "    ['2095da0cb.jpg', '45b1a4561.jpg', '68', 0],\n",
    "]\n",
    "\n",
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_pair(img1_id, img2_id, img1_overlap_tag, is_dup):\n",
    "    \n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "    dcnn_scores_raw = overlap_cnn_tile_scores[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    print(dcnn_scores_raw)\n",
    "#     print(sdcic.tile_entropy_grids[img1_id])\n",
    "#     print(sdcic.tile_entropy_grids[img2_id])\n",
    "    print(is_dup, overlap_image_maps[(img1_id, img2_id)])\n",
    "    \n",
    "    dtick = 256\n",
    "    n_ticks = imgmod1.shape[1] // dtick + 1\n",
    "    ticks = [i * dtick for i in range(n_ticks)]\n",
    "\n",
    "    slice1 = overlap_tag_slices[img1_overlap_tag]\n",
    "    slice2 = overlap_tag_slices[overlap_tag_pairs[img1_overlap_tag]]\n",
    "\n",
    "    cmh2 = img_hash.colorMomentHash(imgmod1.parent_rgb[slice1])\n",
    "    cmh1 = img_hash.colorMomentHash(imgmod2.parent_rgb[slice2])\n",
    "    score0_norm = np.linalg.norm(cmh1 - cmh2)\n",
    "    score0_expnorm = np.exp(-score0_norm)\n",
    "    print(len(imgmod1.parent_rgb[slice1]), len(cmh1[0]))\n",
    "#     print(cmh1.reshape((6, 7)))\n",
    "#     print(cmh2.reshape((6, 7)))\n",
    "    print(score0_expnorm, score0_norm)\n",
    "    \n",
    "    m12 = np.median(np.vstack([imgmod1.parent_rgb[slice1], imgmod2.parent_rgb[slice2]]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "    \n",
    "    brightness_level = -100 if np.sum(m12) >= 384 else 100\n",
    "    img1 = imgmod1.channel_shift('L', brightness_level)\n",
    "    img2 = imgmod2.channel_shift('L', brightness_level)\n",
    "    \n",
    "    img1_drop = imgmod1.parent_rgb - m12\n",
    "    img2_drop = imgmod2.parent_rgb - m12\n",
    "    \n",
    "    img1[slice1] = img1_drop[slice1]\n",
    "    img2[slice2] = img2_drop[slice2]\n",
    "\n",
    "    img1_overlap_map = overlap_tag_maps[img1_overlap_tag]\n",
    "    img2_overlap_map = overlap_tag_maps[overlap_tag_pairs[img1_overlap_tag]]\n",
    "\n",
    "    for idx1, idx2 in zip(img1_overlap_map, img2_overlap_map):\n",
    "        \n",
    "        print(f'tile {idx1} / tile {idx2}')\n",
    "        tile1 = get_tile(imgmod1.parent_rgb, idx1)\n",
    "        tile2 = get_tile(imgmod2.parent_rgb, idx2)\n",
    "        score0 = fuzzy_compare(tile1, tile2)\n",
    "        \n",
    "        bmh1_0 = img_hash.blockMeanHash(tile1)\n",
    "        bmh2_0 = img_hash.blockMeanHash(tile2)\n",
    "        score0_hamm = get_hamming_distance(bmh1_0, bmh2_0, normalize=True, as_score=True)\n",
    "#         print(bmh1_0)\n",
    "#         print(bmh2_0)\n",
    "\n",
    "        cmh1_0 = img_hash.colorMomentHash(tile1)\n",
    "        cmh2_0 = img_hash.colorMomentHash(tile2)\n",
    "        score0_norm = np.linalg.norm(cmh1_0 - cmh2_0)\n",
    "        score0_expnorm = np.exp(-score0_norm)\n",
    "#         print(cmh1_0.reshape((6, 7)))\n",
    "#         print(cmh2_0.reshape((6, 7)))\n",
    "        \n",
    "        tile1_drop = get_tile(img1_drop, idx1)\n",
    "        tile2_drop = get_tile(img2_drop, idx2)\n",
    "        score1 = fuzzy_compare(tile1_drop, tile2_drop)\n",
    "\n",
    "        bmh1_1 = img_hash.blockMeanHash(tile1_drop)\n",
    "        bmh2_1 = img_hash.blockMeanHash(tile2_drop)\n",
    "        score1_hamm = get_hamming_distance(bmh1_1, bmh2_1, normalize=True, as_score=True)\n",
    "#         print(bmh1_1)\n",
    "#         print(bmh2_1)\n",
    "        \n",
    "        cmh1_1 = img_hash.colorMomentHash(tile1_drop)\n",
    "        cmh2_1 = img_hash.colorMomentHash(tile2_drop)\n",
    "        score1_norm = np.linalg.norm(cmh1_1 - cmh2_1)\n",
    "        score1_expnorm = np.exp(-score1_norm)\n",
    "#         print(cmh1_1.reshape((6, 7)))\n",
    "#         print(cmh2_1.reshape((6, 7)))\n",
    "        \n",
    "        m12_tile = np.median(np.vstack([tile1, tile2]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "        tile1_drop = tile1 - m12_tile\n",
    "        tile2_drop = tile2 - m12_tile\n",
    "        score2 = fuzzy_compare(tile1_drop, tile2_drop)\n",
    "        \n",
    "        bmh1_2 = img_hash.blockMeanHash(tile1_drop)\n",
    "        bmh2_2 = img_hash.blockMeanHash(tile2_drop)\n",
    "        score2_hamm = get_hamming_distance(bmh1_2, bmh2_2, normalize=True, as_score=True)\n",
    "#         print(bmh1_2)\n",
    "#         print(bmh2_2)\n",
    "        \n",
    "        cmh1_2 = img_hash.colorMomentHash(tile1_drop)\n",
    "        cmh2_2 = img_hash.colorMomentHash(tile2_drop)\n",
    "        score2_norm = np.linalg.norm(cmh1_2 - cmh2_2)\n",
    "        score2_expnorm = np.exp(-score2_norm)\n",
    "#         print(cmh1_2.reshape((6, 7)))\n",
    "#         print(cmh2_2.reshape((6, 7)))\n",
    "        \n",
    "        print(f'{score0:10.8f}, {score0_hamm:10.8f}, {score0_norm:10.8f}, {score0_expnorm:10.8f}')\n",
    "        print(f'{score1:10.8f}, {score1_hamm:10.8f}, {score1_norm:10.8f}, {score1_expnorm:10.8f}', m12)\n",
    "        print(f'{score2:10.8f}, {score2_hamm:10.8f}, {score2_norm:10.8f}, {score2_expnorm:10.8f}', m12_tile)\n",
    "        \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "    \n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(f'{img1_id}')\n",
    "    ax1.set_xticks(ticks)\n",
    "    ax1.set_yticks(ticks)\n",
    "    \n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title(f'{img2_id}')\n",
    "    ax2.set_xticks(ticks)\n",
    "    ax2.set_yticks(ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_image_pair(*tricky_examples_6[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
