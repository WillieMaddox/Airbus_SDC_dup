{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import operator\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from cv2 import img_hash\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.util import montage\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import tile_ij2idx, tile_idx2ij\n",
    "from utils import overlay_tag_pairs\n",
    "from utils import overlay_tag_maps\n",
    "from utils import generate_overlay_tag_slices\n",
    "from utils import generate_pair_tag_lookup\n",
    "from utils import get_tile\n",
    "from utils import channel_shift\n",
    "from utils import read_duplicate_truth\n",
    "from utils import update_duplicate_truth\n",
    "from utils import read_image_duplicate_tiles\n",
    "from utils import write_image_duplicate_tiles\n",
    "from utils import read_image_image_duplicate_tiles\n",
    "from utils import update_image_image_duplicate_tiles\n",
    "from utils import generate_overlay_tag_nines_mask\n",
    "\n",
    "from test_friend_circles import SDCImageContainer\n",
    "\n",
    "from dupnet import load_checkpoint\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "EPS = np.finfo(np.float32).eps\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title\n",
    "\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "montage_pad = lambda x, *args, **kwargs: montage(x, padding_width=10, *args, **kwargs)\n",
    "\n",
    "ship_dir = \"data/input\"\n",
    "train_image_dir = os.path.join(ship_dir, \"train_768\")\n",
    "train_mask_dir = os.path.join(ship_dir, 'train_masks_768')\n",
    "image_md5hash_grids_file = os.path.join(\"data\", \"image_md5hash_grids.pkl\")\n",
    "image_bm0hash_grids_file = os.path.join(\"data\", \"image_bm0hash_grids.pkl\")\n",
    "image_entropy_grids_file = os.path.join(\"data\", \"image_entropy_grids.pkl\")\n",
    "image_duplicate_tiles_file = os.path.join(\"data\", \"image_duplicate_tiles.txt\")\n",
    "image_image_duplicate_tiles_file = os.path.join(\"data\", \"image_image_duplicate_tiles.txt\")\n",
    "duplicate_truth_file = os.path.join('data', 'duplicate_truth.txt')\n",
    "\n",
    "overlay_tag_slices = generate_overlay_tag_slices()\n",
    "pair_tag_lookup = generate_pair_tag_lookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_compare(tile1, tile2):\n",
    "    maxab = np.max(np.stack([tile1, tile2]), axis=0)\n",
    "    a = maxab - tile2\n",
    "    b = maxab - tile1\n",
    "    ab = a + b\n",
    "    n = np.prod(maxab.shape)\n",
    "    return np.sum(255 - ab) / (255 * n)\n",
    "\n",
    "def fuzzy_diff(tile1, tile2):\n",
    "    maxab = np.max(np.stack([tile1, tile2]), axis=0)\n",
    "    a = maxab - tile2\n",
    "    b = maxab - tile1\n",
    "    ab = a + b\n",
    "    return np.sum(ab)\n",
    "\n",
    "def slice_from_large(img, idx, sz=256):\n",
    "    tile = get_tile(img, idx, sz=sz)\n",
    "    return cv2.cvtColor(tile, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def check_fuzzy_diff(img1, img2, overlay_tag):\n",
    "    slice1 = overlay_tag_slices[overlay_tag]\n",
    "    slice2 = overlay_tag_slices[overlay_tag_pairs[overlay_tag]]\n",
    "    score = fuzzy_diff(img1[slice1], img2[slice2])\n",
    "    return score\n",
    "\n",
    "def check_fuzzy_score(img1, img2, overlay_tag):\n",
    "    slice1 = overlay_tag_slices[overlay_tag]\n",
    "    slice2 = overlay_tag_slices[overlay_tag_pairs[overlay_tag]]\n",
    "    score = fuzzy_compare(img1[slice1], img2[slice2])\n",
    "    return score\n",
    "\n",
    "def get_overlay_score(img1, img2, overlay_tag, sz=256, mode=0):\n",
    "    overlay_map1 = overlay_tag_maps[overlay_tag]\n",
    "    overlay_map2 = overlay_tag_maps[overlay_tag_pairs[overlay_tag]]\n",
    "    bmh1_list = []\n",
    "    bmh2_list = []\n",
    "    for ((i, j), (k, l)) in zip(overlay_map1, overlay_map2):\n",
    "        idx1 = tile_ij2idx[(i, j)]\n",
    "        idx2 = tile_ij2idx[(k, l)]\n",
    "        tile1 = get_tile(img1, idx1, sz=sz)\n",
    "        tile2 = get_tile(img2, idx2, sz=sz)\n",
    "        bmh1 = img_hash.blockMeanHash(tile1, mode=mode)\n",
    "        bmh2 = img_hash.blockMeanHash(tile2, mode=mode)\n",
    "        bmh1_list.append(bmh1)\n",
    "        bmh2_list.append(bmh2)\n",
    "    bmh1_arr = np.vstack(bmh1_list)\n",
    "    bmh2_arr = np.vstack(bmh2_list)\n",
    "    score = fuzzy_compare(bmh1_arr, bmh2_arr)\n",
    "    return score\n",
    "\n",
    "def get_tile_scores(img1, img2, overlay_tag, sz=256, mode=0):    \n",
    "    overlay_map1 = overlay_tag_maps[overlay_tag]\n",
    "    overlay_map2 = overlay_tag_maps[overlay_tag_pairs[overlay_tag]]\n",
    "    scores = []\n",
    "    for ((i, j), (k, l)) in zip(overlay_map1, overlay_map2):\n",
    "        idx1 = tile_ij2idx[(i, j)]\n",
    "        idx2 = tile_ij2idx[(k, l)]\n",
    "        tile1 = get_tile(img1, idx1, sz=sz)\n",
    "        tile2 = get_tile(img2, idx2, sz=sz)\n",
    "        bmh1 = img_hash.blockMeanHash(tile1, mode=mode)\n",
    "        bmh2 = img_hash.blockMeanHash(tile2, mode=mode)\n",
    "        score = fuzzy_compare(bmh1, bmh2)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def get_pixel_scores(img1, img2, overlay_tag, sz=256):\n",
    "    overlay_map1 = overlay_tag_maps[overlay_tag]\n",
    "    overlay_map2 = overlay_tag_maps[overlay_tag_pairs[overlay_tag]]\n",
    "    scores = []\n",
    "    for ((i, j), (k, l)) in zip(overlay_map1, overlay_map2):\n",
    "        idx1 = tile_ij2idx[(i, j)]\n",
    "        idx2 = tile_ij2idx[(k, l)]\n",
    "        tile1 = get_tile(img1, idx1, sz=sz)\n",
    "        tile2 = get_tile(img2, idx2, sz=sz)\n",
    "        score = fuzzy_diff(tile1, tile2)\n",
    "        scores.append(score)\n",
    "    return np.array(scores)\n",
    "\n",
    "def get_dcnn_scores(img1, img2, overlay_map, model, sz=256):    \n",
    "    overlay_map1 = overlay_tag_maps[overlay_tag]\n",
    "    overlay_map2 = overlay_tag_maps[overlay_tag_pairs[overlay_tag]]\n",
    "    X_list = []\n",
    "    for ((i, j), (k, l)) in zip(overlay_map1, overlay_map2):\n",
    "        idx1 = tile_ij2idx[(i, j)]\n",
    "        idx2 = tile_ij2idx[(k, l)]\n",
    "        tile1 = slice_from_large(img1, idx1, sz=sz).astype(np.float32) / 255.0\n",
    "        tile2 = slice_from_large(img2, idx2, sz=sz).astype(np.float32) / 255.0\n",
    "        X = np.dstack([tile1, tile2])\n",
    "        X = X.transpose((2, 0, 1))\n",
    "        X_list.append(X)\n",
    "\n",
    "    X_arr = np.stack(X_list)\n",
    "    inputs = torch.from_numpy(X_arr)\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        val_outputs = model(inputs)\n",
    "\n",
    "#     y_pred = val_outputs > 0.5\n",
    "    return val_outputs[:, 0].cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdcic = SDCImageContainer(train_image_dir)\n",
    "sdcic.load_3x3_grids(\n",
    "    image_md5hash_grids_file,\n",
    "    image_bm0hash_grids_file,\n",
    "    image_entropy_grids_file,\n",
    "    image_duplicate_tiles_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlapping images using hashlib\n",
    "Update: The values between two supposedly exact 256x256 crops are not exact (See below).  Not sure how to use a \"friend circles\" algorithm for overlap testing/grouping.  I defer this work to a later date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md5hash_dict = defaultdict(list)\n",
    "img_ids = os.listdir(train_image_dir)\n",
    "\n",
    "for img_id in tqdm_notebook(img_ids):\n",
    "    for h in sdcic.tile_md5hash_grids[img_id]:\n",
    "        md5hash_dict[h].append(img_id)\n",
    "\n",
    "dup_counts_dict = defaultdict(int)\n",
    "for key, dups in md5hash_dict.items():\n",
    "    dup_counts_dict[len(dups)] += 1\n",
    "\n",
    "sorted_bin_sizes = sorted(dup_counts_dict.items())\n",
    "sorted_bin_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot our groupings and make sure images have a common tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "skip = 365\n",
    "ii = 0\n",
    "jj = 0\n",
    "batch_limit = 9\n",
    "samples_images = np.empty((batch_limit, 768, 768, 3), dtype=np.float32)\n",
    "\n",
    "for hash_id, dups in md5hash_dict.items():\n",
    "    ii += 1\n",
    "    if len(dups) == batch_size:\n",
    "        dups0 = list(set(dups))\n",
    "        img_id = dups0[0]\n",
    "        idx = sdcic.tile_md5hash_grids[img_id].index(hash_id)\n",
    "        print(hash_id, len(dups), ii, sdcic.tile_entropy_grids[img_id][idx])\n",
    "        if jj == min(dup_counts_dict[len(dups)], skip):\n",
    "            break\n",
    "        jj += 1\n",
    "\n",
    "for i, c_img_id in enumerate(dups0[:batch_limit]):\n",
    "    c_img = cv2.cvtColor(sdcic.get_img(c_img_id), cv2.COLOR_BGR2RGB)\n",
    "    samples_images[i] = c_img.astype(np.float32) / 255.0\n",
    "\n",
    "batch_rgb = montage_rgb(samples_images)\n",
    "print(samples_images.shape)\n",
    "print(batch_rgb.shape, batch_rgb.dtype)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16, 16))\n",
    "ax.imshow(batch_rgb, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "# plt.savefig(os.path.join('out', BASE_MODEL, f\"{train_meta_filebase}_{score_str}_batch_{BATCH_NUM}.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlapping images using cv2.img_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm0hash_dict = defaultdict(list)\n",
    "img_ids = os.listdir(train_image_dir)\n",
    "\n",
    "for img_id in tqdm_notebook(img_ids):\n",
    "    for h in sdcic.tile_bm0hash_grids[img_id]:\n",
    "        bm0hash_dict[tuple(h)].append(img_id)  # hex\n",
    "\n",
    "dup_counts_dict = defaultdict(int)\n",
    "for key, dups in bm0hash_dict.items():\n",
    "    dup_counts_dict[len(dups)] += 1\n",
    "\n",
    "sorted_bin_sizes = sorted(dup_counts_dict.items())\n",
    "sorted_bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 18\n",
    "skip = 5\n",
    "ii = 0\n",
    "jj = 0\n",
    "batch_limit = 9\n",
    "samples_images = np.empty((batch_limit, 768, 768, 3), dtype=np.float32)\n",
    "\n",
    "for hash_id, dups in bm0hash_dict.items():\n",
    "    ii += 1\n",
    "    if len(dups) == batch_size:\n",
    "        dups0 = list(set(dups))\n",
    "        img_id = dups0[0]\n",
    "        idx = sdcic.tile_bm0hash_grids[img_id].index(hash_id)\n",
    "        print(hash_id, len(dups), ii, sdcic.tile_entropy_grids[img_id][idx])\n",
    "        if jj == min(dup_counts_dict[len(dups)], skip):\n",
    "            break\n",
    "        jj += 1\n",
    "\n",
    "for i, c_img_id in enumerate(dups0[:batch_limit]):\n",
    "    c_img = cv2.cvtColor(sdcic.get_img(c_img_id), cv2.COLOR_BGR2RGB)\n",
    "    samples_images[i] = c_img.astype(np.float32) / 255.0\n",
    "\n",
    "batch_rgb = montage_rgb(samples_images)\n",
    "print(samples_images.shape)\n",
    "print(batch_rgb.shape, batch_rgb.dtype)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16, 16))\n",
    "ax.imshow(batch_rgb, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "# plt.savefig(os.path.join('out', BASE_MODEL, f\"{train_meta_filebase}_{score_str}_batch_{BATCH_NUM}.jpg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_images = ['03ffa7680.jpg', '8d5521663.jpg', '5a70ef013.jpg', '9a2f9d347.jpg', '37a912dca.jpg', '4add7aa1d.jpg', '3db3ef7cc.jpg', '73fec0637.jpg', '7df214d98.jpg', 'c2955cd21.jpg', 'de018b2a8.jpg', '8ce769141.jpg', 'fc0e22a0a.jpg', '770c46cd4.jpg', 'd6e432b79.jpg', 'd5d1b6fb8.jpg', '0e4d7dd93.jpg', '9ddeed533.jpg', 'addc11de0.jpg', '65418dfe4.jpg', '119d6a3d6.jpg', '1b287c905.jpg', 'b264b0f96.jpg', '996f92939.jpg', 'e5c3b1f59.jpg']\n",
    "fig, ax = plt.subplots(5, 5, figsize=(15, 15))\n",
    "for i, img_id in enumerate(black_images):\n",
    "    img = cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ax[i // 5, i % 5].imshow(img)\n",
    "    ax[i // 5, i % 5].set_title(img_id)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth = read_duplicate_truth(duplicate_truth_file)\n",
    "len(dup_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")          # a CUDA device object\n",
    "model = load_checkpoint('out/dup_model.last.pth')\n",
    "model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth1 = {}\n",
    "for key, is_dup in dup_truth.items():\n",
    "    if not is_dup:\n",
    "        dup_truth1[key] = is_dup\n",
    "len(dup_truth1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ii = 1\n",
    "dup_dict = {}\n",
    "for (img1_id, img2_id, overlay_tag), is_dup in dup_truth1.items():\n",
    "    ii += 1\n",
    "    if img1_id > img2_id:\n",
    "        img1_id, img2_id = img2_id, img1_id\n",
    "        overlay_tag = overlay_tag_pairs[overlay_tag]\n",
    "\n",
    "    if (img1_id, img2_id, overlay_tag) in dup_dict:\n",
    "        continue\n",
    "\n",
    "    img1 = cv2.imread(os.path.join(train_image_dir, img1_id))\n",
    "    img2 = cv2.imread(os.path.join(train_image_dir, img2_id))\n",
    "\n",
    "    entropy_score = get_entropy3(img1_id, img2_id, overlay_tag)\n",
    "    image_score = get_overlay_score(img1, img2, overlay_tag)\n",
    "    pixel_scores = get_pixel_scores(img1, img2, overlay_tag)\n",
    "    tiles_score = get_tile_scores(img1, img2, overlay_tag)\n",
    "    dcnn_scores_raw = get_dcnn_scores(img1, img2, overlay_tag, model)\n",
    "    dcnn_scores = (dcnn_scores_raw > 0.5) * 1\n",
    "\n",
    "    dup_dict[(img1_id, img2_id, overlay_tag)] = (is_dup, image_score, min(tiles_score))\n",
    "\n",
    "    if is_dup == np.max(dcnn_scores) == 0:\n",
    "        continue\n",
    "\n",
    "    if is_dup == np.min(dcnn_scores) == 1:\n",
    "        continue\n",
    "\n",
    "#     print(f\"{ii:>3} {img1_id} {img2_id}               {is_dup} {np.min(dcnn_scores)} {image_score:6.4f}, {min(tiles_score):6.4f}]\", pixel_scores, dcnn_scores_raw)\n",
    "    print(f\"{ii:>3} {img1_id} {img2_id} {overlay_tag} {is_dup} {entropy_score} {image_score}\")\n",
    "    print(pixel_scores)\n",
    "#     print(dcnn_scores)\n",
    "    print(dcnn_scores_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (img_id1, img_id2, overlay_tag), (is_dup, image_score, tiles_score) in dup_dict.items():\n",
    "#     if is_dup < 0:\n",
    "#         continue\n",
    "    \n",
    "    filename = os.path.join('temp', f\"{img_id1}_{img_id2}\")\n",
    "    if os.path.exists(filename):\n",
    "        continue\n",
    "\n",
    "    img1 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, img_id1)), cv2.COLOR_BGR2RGB)\n",
    "    img2 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, img_id2)), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    image_score = get_overlay_score(img1, img2, '0022', sz=256)\n",
    "    tiles_score = get_tile_scores(img1, img2, '0022', sz=256)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "    ax1.imshow(img1)\n",
    "    title1 = f'({image_score:7.5f}) {img_id1}'\n",
    "    ax1.set_title(title1)\n",
    "    \n",
    "    ax2.imshow(img2)\n",
    "    title2 = f'({min(tiles_score):7.5f}) {img_id2}'\n",
    "    ax2.set_title(title2)\n",
    "    \n",
    "    fig.savefig(filename)\n",
    "    fig.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 1769472\n",
    "\n",
    "def get_channel_entropy(ctr):\n",
    "    ctr_norm = {k: v / img_size for k, v in ctr.items()}\n",
    "    ctr_entropy = {k: -v * np.log(v) for k, v in ctr_norm.items()}\n",
    "    entropy = np.sum([k * v for k, v in ctr_entropy.items()])\n",
    "    return entropy\n",
    "\n",
    "def get_entropy(img_id):\n",
    "    img = cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    img_grad = np.gradient(img.astype(np.int), axis=(0, 1))\n",
    "    entropy_vec = []\n",
    "    for channel_grad in img_grad:\n",
    "        ctr = Counter(np.abs(channel_grad).flatten())\n",
    "        ctr_sorted = {k: v for k, v in sorted(ctr.items())}\n",
    "        entropy_vec.append(get_channel_entropy(ctr_sorted))\n",
    "    return np.array(entropy_vec)\n",
    "\n",
    "def get_channel_entropy2(ctr1, ctr2):\n",
    "    ctr = (ctr1 - ctr2) + (ctr2 - ctr1)\n",
    "    ctr_norm = {k: v / img_size for k, v in sorted(ctr.items())}\n",
    "    ctr_entropy = {k: -v * np.log(v) for k, v in ctr_norm.items()}\n",
    "    entropy = np.sum([k * v for k, v in ctr_entropy.items()])\n",
    "    return entropy\n",
    "\n",
    "def get_entropy1(img_id):\n",
    "    img = cv2.imread(os.path.join(train_image_dir, img_id))\n",
    "    img_grad = np.gradient(img.astype(np.int), 0.5, axis=(0, 1))\n",
    "    entropy_list = []\n",
    "    for channel_grad in img_grad:\n",
    "        ctr = Counter(np.abs(channel_grad).flatten())\n",
    "        ctr = Counter(np.abs(channel_grad).astype(np.uint8).flatten())\n",
    "        entropy_list.append(ctr)\n",
    "    return entropy_list\n",
    "\n",
    "def get_entropy2(img1_id, img2_id):\n",
    "    entropy1_list = get_entropy1(img1_id)\n",
    "    entropy2_list = get_entropy1(img2_id)\n",
    "    entropy_vec = []\n",
    "    for ctr1, ctr2 in zip(entropy1_list, entropy2_list):\n",
    "        entropy_vec.append(get_channel_entropy2(ctr1, ctr2))\n",
    "    return np.array(entropy_vec)\n",
    "\n",
    "def get_entropy3(img1_id, img2_id, overlay_tag1):\n",
    "    overlay_map1 = overlay_tag_maps[overlay_tag1]\n",
    "    overlay_map2 = overlay_tag_maps[overlay_tag_pairs[overlay_tag1]]\n",
    "    entropy_list = []\n",
    "    for ((i, j), (k, l)) in zip(overlay_map1, overlay_map2):\n",
    "        idx1 = tile_ij2idx[(i, j)]\n",
    "        idx2 = tile_ij2idx[(k, l)]\n",
    "        e1 = sdcic.tile_entropy_grids[img1_id][idx1]\n",
    "        e2 = sdcic.tile_entropy_grids[img2_id][idx2]\n",
    "        entropy = np.linalg.norm(((e1 + e2) / 2))\n",
    "        entropy_list.append(entropy)\n",
    "    score = np.mean(entropy_list)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we explore dup detection using image gradients and cross entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id1 = '691d5afc2.jpg'\n",
    "img_id2 = '56417e7af.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_lim0 = 0\n",
    "score_lim1 = 1\n",
    "for (img_id1, img_id2), (is_dup, image_score, tiles_score) in dup_dict.items():\n",
    "    entropy_vec1 = get_entropy(img_id1)\n",
    "    entropy_vec2 = get_entropy(img_id2)\n",
    "    n_vec1 = np.linalg.norm(entropy_vec1)\n",
    "    n_vec2 = np.linalg.norm(entropy_vec2)\n",
    "    n_vec = np.max([n_vec1, n_vec2])\n",
    "    scaled_vec1 = entropy_vec1 / n_vec\n",
    "    scaled_vec2 = entropy_vec2 / n_vec\n",
    "    grad_score = 1.0 - np.linalg.norm(scaled_vec1 - scaled_vec2)\n",
    "    \n",
    "    if is_dup == 0 and grad_score > score_lim0:\n",
    "        score_lim0 = grad_score\n",
    "        print_score = True\n",
    "    elif is_dup == 1 and grad_score < score_lim1:\n",
    "        score_lim1 = grad_score\n",
    "        print_score = True\n",
    "    else:\n",
    "        print_score = False\n",
    "        \n",
    "    if print_score:\n",
    "        entropy2 = get_entropy2(img_id1, img_id2)\n",
    "        entropy2_norm = np.linalg.norm(entropy3)\n",
    "        print('')\n",
    "        print(f\"{is_dup}, {image_score:7.5f}, {tiles_score:7.5f}, {grad_score:7.5f}, {entropy2_norm}\")\n",
    "        print(img_id1, entropy_vec1, f\"{n_vec1}\")\n",
    "        print(img_id2, entropy_vec2, f\"{n_vec2}\")\n",
    "#         print(get_entropy(img_id1))\n",
    "#         print(get_entropy(img_id2))\n",
    "        print(entropy2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(train_image_dir, img_id2))\n",
    "img_grad = np.gradient(img.astype(np.int), 0.5, axis=(0, 1))\n",
    "ctr2 = Counter(np.abs(img_grad[0]).astype(np.uint8).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_vec1 = get_entropy(img_id1)\n",
    "entropy_vec2 = get_entropy(img_id2)\n",
    "n_vec1 = np.linalg.norm(entropy_vec1)\n",
    "n_vec2 = np.linalg.norm(entropy_vec2)\n",
    "n_vec = np.max([n_vec1, n_vec2])\n",
    "scaled_vec1 = entropy_vec1 / n_vec\n",
    "scaled_vec2 = entropy_vec2 / n_vec\n",
    "print('')\n",
    "print(img_id1, entropy_vec1, f\"{n_vec1}\")\n",
    "print(img_id2, entropy_vec2, f\"{n_vec2}\")\n",
    "print(f\"{is_dup}, {image_score:7.5f}, {tiles_score:7.5f} {np.linalg.norm(scaled_vec1 - scaled_vec2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dup_blacklist_6.csv', sep=', ')\n",
    "for idx, row in df.iterrows():\n",
    "    print(idx)\n",
    "    entropy_vec1 = get_entropy(row['ImageId1'])\n",
    "    entropy_vec1_u = entropy_vec1 / np.linalg.norm(entropy_vec1)\n",
    "    print(row['ImageId1'], entropy_vec1)\n",
    "    entropy_vec2 = get_entropy(row['ImageId2'])\n",
    "    entropy_vec2_u = entropy_vec2 / np.linalg.norm(entropy_vec2)\n",
    "    print(row['ImageId2'], entropy_vec2)\n",
    "    print(np.dot(entropy_vec1_u, entropy_vec2_u), np.linalg.norm(entropy_vec1 - entropy_vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an interactive widget for tagging duplicate overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import Button, Image, Layout, Box, HBox, VBox, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgMod:\n",
    "    \"\"\"\n",
    "    Reads a single image to be modified by hls.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.img_id = filename.split('/')[-1]\n",
    "\n",
    "        self._hls_chan = None\n",
    "        self._hls_gain = None\n",
    "\n",
    "        self._parent_bgr = None\n",
    "        self._parent_hls = None\n",
    "        self._parent_rgb = None\n",
    "        self._cv2_hls = None\n",
    "        self._cv2_bgr = None\n",
    "        self._cv2_rgb = None\n",
    "\n",
    "    def channel_shift(self, chan, gain):\n",
    "        self._hls_chan = chan\n",
    "        self._hls_gain = gain\n",
    "        self._cv2_hls = None\n",
    "        return self.cv2_rgb\n",
    "    \n",
    "    def scale(self, minval, maxval):\n",
    "        m = 255.0 * (maxval - minval)\n",
    "        res = m * (self.parent_bgr - minval)\n",
    "        return np.around(res).astype(np.uint8)\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.parent_bgr.shape\n",
    "    \n",
    "    @property\n",
    "    def parent_bgr(self):\n",
    "        if self._parent_bgr is None:\n",
    "            self._parent_bgr = cv2.imread(self.filename)\n",
    "        return self._parent_bgr\n",
    "\n",
    "    @property\n",
    "    def parent_hls(self):\n",
    "        if self._parent_hls is None:\n",
    "            self._parent_hls = self.to_hls(self.parent_bgr)\n",
    "        return self._parent_hls\n",
    "\n",
    "    @property\n",
    "    def parent_rgb(self):\n",
    "        if self._parent_rgb is None:\n",
    "            self._parent_rgb = self.to_rgb(self.parent_bgr)\n",
    "        return self._parent_rgb\n",
    "\n",
    "    @property\n",
    "    def cv2_hls(self):\n",
    "        if self._cv2_hls is None:\n",
    "            if self._hls_gain == None:\n",
    "                self._cv2_hls = self.parent_hls\n",
    "            else:\n",
    "                self._cv2_hls = channel_shift(self.parent_hls, self._hls_chan, self._hls_gain)\n",
    "        return self._cv2_hls\n",
    "\n",
    "    @property\n",
    "    def cv2_bgr(self):\n",
    "        if self._cv2_bgr is None:\n",
    "            self._cv2_bgr = self.to_bgr(self.cv2_hls)\n",
    "        return self._cv2_bgr\n",
    "\n",
    "    @property\n",
    "    def cv2_rgb(self):\n",
    "        if self._cv2_rgb is None:\n",
    "            self._cv2_rgb = self.to_rgb(self.cv2_bgr)\n",
    "        return self._cv2_rgb\n",
    "\n",
    "    def to_hls(self, bgr):\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2HLS_FULL)\n",
    "\n",
    "    def to_bgr(self, hls):\n",
    "        return cv2.cvtColor(hls, cv2.COLOR_HLS2BGR_FULL)\n",
    "\n",
    "    def to_rgb(self, bgr):\n",
    "        return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_matching_tiles = 6\n",
    "# n_matching_tiles = 4\n",
    "# n_matching_tiles = 3\n",
    "overlay_matches_file = os.path.join(\"data\", f\"overlay_matches_{n_matching_tiles}.pkl\")\n",
    "\n",
    "df = pd.read_pickle(overlay_matches_file)\n",
    "for row in tqdm_notebook(df.to_dict('split')['data']):\n",
    "    sdcic.matches[(row[0], row[1])].append((row[2], row[3], row[4:]))\n",
    "\n",
    "sdcic.image_image_duplicate_tiles = read_image_image_duplicate_tiles(image_image_duplicate_tiles_file)\n",
    "\n",
    "for img_id12, values in sorted(sdcic.matches.items()):\n",
    "    p0 = len(set([v[0] for v in values]))  # all have the same overlay_tag\n",
    "    if len(values) >= 1 and p0 == 1:\n",
    "        tag, overlay_score, tile_scores = values[0]\n",
    "        sdcic.update_overlay_maps(img_id12[0], img_id12[1], tag, overlay_score=overlay_score, tile_scores=tile_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_candidates = []\n",
    "for img1_id in tqdm_notebook(sdcic.overlay_image_maps):\n",
    "    for overlay_tag1, overlay_dict in sdcic.overlay_image_maps[img1_id].items():\n",
    "        if len(overlay_dict) > 1:\n",
    "            continue\n",
    "        for img2_id, (overlay_score, tile_scores) in overlay_dict.items():\n",
    "            if img1_id > img2_id:\n",
    "                continue\n",
    "            if (img1_id, img2_id, overlay_tag1) in dup_truth:\n",
    "                continue\n",
    "            entropy_score = get_entropy3(img1_id, img2_id, overlay_tag1)\n",
    "            imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "            imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "            pixel_score = check_fuzzy_diff(imgmod1.parent_bgr, imgmod2.parent_bgr, overlay_tag1)\n",
    "            overlay_candidates.append((img1_id, img2_id, overlay_tag1, entropy_score, pixel_score))\n",
    "\n",
    "overlay_tag_nines_mask = generate_overlay_tag_nines_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_candidates = []\n",
    "for img1_id, img2_id, overlay_tag1, overlay_score, tiles_score in sorted(overlay_candidates, key = operator.itemgetter(4, 0), reverse=True):\n",
    "    img1_nine, img2_nine = sdcic.image_image_duplicate_tiles[(img1_id, img2_id)]\n",
    "    img1_nines_mask = overlay_tag_nines_mask[overlay_tag1]\n",
    "    img2_nines_mask = overlay_tag_nines_mask[overlay_tag_pairs[overlay_tag1]]\n",
    "    img1_mask = img1_nine[img1_nines_mask]\n",
    "    img2_mask = img2_nine[img2_nines_mask]\n",
    "    \n",
    "    # This is here so I don't forget to address small 2 tile or 1 tile overlays later.\n",
    "    if len(img1_mask) <= 2:\n",
    "        print(img1_mask, img2_mask)\n",
    "        continue\n",
    "    \n",
    "    # (0, 3, 6) == (0, 3, 6) is exact duplicate\n",
    "    if len(set(img1_mask)) == len(img1_mask) and np.all(img1_mask == img2_mask) and 9 not in img1_mask:\n",
    "        continue\n",
    "    \n",
    "    # (0, 0, 0) == (0, 0, 0) skip probably is duplicate of white clouds, or blue border.\n",
    "    if len(set(img1_mask) | set(img2_mask)) == 1 and 9 not in img1_mask:\n",
    "        continue\n",
    "    \n",
    "    # (0, 0, 0) == (2, 2, 2) is NOT duplicate. probably white clouds overlay with blue boarder\n",
    "#     if len(set(img1_mask)) == 1 and len(set(img2_mask)) == 1 and set(img1_mask) != set(img2_mask) and 9 not in img1_mask and 9 not in img2_mask:\n",
    "#         continue\n",
    "        \n",
    "#     if len(set(img1_mask)) == 1 and len(set(img2_mask)) != 1 and 9 not in img1_mask:\n",
    "#         if set(img1_mask) != set(img2_mask):\n",
    "#         continue\n",
    "    \n",
    "    duplicate_candidates.append((img1_id, img2_id, overlay_tag1, overlay_score, tiles_score))\n",
    "\n",
    "print(len(overlay_candidates), len(duplicate_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_iter = iter(duplicate_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_button = Button(\n",
    "    description='Same',\n",
    "    disabled=False,\n",
    "    layout=Layout(flex='1 1 auto', width='auto'), \n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Overlays are the same',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "diff_button = Button(\n",
    "    description='Diff',\n",
    "    disabled=False,\n",
    "    layout=Layout(flex='1 1 auto', width='auto'), \n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Overlays are different',\n",
    "    icon='x'\n",
    ")\n",
    "\n",
    "skip_button = Button(\n",
    "    description='Skip',\n",
    "    disabled=False,\n",
    "    layout=Layout(flex='1 1 auto', width='auto'), \n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Not sure.  Skip for now.',\n",
    "    icon='?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "img_id1 = None\n",
    "img_id2 = None\n",
    "overlay_tag = None\n",
    "\n",
    "box_layout = Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    align_items='stretch',\n",
    "                    width='100%')\n",
    "\n",
    "def get_next_img_pair():\n",
    "    global img_id1, img_id2, overlay_tag\n",
    "    \n",
    "    while True:\n",
    "        img_id1, img_id2, overlay_tag, overlay_score, tiles_score = next(candidates_iter)\n",
    "        \n",
    "        if img_id1 > img_id2:\n",
    "            continue\n",
    "        \n",
    "        if (img_id1, img_id2, overlay_tag) in overlay_labels:\n",
    "            continue\n",
    "        \n",
    "        img1_nine, img2_nine = sdcic.image_image_duplicate_tiles[(img_id1, img_id2)]\n",
    "        img1_nines_mask = overlay_tag_nines_mask[overlay_tag]\n",
    "        img2_nines_mask = overlay_tag_nines_mask[overlay_tag_pairs[overlay_tag]]\n",
    "        img1_mask = img1_nine[img1_nines_mask]\n",
    "        img2_mask = img2_nine[img2_nines_mask]\n",
    "\n",
    "        if len(set(img1_mask)) == 1 and len(set(img2_mask)) == 1 and set(img1_mask) != set(img2_mask) and 9 not in img1_mask and 9 not in img2_mask:\n",
    "            overlay_labels[(img_id1, img_id2, overlay_tag)] = 0\n",
    "            continue\n",
    "\n",
    "        imgmod1 = ImgMod(os.path.join(train_image_dir, img_id1))\n",
    "        imgmod2 = ImgMod(os.path.join(train_image_dir, img_id2))\n",
    "    \n",
    "        if check_fuzzy_diff(imgmod1.parent_bgr, imgmod2.parent_bgr, overlay_tag) < 160:\n",
    "            overlay_labels[(img_id1, img_id2, overlay_tag)] = 1\n",
    "            continue\n",
    "            \n",
    "        if check_fuzzy_score(imgmod1.parent_bgr, imgmod2.parent_bgr, overlay_tag) < 0.4:\n",
    "            overlay_labels[(img_id1, img_id2, overlay_tag)] = 0\n",
    "            continue\n",
    "        \n",
    "        break\n",
    "\n",
    "    return imgmod1, imgmod2, img_id1, img_id2, overlay_tag\n",
    "\n",
    "def draw_images(imgmod1, imgmod2, img_id1, img_id2, overlay_tag1):\n",
    "    dtick = 256\n",
    "    n_ticks = imgmod1.shape[1] // dtick + 1\n",
    "    ticks = [i * dtick for i in range(n_ticks)]\n",
    "\n",
    "#     image_score = get_overlay_score(imgmod1.parent_bgr, imgmod2.parent_bgr, overlay_tag1)\n",
    "    image_score = get_entropy3(img_id1, img_id2, overlay_tag1)\n",
    "    tile_scores = get_tile_scores(imgmod1.parent_bgr, imgmod2.parent_bgr, overlay_tag1)\n",
    "    \n",
    "    slice1 = overlay_tag_slices[overlay_tag1]\n",
    "    slice2 = overlay_tag_slices[overlay_tag_pairs[overlay_tag1]]\n",
    "\n",
    "    m12 = np.median(np.vstack([imgmod1.parent_rgb, imgmod2.parent_rgb]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "    \n",
    "#     brightness_level1 = 100 if np.mean(imgmod2.parent_rgb) <= 128 else -100\n",
    "    brightness_level = -100 if np.sum(m12) >= 384 else 100\n",
    "    img1 = imgmod1.channel_shift('L', brightness_level)\n",
    "    img2 = imgmod2.channel_shift('L', brightness_level)\n",
    "    \n",
    "    img1_drop = imgmod1.parent_rgb - m12\n",
    "    img2_drop = imgmod2.parent_rgb - m12\n",
    "    img_nine1, img_nine2 = sdcic.image_image_duplicate_tiles[(img_id1, img_id2)]\n",
    "    img_mask1 = overlay_tag_nines_mask[overlay_tag1]\n",
    "    img_mask2 = overlay_tag_nines_mask[overlay_tag_pairs[overlay_tag1]]\n",
    "    img_dups1_str = ' '.join(list(map(str, img_nine1[img_mask1])))\n",
    "    img_dups2_str = ' '.join(list(map(str, img_nine2[img_mask2])))\n",
    "    \n",
    "    img1[slice1] = img1_drop[slice1]\n",
    "    img2[slice2] = img2_drop[slice2]\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    ax[0][0].imshow(img1)\n",
    "    title1 = f'{img_id1} {image_score:7.5f}'\n",
    "    ax[0][0].set_title(title1)\n",
    "    ax[0][0].set_xticks(ticks)\n",
    "    ax[0][0].set_yticks(ticks)\n",
    "\n",
    "    ax[0][1].imshow(img2)\n",
    "    title2 = f'{img_id2} {min(tile_scores):7.5f}'\n",
    "    ax[0][1].set_title(title2)\n",
    "    ax[0][1].set_xticks(ticks)\n",
    "    ax[0][1].set_yticks(ticks)\n",
    "    \n",
    "    img1[slice1] = imgmod1.parent_rgb[slice1]\n",
    "    img2[slice2] = imgmod2.parent_rgb[slice2]\n",
    "\n",
    "    fuzzy_compare_score = fuzzy_compare(imgmod1.parent_rgb[slice1], imgmod2.parent_rgb[slice2])\n",
    "    fuzzy_diff_score = fuzzy_diff(imgmod1.parent_rgb[slice1], imgmod2.parent_rgb[slice2])\n",
    "    \n",
    "    ax[1][0].imshow(img1)\n",
    "    title1 = f'{fuzzy_compare_score:7.5f} ({img_dups1_str})'\n",
    "#     title1 = f'{img_id1} ({img_dups1_str})'\n",
    "#     title1 = f'{img_id1}'\n",
    "    ax[1][0].set_title(title1)\n",
    "    ax[1][0].set_xticks(ticks)\n",
    "    ax[1][0].set_yticks(ticks)\n",
    "\n",
    "    ax[1][1].imshow(img2)\n",
    "    title2 = f'{fuzzy_diff_score} ({img_dups2_str})'\n",
    "#     title2 = f'{img_id2} ({img_dups2_str})'\n",
    "#     title2 = f'{img_id2}'\n",
    "    ax[1][1].set_title(title2)\n",
    "    ax[1][1].set_xticks(ticks)\n",
    "    ax[1][1].set_yticks(ticks)\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "def redraw(imgmod1, imgmod2, img_id1, img_id2, overlay_tag):\n",
    "    out.clear_output(True)\n",
    "    with out:\n",
    "        ax = draw_images(imgmod1, imgmod2, img_id1, img_id2, overlay_tag)\n",
    "        plt.show()\n",
    "    \n",
    "def on_same_button_clicked(b):\n",
    "    global img_id1, img_id2, overlay_tag\n",
    "    overlay_labels[(img_id1, img_id2, overlay_tag)] = 1\n",
    "    imgmod1, imgmod2, img_id1, img_id2, overlay_tag = get_next_img_pair()\n",
    "    redraw(imgmod1, imgmod2, img_id1, img_id2, overlay_tag)\n",
    "    \n",
    "def on_diff_button_clicked(b):\n",
    "    global img_id1, img_id2, overlay_tag\n",
    "    overlay_labels[(img_id1, img_id2, overlay_tag)] = 0\n",
    "    imgmod1, imgmod2, img_id1, img_id2, overlay_tag = get_next_img_pair()\n",
    "    redraw(imgmod1, imgmod2, img_id1, img_id2, overlay_tag)\n",
    "    \n",
    "def on_skip_button_clicked(b):\n",
    "    global img_id1, img_id2, overlay_tag\n",
    "    imgmod1, imgmod2, img_id1, img_id2, overlay_tag = get_next_img_pair()\n",
    "    redraw(imgmod1, imgmod2, img_id1, img_id2, overlay_tag)\n",
    "\n",
    "same_button.on_click(on_same_button_clicked)\n",
    "diff_button.on_click(on_diff_button_clicked)\n",
    "skip_button.on_click(on_skip_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = Output()\n",
    "buttons_3 = Box(children=[same_button, diff_button, skip_button], layout=box_layout)\n",
    "display(VBox([out, buttons_3]))\n",
    "\n",
    "imgmod1, imgmod2, img_id1, img_id2, overlay_tag = get_next_img_pair()\n",
    "with out:\n",
    "    ax = draw_images(imgmod1, imgmod2, img_id1, img_id2, overlay_tag)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdcic.tile_entropy_grids['00374ccfa.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdcic.tile_entropy_grids['218bb7055.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(overlay_labels), 100*len(overlay_labels)/len(duplicate_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in overlay_labels.items():\n",
    "    continue\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del overlay_labels[('b887a184a.jpg', 'ca57c33ce.jpg', '0010')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overlay_labels[('0ee790381.jpg', '2f6c0deaa.jpg', '1020')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_duplicate_truth(duplicate_truth_file, overlay_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we create image_duplicate_tiles.txt, lets check to see how many duplicate tiles we actually have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_duplicate_tiles = read_image_duplicate_tiles(image_duplicate_tiles_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_tiles = []\n",
    "dup_hashes = {}\n",
    "dup_files = []\n",
    "dup_counts = {}\n",
    "for img_id, img_dup9 in sdcic.image_duplicate_tiles.items():\n",
    "    img = None\n",
    "    c0 = Counter(img_dup9)\n",
    "    for i, c in c0.items():\n",
    "        if c == 1:\n",
    "            continue\n",
    "        for ii in np.where(img_dup9 == i)[0]:\n",
    "#             k, l = overlay_tag_maps['0022'][ii]\n",
    "            new_hash = sdcic.tile_md5hash_grids[img_id][ii]\n",
    "            if new_hash in dup_hashes:\n",
    "                dup_counts[new_hash] += 1\n",
    "                if img_id not in dup_hashes[new_hash]:\n",
    "                    dup_hashes[new_hash][img_id] = []\n",
    "                dup_hashes[new_hash][img_id].append(ii)\n",
    "            else:\n",
    "                dup_counts[new_hash] = 1\n",
    "                dup_hashes[new_hash] = {}\n",
    "                dup_hashes[new_hash][img_id] = []\n",
    "                dup_hashes[new_hash][img_id].append(ii)\n",
    "                dup_files.append(img_id)\n",
    "                img = sdcic.get_img(img_id)\n",
    "                new_tile = sdcic.get_tile(img, ii)\n",
    "                dup_tiles.append(new_tile)\n",
    "                print(len(dup_files)-1, new_hash, img_id, ii)\n",
    "dup_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ii, dup_tile in enumerate(dup_tiles):\n",
    "    print(ii)\n",
    "    print(dup_tile[2, 2], dup_tile[2, -2])\n",
    "    print(dup_tile[-2, 2], dup_tile[-2, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "img1 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[0])), cv2.COLOR_BGR2RGB)\n",
    "ax1.imshow(img1)\n",
    "img2 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[5])), cv2.COLOR_BGR2RGB)\n",
    "ax2.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "img1 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[1])), cv2.COLOR_BGR2RGB)\n",
    "ax1.imshow(img1)\n",
    "img2 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[2])), cv2.COLOR_BGR2RGB)\n",
    "ax2.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "img1 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[3])), cv2.COLOR_BGR2RGB)\n",
    "ax1.imshow(img1)\n",
    "img2 = cv2.cvtColor(cv2.imread(os.path.join(train_image_dir, dup_files[4])), cv2.COLOR_BGR2RGB)\n",
    "ax2.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_tile = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "white_tile = black_tile + 255\n",
    "blue_tile = np.copy(black_tile) \n",
    "blue_tile[:, :, 0] = 255\n",
    "red_tile = np.copy(black_tile) \n",
    "red_tile[:, :, 2] = 255\n",
    "color_tiles = [black_tile, white_tile, blue_tile, red_tile]\n",
    "for color_tile in color_tiles:\n",
    "    print(img_hash.blockMeanHash(color_tile, mode=0)[0])\n",
    "    print(hashlib.md5(color_tile.tobytes()).hexdigest())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Extra) Left over code to plot ship labels over images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, value in sorted(dup_dict.items(), key=lambda x: x[1][2]):\n",
    "    has_mask = []\n",
    "    if value[0]:\n",
    "        if os.path.exists(os.path.join(train_mask_dir, key[0])):\n",
    "            has_mask.append(1)\n",
    "        else:\n",
    "            has_mask.append(0)\n",
    "        if os.path.exists(os.path.join(train_mask_dir, key[1])):\n",
    "            has_mask.append(1)\n",
    "        else:\n",
    "            has_mask.append(0)\n",
    "        print(f'{key[0]}, {has_mask[0]}, {key[1]}, {has_mask[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (img_id1, img_id2), (is_dup, tiles_score, tiles_score1) in dup_dict.items():\n",
    "    if is_dup == 0:\n",
    "        continue\n",
    "    has_mask = 0\n",
    "    if os.path.exists(os.path.join(train_mask_dir, img_id1)):\n",
    "        has_mask += 1\n",
    "    if os.path.exists(os.path.join(train_mask_dir, img_id2)):\n",
    "        has_mask += 1\n",
    "    if has_mask == 0:\n",
    "        continue\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "    img1 = cv2.imread(os.path.join(train_image_dir, img_id1))\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "    ax1.imshow(img1)\n",
    "    title1 = f'({tiles_score:7.5f}) {img_id1}'\n",
    "    if os.path.exists(os.path.join(train_mask_dir, img_id1)):\n",
    "        mask1 = cv2.imread(os.path.join(train_mask_dir, img_id1))\n",
    "        mask1 = cv2.cvtColor(mask1, cv2.COLOR_BGR2RGB)\n",
    "        ax1.imshow(mask1[..., 0], alpha=0.5)\n",
    "    ax1.set_title(title1)\n",
    "    \n",
    "    img2 = cv2.imread(os.path.join(train_image_dir, img_id2))\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "    ax2.imshow(img2)\n",
    "    title2 = f'({tiles_score1:7.5f}) {img_id2}'\n",
    "    if os.path.exists(os.path.join(train_mask_dir, img_id2)):\n",
    "        mask2 = cv2.imread(os.path.join(train_mask_dir, img_id2))\n",
    "        mask2 = cv2.cvtColor(mask2, cv2.COLOR_BGR2RGB)\n",
    "        ax2.imshow(mask2[..., 0], alpha=0.5)\n",
    "    ax2.set_title(title2)\n",
    "    \n",
    "    fig.savefig(os.path.join('temp', f\"{img_id1}_{img_id2}_mask.jpg\"));\n",
    "    fig.clear();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
