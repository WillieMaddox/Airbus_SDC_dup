{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from cv2 import img_hash\n",
    "\n",
    "from sdcdup.utils import overlap_tag_pairs\n",
    "from sdcdup.utils import overlap_tag_maps\n",
    "from sdcdup.utils import generate_overlap_tag_slices\n",
    "from sdcdup.utils import generate_tag_pair_lookup\n",
    "from sdcdup.utils import get_project_root\n",
    "from sdcdup.utils import fuzzy_compare\n",
    "from sdcdup.utils import bce_loss\n",
    "from sdcdup.utils import get_hamming_distance\n",
    "from sdcdup.utils import load_duplicate_truth\n",
    "from sdcdup.utils import get_tile\n",
    "from sdcdup.utils import ImgMod\n",
    "from sdcdup.features import SDCImageContainer\n",
    "from sdcdup.visualization import get_ticks\n",
    "from sdcdup.visualization import subtract_channel_average\n",
    "from sdcdup.visualization import draw_overlap_bbox\n",
    "from sdcdup.visualization import show_image\n",
    "from sdcdup.visualization import ChannelShift\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "RED = (244, 67, 54)  #F44336\n",
    "GREEN = (76, 175, 80)  #4CAF50\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title\n",
    "\n",
    "project_root = get_project_root()\n",
    "models_dir = os.path.join(project_root, 'models')\n",
    "results_dir = os.path.join(project_root, 'notebooks', 'figures')\n",
    "train_image_dir = os.path.join(project_root, os.getenv('RAW_DATA_DIR'), 'train_768')\n",
    "tag_pair_lookup = generate_tag_pair_lookup()\n",
    "overlap_tag_slices = generate_overlap_tag_slices()\n",
    "ticks = get_ticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth = load_duplicate_truth()\n",
    "print(len(dup_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdcic = SDCImageContainer()\n",
    "sdcic.matches = list(dup_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_files = []\n",
    "# score_types = ['bmh32', 'bmh96', 'hst', 'avg', 'pix', 'dnn']\n",
    "score_types = ['dnn']\n",
    "overlap_image_maps = sdcic.load_image_overlap_properties(matches_files, score_types=score_types)\n",
    "print(len(overlap_image_maps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate all the ground truth examples on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_Stats = namedtuple('dnn_stats', ['yprob', 'ypred', 'loss'])\n",
    "\n",
    "dup_dict = {}\n",
    "for (img1_id, img2_id, img1_overlap_tag), ytrue in tqdm_notebook(dup_truth.items()):\n",
    "    yprob = np.min(overlap_image_maps[(img1_id, img2_id, img1_overlap_tag)].dnn)\n",
    "    ypred = (yprob > 0.5) * 1\n",
    "    loss = bce_loss(ytrue, yprob)\n",
    "    dup_dict[(img1_id, img2_id, img1_overlap_tag)] = DNN_Stats(yprob, ypred, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out a decision tree classifier for dup_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "X = []\n",
    "Y = []\n",
    "for key, scores in dup_dict.items():\n",
    "    L.append(key)\n",
    "    X.append([\n",
    "        scores.ypred,\n",
    "        scores.loss,\n",
    "#         min(overlap_image_maps[key].bmh32),\n",
    "#         min(overlap_image_maps[key].bmh96),\n",
    "#         max(overlap_image_maps[key].hst),\n",
    "#         max(overlap_image_maps[key].avg),\n",
    "#         max(overlap_image_maps[key].pix), \n",
    "    ])\n",
    "    Y.append(dup_truth[key])\n",
    "\n",
    "L = np.array(L)\n",
    "X = np.array(X)  # X = [[0, 0], [1, 1]]\n",
    "Y = np.array(Y)  # Y = [0, 1]\n",
    "\n",
    "print(len(X), len(Y), sum(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "dot_data = tree.export_graphviz(\n",
    "    clf, \n",
    "    feature_names=[\n",
    "        'ypred',\n",
    "        'loss',\n",
    "#         'bmh32', \n",
    "#         'bmh96', \n",
    "#         'hst', \n",
    "#         'avg', \n",
    "#         'pix', \n",
    "    ], \n",
    "    filled=True, \n",
    "    rounded=True, \n",
    "    special_characters=True, \n",
    "    leaves_parallel=True) \n",
    "\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.render(f'decision_tree_{len(X)}', directory=results_dir, cleanup=True, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree analysis (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = clf.apply(X)\n",
    "\n",
    "nodes = np.where(all_nodes == 6)\n",
    "np.argmin(X[nodes]), np.min(X[nodes]), np.argmax(X[nodes]), np.max(X[nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "print(L[nodes][idx], Y[nodes][idx], X[nodes][idx])\n",
    "print(overlap_image_maps[tuple(L[nodes][idx])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tricky_examples = [\n",
    "    ['e28669903.jpg', 'ed2998ef7.jpg', '08', 1],  # 9\n",
    "    ['66482462b.jpg', 'e2497099c.jpg', '08', 1],  # 9\n",
    "    ['73fec0637.jpg', '8b0219c19.jpg', '08', 0],  # 9\n",
    "    ['00ce2c1c0.jpg', '68ef625ba.jpg', '18', 1],  # 6\n",
    "    ['01178499a.jpg', '7a7a0034a.jpg', '05', 1],  # 6\n",
    "    ['1ebdf2f08.jpg', 'b1bfb768c.jpg', '05', 1],  # 6 [91.          0.99781223]\n",
    "    ['d4f0aaa70.jpg', 'd84d4a78a.jpg', '05', 0],  # 6 [5.95230000e+04 9.98578088e-01] \n",
    "    ['012d8cca1.jpg', 'bc45cee87.jpg', '07', 1],  # 6\n",
    "    ['2323bf875.jpg', 'b5da61fce.jpg', '07', 1],  # 6 [2.05663500e+06 9.98277186e-01]\n",
    "    ['7f2be2b0a.jpg', '84dcdc7af.jpg', '07', 0],  # 6\n",
    "    ['089858a56.jpg', '903a8b121.jpg', '38', 1],  # 6\n",
    "    ['468bf9178.jpg', '6090b3a8b.jpg', '38', 1],  # 6 [1.30900000e+03 9.97640283e-01]\n",
    "    ['d843fc5ca.jpg', 'e805070df.jpg', '38', 1],  # 6\n",
    "    ['000194a2d.jpg', '384765ab2.jpg', '38', 1],  # 6\n",
    "    ['0ef6cd331.jpg', 'e6a6f80cd.jpg', '38', 0],  # 6 [1.72270000e+04 9.98394555e-01]\n",
    "    ['0a33ce967.jpg', '3964f0cee.jpg', '04', 1],  # 4\n",
    "    ['d164aea52.jpg', 'fded6e12d.jpg', '04', 1],  # 4\n",
    "    ['c3193fb05.jpg', 'cc68e7818.jpg', '15', 0],  # 4 [2.16300000e+04 9.98311792e-01]\n",
    "    ['331987f64.jpg', '4869b48b6.jpg', '15', 0],  # 4\n",
    "    ['0318fc519.jpg', 'b7feb225a.jpg', '37', 1],  # 4\n",
    "    ['7234a3a53.jpg', 'dc6534704.jpg', '37', 1],  # 4\n",
    "    ['de6fb187d.jpg', 'ea6dc23b7.jpg', '37', 1],  # 4 [223.           0.99544613]\n",
    "    ['cd3c59923.jpg', 'efdd03319.jpg', '37', 0],  # 4 [6.70246000e+05 9.99894307e-01] \n",
    "    ['0c279107f.jpg', '3b1314d5d.jpg', '37', 0],  # 4\n",
    "    ['42f02a4a4.jpg', '7d31648ff.jpg', '48', 0],  # 4\n",
    "    ['204906e27.jpg', '892a69b4b.jpg', '02', 1],  # 3 [6.31644000e+05 9.97614902e-01]\n",
    "    ['813c8ec35.jpg', 'caa94ffc3.jpg', '06', 0],  # 3 [1.76759000e+05 9.99834742e-01]\n",
    "    ['0256ef90d.jpg', '46da51931.jpg', '06', 0],  # 3 [3.70260000e+05 9.99319673e-01]\n",
    "    ['0ee790381.jpg', 'ac87bcee5.jpg', '06', 0],  # 3\n",
    "    ['2f6c0deaa.jpg', 'e44a4f5b0.jpg', '28', 1],  # 3 [24.          0.99509307]\n",
    "    ['0ef6cd331.jpg', '813c8ec35.jpg', '28', 0],  # 3 [1.79442000e+05 9.98195859e-01]\n",
    "    ['4c56d2f00.jpg', 'dcd94e973.jpg', '68', 1],  # 3 [6.31635000e+05 9.97534103e-01]\n",
    "    ['b645cd49b.jpg', 'f2e554691.jpg', '68', 1],  # 3 [3.76847000e+05 9.96659721e-01]\n",
    "    ['b998c7415.jpg', 'd4d26f700.jpg', '68', 1],  # 3 [3.76847000e+05 9.96680501e-01]\n",
    "    ['0ef6cd331.jpg', '3a9e579aa.jpg', '68', 0],  # 3 [1.62810000e+04 9.98394555e-01]\n",
    "    ['a61b3e245.jpg', 'd84d4a78a.jpg', '68', 0],  # 3 [2.59134100e+06 9.99175738e-01]\n",
    "    ['2095da0cb.jpg', '45b1a4561.jpg', '68', 0],  # 3\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_scores(tile1, tile2):\n",
    "    score = fuzzy_compare(tile1, tile2)\n",
    "    bmh1 = img_hash.blockMeanHash(tile1)\n",
    "    bmh2 = img_hash.blockMeanHash(tile2)\n",
    "    score_hamm = get_hamming_distance(bmh1, bmh2, normalize=True, as_score=True)\n",
    "    cmh1 = img_hash.colorMomentHash(tile1)\n",
    "    cmh2 = img_hash.colorMomentHash(tile2)\n",
    "    score_norm = np.linalg.norm(cmh1 - cmh2)\n",
    "    score_expnorm = np.exp(-score_norm)\n",
    "    return score, score_hamm, score_norm, score_expnorm\n",
    "\n",
    "def plot_image_pair(img1_id, img2_id, img1_overlap_tag, is_dup, draw_boxes=True):\n",
    "    \n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "    \n",
    "    img1 = imgmod1.parent_rgb\n",
    "    img2 = imgmod2.parent_rgb\n",
    "    \n",
    "    subtract_channel_average(img1, img2, img1_overlap_tag, shift=ChannelShift('median', True))\n",
    "    img2_overlap_tag = overlap_tag_pairs[img1_overlap_tag]\n",
    "    \n",
    "    img1_overlap_map = overlap_tag_maps[img1_overlap_tag]\n",
    "    img2_overlap_map = overlap_tag_maps[img2_overlap_tag]\n",
    "    for idx1, idx2 in zip(img1_overlap_map, img2_overlap_map):\n",
    "        \n",
    "        tile1 = get_tile(imgmod1.parent_rgb, idx1)\n",
    "        tile2 = get_tile(imgmod2.parent_rgb, idx2)\n",
    "        score0, score0_hamm, score0_norm, score0_expnorm = get_tile_scores(tile1, tile2)\n",
    "        \n",
    "        tile1_drop = get_tile(img1, idx1)\n",
    "        tile2_drop = get_tile(img2, idx2)\n",
    "        score1, score1_hamm, score1_norm, score1_expnorm = get_tile_scores(tile1_drop, tile2_drop)\n",
    "        \n",
    "        m12_tile = np.median(np.vstack([tile1, tile2]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "        tile1_drop = tile1 - m12_tile\n",
    "        tile2_drop = tile2 - m12_tile        \n",
    "        score2, score2_hamm, score2_norm, score2_expnorm = get_tile_scores(tile1_drop, tile2_drop)\n",
    "        \n",
    "        print(f'tile {idx1} / tile {idx2}')        \n",
    "        print(f'{score0:10.8f}, {score0_hamm:10.8f}, {score0_norm:10.8f}, {score0_expnorm:10.8f}')\n",
    "        print(f'{score1:10.8f}, {score1_hamm:10.8f}, {score1_norm:10.8f}, {score1_expnorm:10.8f}')\n",
    "        print(f'{score2:10.8f}, {score2_hamm:10.8f}, {score2_norm:10.8f}, {score2_expnorm:10.8f}', m12_tile)\n",
    "    \n",
    "    if draw_boxes:\n",
    "        bbox_thickness = 4\n",
    "        bbox_color = GREEN if is_dup else RED\n",
    "        draw_overlap_bbox(img1, img1_overlap_tag, bbox_thickness, bbox_color)\n",
    "        draw_overlap_bbox(img2, img2_overlap_tag, bbox_thickness, bbox_color)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    show_image(ax1, img1, img1_id, ticks)\n",
    "    show_image(ax2, img2, img2_id, ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_image_pair(*tricky_examples[22], draw_boxes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_image_pair(*L[nodes][idx], Y[nodes][idx], draw_boxes=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
