{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from cv2 import img_hash\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "from sdcdup.utils import overlap_tag_pairs\n",
    "from sdcdup.utils import overlap_tag_maps\n",
    "from sdcdup.utils import generate_overlap_tag_slices\n",
    "from sdcdup.utils import generate_tag_pair_lookup\n",
    "from sdcdup.utils import get_project_root\n",
    "from sdcdup.utils import fuzzy_compare\n",
    "from sdcdup.utils import get_hamming_distance\n",
    "from sdcdup.utils import load_duplicate_truth\n",
    "from sdcdup.utils import get_tile\n",
    "from sdcdup.utils import ImgMod\n",
    "from sdcdup.features import load_image_overlap_properties\n",
    "from sdcdup.data import EvalDataset as Dataset\n",
    "from sdcdup.data import WrappedDataLoader\n",
    "from sdcdup.models import load_checkpoint\n",
    "from sdcdup.visualization import get_ticks\n",
    "from sdcdup.visualization import subtract_channel_average\n",
    "from sdcdup.visualization import draw_overlap_bbox\n",
    "from sdcdup.visualization import show_image\n",
    "from sdcdup.visualization import ChannelShift\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "RED = (244, 67, 54)  #F44336\n",
    "GREEN = (76, 175, 80)  #4CAF50\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title\n",
    "\n",
    "project_root = get_project_root()\n",
    "models_dir = os.path.join(project_root, 'models')\n",
    "train_image_dir = os.path.join(project_root, os.getenv('RAW_DATA_DIR'), 'train_768')\n",
    "\n",
    "overlap_tag_slices = generate_overlap_tag_slices()\n",
    "img_overlap_index_maps = generate_tag_pair_lookup()\n",
    "\n",
    "ticks = get_ticks()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_types = ['bmh', 'cmh', 'enp', 'pix', 'px0']\n",
    "overlap_image_maps = load_image_overlap_properties(score_types=score_types)\n",
    "print(len(overlap_image_maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth = load_duplicate_truth()\n",
    "print(len(dup_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return x.view(-1, 6, 256, 256).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate all the ground truth examples on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TilePairs = namedtuple('TilePairs', 'img1_id img2_id img1_overlap_tag overlap_idx idx1 idx2')\n",
    "\n",
    "tile_pairs = []\n",
    "for img1_id, img2_id, img1_overlap_tag in tqdm_notebook(dup_truth):\n",
    "    for overlap_idx, (idx1, idx2) in enumerate(img_overlap_index_maps[img1_overlap_tag]):\n",
    "        tile_pairs.append(TilePairs(img1_id, img2_id, img1_overlap_tag, overlap_idx, idx1, idx2))\n",
    "\n",
    "len(tile_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(tile_pairs)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=256, num_workers=18)\n",
    "test_dl = WrappedDataLoader(test_dl, preprocess)\n",
    "print('Total number of batches to evaluate: ', len(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint(os.path.join(models_dir, 'dup_model.2019_0802_2209.best.pth'))\n",
    "model.cuda()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yprobs0 = [model(xb) for xb in tqdm_notebook(test_dl)]\n",
    "    yprobs = np.vstack([l.cpu() for l in yprobs0]).reshape(-1)\n",
    "print(len(yprobs0), yprobs.shape, min(yprobs), max(yprobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_cnn_tile_scores = defaultdict(dict)\n",
    "for tp, yprob in zip(tile_pairs, yprobs):\n",
    "    \n",
    "    if tp.img1_overlap_tag not in overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)]:\n",
    "        n_overlapping_tiles = len(img_overlap_index_maps[tp.img1_overlap_tag])\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag] = np.zeros(n_overlapping_tiles)\n",
    "    \n",
    "    overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag][tp.overlap_idx] = yprob\n",
    "\n",
    "DNN_Stats = namedtuple('dnn_stats', ['yprob', 'ypred', 'ytrue', 'loss', 'yconf', 'pix'])\n",
    "\n",
    "missing_maps = 0\n",
    "missing_tags = 0\n",
    "dup_dict = {}\n",
    "for (img1_id, img2_id, img1_overlap_tag), ytrue in tqdm_notebook(dup_truth.items()):\n",
    "\n",
    "    if (img1_id, img2_id) not in overlap_image_maps:\n",
    "        missing_maps += 1\n",
    "        # TODO: explain why this conditional is here OR fix it to where it doesn't have to be.\n",
    "#         print('1', ytrue, img1_id, img2_id, img1_overlap_tag)\n",
    "        continue\n",
    "    if img1_overlap_tag not in overlap_image_maps[(img1_id, img2_id)]:\n",
    "        missing_tags += 1\n",
    "        # TODO: explain why this conditional is here OR fix it to where it doesn't have to be.\n",
    "#         print('2', ytrue, img1_id, img2_id, img1_overlap_tag)\n",
    "        continue\n",
    "    scores = overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag]\n",
    "#     if len(scores.pix) < 2:\n",
    "#         print('3')\n",
    "#         continue\n",
    "    pix = max(scores.pix)\n",
    "#     if (img1_id, img2_id) not in overlap_cnn_tile_scores:\n",
    "#         print('4')\n",
    "#         continue\n",
    "#     if img1_overlap_tag not in overlap_cnn_tile_scores[(img1_id, img2_id)]:\n",
    "#         print('5')\n",
    "#         continue\n",
    "\n",
    "    dcnn_scores_raw = overlap_cnn_tile_scores[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    dcnn_conf_raw = np.abs((dcnn_scores_raw - 0.5) * 2) # confidence? (1: very, 0: not at all)\n",
    "    yconf = np.min(dcnn_conf_raw)\n",
    "    yprob = np.min(dcnn_scores_raw)\n",
    "    ypred = (yprob > 0.5) * 1\n",
    "    assert ypred <= 1\n",
    "    \n",
    "    if ytrue:\n",
    "        bce = - ytrue * np.log(yprob)\n",
    "    else:\n",
    "        bce = - (1 - ytrue) * np.log(1 - yprob)\n",
    "    \n",
    "    dup_dict[(img1_id, img2_id, img1_overlap_tag)] = DNN_Stats(yprob, ypred, ytrue, bce, yconf, pix)\n",
    "\n",
    "print('missing maps: ', missing_maps)\n",
    "print('missing tags: ', missing_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out a decision tree classifier for dup_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_maps = 0\n",
    "missing_tags = 0\n",
    "L = []\n",
    "X = []\n",
    "Y = []\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in dup_truth.items():\n",
    "    \n",
    "    if (img1_id, img2_id) not in overlap_image_maps:\n",
    "        missing_maps += 1\n",
    "        continue\n",
    "    overlap_maps = overlap_image_maps[(img1_id, img2_id)]\n",
    "    if img1_overlap_tag not in overlap_maps:\n",
    "        missing_tags += 1\n",
    "        continue\n",
    "    scores = overlap_maps[img1_overlap_tag]\n",
    "    if len(scores.pix) < 2:\n",
    "        continue\n",
    "    \n",
    "    L.append((img1_id, img2_id, img1_overlap_tag))\n",
    "    X.append([\n",
    "        dup_dict[(img1_id, img2_id, img1_overlap_tag)].ypred,\n",
    "        dup_dict[(img1_id, img2_id, img1_overlap_tag)].loss,\n",
    "#         min(scores.bmh),\n",
    "#         min(scores.cmh),\n",
    "#         max(scores.pix), \n",
    "    ])\n",
    "    Y.append([is_dup])\n",
    "\n",
    "L = np.array(L)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "# X = [[0, 0], [1, 1]]\n",
    "# Y = [0, 1]\n",
    "\n",
    "print('missing maps: ', missing_maps)\n",
    "print('missing tags: ', missing_tags)\n",
    "print(len(X))\n",
    "print(len(Y), sum(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "dot_data = tree.export_graphviz(\n",
    "    clf, \n",
    "    out_file=None, \n",
    "    feature_names=[\n",
    "        'ypred',\n",
    "        'loss',\n",
    "#         'min(bmh)', \n",
    "#         'min(cmh)', \n",
    "#         'max(pix)', \n",
    "    ], \n",
    "    filled=True, \n",
    "    rounded=True, \n",
    "    special_characters=True, \n",
    "    leaves_parallel=True) \n",
    "\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree analysis (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = clf.apply(X)\n",
    "\n",
    "nodes = np.where(all_nodes == 3)\n",
    "np.argmin(X[nodes]), np.min(X[nodes]), np.argmax(X[nodes]), np.max(X[nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "print(L[nodes][idx], Y[nodes][idx], X[nodes][idx])\n",
    "print(overlap_image_maps[(L[nodes][idx][0], L[nodes][idx][1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tricky_examples_9 = [\n",
    "    ['e28669903.jpg', 'ed2998ef7.jpg', '08', 1],\n",
    "    ['66482462b.jpg', 'e2497099c.jpg', '08', 1],\n",
    "    ['73fec0637.jpg', '8b0219c19.jpg', '08', 0],\n",
    "]\n",
    "\n",
    "tricky_examples_6 = [\n",
    "    ['00ce2c1c0.jpg', '68ef625ba.jpg', '18', 1],\n",
    "    ['01178499a.jpg', '7a7a0034a.jpg', '05', 1],\n",
    "    ['1ebdf2f08.jpg', 'b1bfb768c.jpg', '05', 1],  # [91.          0.99781223]\n",
    "    ['d4f0aaa70.jpg', 'd84d4a78a.jpg', '05', 0],  # [5.95230000e+04 9.98578088e-01] \n",
    "    ['012d8cca1.jpg', 'bc45cee87.jpg', '07', 1],\n",
    "    ['2323bf875.jpg', 'b5da61fce.jpg', '07', 1],  # [2.05663500e+06 9.98277186e-01]\n",
    "    ['7f2be2b0a.jpg', '84dcdc7af.jpg', '07', 0],\n",
    "    ['089858a56.jpg', '903a8b121.jpg', '38', 1],\n",
    "    ['468bf9178.jpg', '6090b3a8b.jpg', '38', 1],  # [1.30900000e+03 9.97640283e-01]\n",
    "    ['d843fc5ca.jpg', 'e805070df.jpg', '38', 1],\n",
    "    ['000194a2d.jpg', '384765ab2.jpg', '38', 1],\n",
    "    ['0ef6cd331.jpg', 'e6a6f80cd.jpg', '38', 0],  # [1.72270000e+04 9.98394555e-01]\n",
    "]\n",
    "\n",
    "tricky_examples_4 = [\n",
    "    ['0a33ce967.jpg', '3964f0cee.jpg', '04', 1],\n",
    "    ['d164aea52.jpg', 'fded6e12d.jpg', '04', 1],\n",
    "    ['c3193fb05.jpg', 'cc68e7818.jpg', '15', 0],  # [2.16300000e+04 9.98311792e-01]\n",
    "    ['331987f64.jpg', '4869b48b6.jpg', '15', 0],\n",
    "    ['0318fc519.jpg', 'b7feb225a.jpg', '37', 1],\n",
    "    ['7234a3a53.jpg', 'dc6534704.jpg', '37', 1],\n",
    "    ['de6fb187d.jpg', 'ea6dc23b7.jpg', '37', 1],  # [223.           0.99544613]\n",
    "    ['cd3c59923.jpg', 'efdd03319.jpg', '37', 0],  # [6.70246000e+05 9.99894307e-01] \n",
    "    ['0c279107f.jpg', '3b1314d5d.jpg', '37', 0],\n",
    "    ['42f02a4a4.jpg', '7d31648ff.jpg', '58', 0],  # '48' ???\n",
    "]\n",
    "\n",
    "tricky_examples_3 = [\n",
    "    ['204906e27.jpg', '892a69b4b.jpg', '02', 1],  # [6.31644000e+05 9.97614902e-01]\n",
    "    ['813c8ec35.jpg', 'caa94ffc3.jpg', '06', 0],  # [1.76759000e+05 9.99834742e-01]\n",
    "    ['0256ef90d.jpg', '46da51931.jpg', '06', 0],  # [3.70260000e+05 9.99319673e-01]\n",
    "    ['0ee790381.jpg', 'ac87bcee5.jpg', '06', 0],\n",
    "    ['2f6c0deaa.jpg', 'e44a4f5b0.jpg', '28', 1],  # [24.          0.99509307]\n",
    "    ['0ef6cd331.jpg', '813c8ec35.jpg', '28', 0],  # [1.79442000e+05 9.98195859e-01]\n",
    "    ['4c56d2f00.jpg', 'dcd94e973.jpg', '68', 1],  # [6.31635000e+05 9.97534103e-01]\n",
    "    ['b645cd49b.jpg', 'f2e554691.jpg', '68', 1],  # [3.76847000e+05 9.96659721e-01]\n",
    "    ['b998c7415.jpg', 'd4d26f700.jpg', '68', 1],  # [3.76847000e+05 9.96680501e-01]\n",
    "    ['0ef6cd331.jpg', '3a9e579aa.jpg', '68', 0],  # [1.62810000e+04 9.98394555e-01]\n",
    "    ['a61b3e245.jpg', 'd84d4a78a.jpg', '68', 0],  # [2.59134100e+06 9.99175738e-01]\n",
    "    ['2095da0cb.jpg', '45b1a4561.jpg', '68', 0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_scores(tile1, tile2):\n",
    "    score = fuzzy_compare(tile1, tile2)\n",
    "    bmh1 = img_hash.blockMeanHash(tile1)\n",
    "    bmh2 = img_hash.blockMeanHash(tile2)\n",
    "    score_hamm = get_hamming_distance(bmh1, bmh2, normalize=True, as_score=True)\n",
    "    cmh1 = img_hash.colorMomentHash(tile1)\n",
    "    cmh2 = img_hash.colorMomentHash(tile2)\n",
    "#     print(cmh1.reshape((6, 7)))\n",
    "#     print(cmh2.reshape((6, 7)))\n",
    "    score_norm = np.linalg.norm(cmh1 - cmh2)\n",
    "    score_expnorm = np.exp(-score_norm)\n",
    "    return score, score_hamm, score_norm, score_expnorm\n",
    "\n",
    "def plot_image_pair(img1_id, img2_id, img1_overlap_tag, is_dup, draw_boxes=True):\n",
    "    \n",
    "#     print(is_dup, img1_overlap_tag)\n",
    "#     print(overlap_image_maps[(img1_id, img2_id)][img1_overlap_tag])\n",
    "#     print(overlap_cnn_tile_scores[(img1_id, img2_id)][img1_overlap_tag])\n",
    "    \n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "    \n",
    "    img1 = imgmod1.parent_rgb\n",
    "    img2 = imgmod2.parent_rgb\n",
    "    \n",
    "    subtract_channel_average(img1, img2, img1_overlap_tag, shift=ChannelShift('median', True))\n",
    "    \n",
    "    img1_overlap_map = overlap_tag_maps[img1_overlap_tag]\n",
    "    img2_overlap_map = overlap_tag_maps[overlap_tag_pairs[img1_overlap_tag]]\n",
    "    for idx1, idx2 in zip(img1_overlap_map, img2_overlap_map):\n",
    "        \n",
    "        tile1 = get_tile(imgmod1.parent_rgb, idx1)\n",
    "        tile2 = get_tile(imgmod2.parent_rgb, idx2)\n",
    "        score0, score0_hamm, score0_norm, score0_expnorm = get_tile_scores(tile1, tile2)\n",
    "        \n",
    "        tile1_drop = get_tile(img1, idx1)\n",
    "        tile2_drop = get_tile(img2, idx2)\n",
    "        score1, score1_hamm, score1_norm, score1_expnorm = get_tile_scores(tile1_drop, tile2_drop)\n",
    "        \n",
    "        m12_tile = np.median(np.vstack([tile1, tile2]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "        tile1_drop = tile1 - m12_tile\n",
    "        tile2_drop = tile2 - m12_tile        \n",
    "        score2, score2_hamm, score2_norm, score2_expnorm = get_tile_scores(tile1_drop, tile2_drop)\n",
    "        \n",
    "        print(f'tile {idx1} / tile {idx2}')        \n",
    "        print(f'{score0:10.8f}, {score0_hamm:10.8f}, {score0_norm:10.8f}, {score0_expnorm:10.8f}')\n",
    "        print(f'{score1:10.8f}, {score1_hamm:10.8f}, {score1_norm:10.8f}, {score1_expnorm:10.8f}')\n",
    "        print(f'{score2:10.8f}, {score2_hamm:10.8f}, {score2_norm:10.8f}, {score2_expnorm:10.8f}', m12_tile)\n",
    "    \n",
    "    if draw_boxes:\n",
    "        bbox_thickness = 4\n",
    "        bbox_color = GREEN if is_dup else RED\n",
    "        draw_overlap_bbox(img1, img1_overlap_tag, bbox_thickness, bbox_color)\n",
    "        draw_overlap_bbox(img2, overlap_tag_pairs[img1_overlap_tag], bbox_thickness, bbox_color)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    show_image(ax1, img1, img1_id, ticks)\n",
    "    show_image(ax2, img2, img2_id, ticks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_image_pair(*tricky_examples_4[6], draw_boxes=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
