{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage.util import montage\n",
    "import cv2\n",
    "from cv2 import img_hash\n",
    "\n",
    "from sdcdup.utils import get_project_root\n",
    "from sdcdup.utils import overlap_tag_maps\n",
    "from sdcdup.utils import overlap_tag_pairs\n",
    "from sdcdup.utils import generate_pair_tag_lookup\n",
    "from sdcdup.utils import get_hamming_distance\n",
    "from sdcdup.utils import get_hamming_distance_array\n",
    "from sdcdup.features import SDCImageContainer\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title\n",
    "\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "\n",
    "project_root = get_project_root()\n",
    "train_image_dir = os.path.join(project_root, os.getenv('RAW_DATA_DIR'), 'train_768')\n",
    "interim_data_dir = os.path.join(project_root, os.getenv('INTERIM_DATA_DIR'))\n",
    "pair_tag_lookup = generate_pair_tag_lookup()\n",
    "ticks = get_ticks()\n",
    "\n",
    "matches_white = {\n",
    "    'bmh32': tuple(np.ones(32, dtype='uint8') * 255),\n",
    "    'bmh96': tuple(np.ones(96, dtype='uint8') * 255)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_metric = 'bmh32'\n",
    "matches_threshold = 0.9\n",
    "\n",
    "sdcic = SDCImageContainer()\n",
    "sdcic.load_image_metrics(['md5', 'bmh32', 'bmh96'])\n",
    "img_ids = os.listdir(train_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All have the same blockMeanHash, but they each have different md5 hashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_tile = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "white_tile = black_tile + 255\n",
    "blue_tile = np.copy(black_tile)\n",
    "blue_tile[:, :, 0] = 255\n",
    "red_tile = np.copy(black_tile)\n",
    "red_tile[:, :, 2] = 255\n",
    "color_tiles = [black_tile, white_tile, blue_tile, red_tile]\n",
    "for color_tile in color_tiles:\n",
    "    print(hashlib.md5(color_tile.tobytes()).hexdigest())\n",
    "    print(img_hash.blockMeanHash(color_tile, mode=0)[0])\n",
    "    # ...for each color channel\n",
    "    hash0 = img_hash.blockMeanHash(color_tile[..., 0], mode=0)\n",
    "    hash1 = img_hash.blockMeanHash(color_tile[..., 1], mode=0)\n",
    "    hash2 = img_hash.blockMeanHash(color_tile[..., 2], mode=0)\n",
    "    print(np.hstack([hash0, hash1, hash2])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlapping images with hashlib.md5\n",
    "Update: The values between two supposedly exact 256x256 crops are not always exact (See below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md5hash_dict = defaultdict(list)\n",
    "for img_id in tqdm_notebook(img_ids):\n",
    "    for h in sdcic.img_metrics['md5'][img_id]:\n",
    "        md5hash_dict[h].append(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_counts_dict = defaultdict(int)\n",
    "for key, dups in md5hash_dict.items():\n",
    "    dup_counts_dict[len(dups)] += 1\n",
    "\n",
    "sorted_bin_sizes = sorted(dup_counts_dict.items())\n",
    "print('n images with k duplicates')\n",
    "print('(k, n)')\n",
    "sorted_bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 9\n",
    "skip = 365\n",
    "ii = 0\n",
    "jj = 0\n",
    "\n",
    "for hash_id, dups in md5hash_dict.items():\n",
    "    ii += 1\n",
    "    if len(dups) == batch_size:\n",
    "        dups0 = list(set(dups))\n",
    "        img_id = dups0[0]\n",
    "        idx = sdcic.img_metrics['md5'][img_id].tolist().index(hash_id)\n",
    "        print(hash_id, len(dups), ii)\n",
    "        if jj == min(dup_counts_dict[len(dups)], skip):\n",
    "            break\n",
    "        jj += 1\n",
    "\n",
    "batch_limit = 9\n",
    "samples_images = np.empty((batch_limit, 768, 768, 3), dtype=np.float32)\n",
    "for i, c_img_id in enumerate(dups0[:batch_limit]):\n",
    "    c_img = cv2.cvtColor(sdcic.get_img(c_img_id), cv2.COLOR_BGR2RGB)\n",
    "    samples_images[i] = c_img.astype(np.float32) / 255.0\n",
    "\n",
    "batch_rgb = montage_rgb(samples_images)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16, 16))\n",
    "ax.imshow(batch_rgb, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find overlapping images with cv2.blockMeanHash \n",
    "(Using only exact first matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use filter for all overlaps here?\n",
    "# img_ids = filter_duplicates(img_ids)\n",
    "\n",
    "bm0hash_dict = defaultdict(set)\n",
    "for img_id in tqdm_notebook(img_ids):\n",
    "    for h in sdcic.img_metrics[matches_metric][img_id]:\n",
    "        bm0hash_dict[tuple(h)].add(img_id)  # hex\n",
    "\n",
    "bm0hash_dict.pop(matches_white[matches_metric])\n",
    "\n",
    "sorted_hash_dict = {}\n",
    "for key, dups in sorted(bm0hash_dict.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "    if len(dups) > 1:\n",
    "        sorted_hash_dict[key] = sorted(dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_counts_dict = defaultdict(int)\n",
    "for key, dups in bm0hash_dict.items():\n",
    "    dup_counts_dict[len(dups)] += 1\n",
    "\n",
    "sorted_bin_sizes = sorted(dup_counts_dict.items())\n",
    "print('n images with k duplicates')\n",
    "print('(k, n)')\n",
    "sorted_bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matches(sorted_hash_dict, sdcic, matches_metric, matches_threshold):\n",
    "\n",
    "    test_matches = set()\n",
    "    for hash_id, img_list in tqdm_notebook(sorted_hash_dict.items()):\n",
    "\n",
    "        hamming_lookup = {img_id: get_hamming_distance_array(sdcic.img_metrics[matches_metric][img_id], np.asarray(hash_id)[None, :], normalize=True, as_score=True) for img_id in img_list}\n",
    "        \n",
    "        temp_matches = set()\n",
    "        for img1_id in img_list:\n",
    "            tiles1 = [idx for idx, bmhd in enumerate(hamming_lookup[img1_id]) if bmhd >= matches_threshold]\n",
    "            for img2_id in img_list:\n",
    "                if img2_id <= img1_id:\n",
    "                    continue\n",
    "                tiles2 = [idx for idx, bmhd in enumerate(hamming_lookup[img2_id]) if bmhd >= matches_threshold]\n",
    "\n",
    "                # create a set of valid overlap_tags based on matching image tiles.\n",
    "                overlap_tags = set()\n",
    "                for t1 in tiles1:\n",
    "                    for t2 in tiles2:\n",
    "                        overlap_tags.add(pair_tag_lookup.get((t1, t2)))\n",
    "\n",
    "                for img1_overlap_tag in overlap_tags:\n",
    "                    temp_matches.add((img1_id, img2_id, img1_overlap_tag))\n",
    "\n",
    "        test_matches.update(temp_matches)\n",
    "        \n",
    "    return test_matches\n",
    "\n",
    "def generate_matches2(test_matches, sdcic, matches_metric, matches_threshold):\n",
    "    new_matches = set()\n",
    "    for match in tqdm_notebook(sorted(test_matches)):\n",
    "        bmh_scores = sdcic.overlap_scores_config[matches_metric]['func'](*match)\n",
    "        if min(bmh_scores) < matches_threshold:\n",
    "            continue\n",
    "        new_matches.add(tuple(match))\n",
    "    \n",
    "    return new_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches = generate_matches(sorted_hash_dict, sdcic, matches_metric, matches_threshold)\n",
    "print(len(test_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = generate_matches2(test_matches, sdcic, matches_metric, matches_threshold)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_file = f'matches_{matches_metric}_{matches_threshold}.csv'\n",
    "full_matches_file = os.path.join(interim_data_dir, matches_file)\n",
    "df = pd.DataFrame(sorted(matches))\n",
    "df.to_csv(full_matches_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 18\n",
    "skip = 5\n",
    "ii = 0\n",
    "jj = 0\n",
    "\n",
    "for hash_id, dups in bm0hash_dict.items():\n",
    "    ii += 1\n",
    "    if len(dups) == batch_size:\n",
    "        dups0 = list(set(dups))\n",
    "        img_id = dups0[0]\n",
    "        idx = np.where(np.all(sdcic.img_metrics[matches_metric][img_id] == np.asarray(hash_id), axis=1))[0]\n",
    "        print(hash_id, len(dups), ii)\n",
    "        if jj == min(dup_counts_dict[len(dups)], skip):\n",
    "            break\n",
    "        jj += 1\n",
    "\n",
    "batch_limit = 9\n",
    "samples_images = np.empty((batch_limit, 768, 768, 3), dtype=np.float32)\n",
    "for i, c_img_id in enumerate(dups0[:batch_limit]):\n",
    "    c_img = cv2.cvtColor(sdcic.get_img(c_img_id), cv2.COLOR_BGR2RGB)\n",
    "    samples_images[i] = c_img.astype(np.float32) / 255.0\n",
    "\n",
    "batch_rgb = montage_rgb(samples_images)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16, 16))\n",
    "ax.imshow(batch_rgb, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
