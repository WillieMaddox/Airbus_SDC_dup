{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "from collections import Counter\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "from sdcdup.utils import overlap_tag_pairs\n",
    "from sdcdup.utils import generate_overlap_tag_slices\n",
    "from sdcdup.utils import generate_tag_pair_lookup\n",
    "from sdcdup.utils import channel_shift\n",
    "from sdcdup.utils import load_duplicate_truth\n",
    "from sdcdup.utils import ImgMod\n",
    "from sdcdup.utils import WrappedDataLoader\n",
    "from sdcdup.utils import EvalDataset as Dataset\n",
    "\n",
    "from sdcdup.models.dupnet import load_checkpoint\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "RED = (244, 67, 54)  #F44336 \n",
    "GREEN = (76, 175, 80)  #4CAF50 \n",
    "LIGHT_BLUE = (3, 169, 244)  #03A9F4\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# SENDTOENV\n",
    "train_image_dir = 'data/raw/train_768/'\n",
    "\n",
    "overlap_tag_slices = generate_overlap_tag_slices()\n",
    "img_overlap_index_maps = generate_tag_pair_lookup()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_truth = load_duplicate_truth()\n",
    "print(len(dup_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return x.view(-1, 6, 256, 256).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TilePairs = namedtuple('TilePairs', 'img1_id img2_id img1_overlap_tag overlap_idx idx1 idx2')\n",
    "\n",
    "ytrue = []\n",
    "tile_pairs = []\n",
    "for (img1_id, img2_id, img1_overlap_tag), is_dup in tqdm_notebook(dup_truth.items()):\n",
    "    for overlap_idx, (idx1, idx2) in enumerate(img_overlap_index_maps[img1_overlap_tag]):\n",
    "        tile_pairs.append(TilePairs(img1_id, img2_id, img1_overlap_tag, overlap_idx, idx1, idx2))\n",
    "        ytrue.append(is_dup)\n",
    "print(len(tile_pairs), sum(ytrue), len(ytrue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(tile_pairs)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=256, num_workers=18)\n",
    "test_dl = WrappedDataLoader(test_dl, preprocess)\n",
    "print(len(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint('models/dup_model.2019_0802_2209.best.pth')\n",
    "model.cuda()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yprobs0 = [model(xb) for xb in tqdm_notebook(test_dl)]\n",
    "    yprobs = np.vstack([l.cpu() for l in yprobs0]).reshape(-1)\n",
    "    print(len(yprobs0), yprobs.shape, min(yprobs), max(yprobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_cnn_tile_scores = {}\n",
    "for tp, yprob in zip(tile_pairs, yprobs):\n",
    "    \n",
    "    if (tp.img1_id, tp.img2_id) not in overlap_cnn_tile_scores:\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)] = {}\n",
    "    \n",
    "    if tp.img1_overlap_tag not in overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)]:\n",
    "        n_overlapping_tiles = len(img_overlap_index_maps[tp.img1_overlap_tag])\n",
    "        cnn_scores = np.zeros(n_overlapping_tiles)\n",
    "        overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag] = cnn_scores\n",
    "    \n",
    "    overlap_cnn_tile_scores[(tp.img1_id, tp.img2_id)][tp.img1_overlap_tag][tp.overlap_idx] = yprob\n",
    "\n",
    "DNN_Stats = namedtuple('dnn_stats', ['yprob', 'ypred', 'ytrue', 'loss', 'yconf'])\n",
    "\n",
    "dup_dict = {}\n",
    "for (img1_id, img2_id, img1_overlap_tag), ytrue in tqdm_notebook(dup_truth.items()):\n",
    "    assert img1_id < img2_id\n",
    "\n",
    "    dcnn_scores_raw = overlap_cnn_tile_scores[(img1_id, img2_id)][img1_overlap_tag]\n",
    "    dcnn_conf_raw = np.abs((dcnn_scores_raw - 0.5) * 2) # confidence? (1: very, 0: not at all)\n",
    "    yconf = np.min(dcnn_conf_raw)\n",
    "    yprob = np.min(dcnn_scores_raw)\n",
    "    ypred = (yprob > 0.5) * 1\n",
    "    assert ypred <= 1\n",
    "    \n",
    "    if ytrue:\n",
    "        bce = - ytrue * np.log(yprob)\n",
    "    else:\n",
    "        bce = - (1 - ytrue) * np.log(1 - yprob)\n",
    "    \n",
    "    dup_dict[(img1_id, img2_id, img1_overlap_tag)] = DNN_Stats(yprob, ypred, ytrue, bce, yconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_Stats2 = namedtuple('dnn_stats', ['key', 'yprob', 'ypred', 'ytrue', 'loss', 'yconf'])\n",
    "dup_dict_flat = []\n",
    "for keys, dnns in tqdm_notebook(dup_dict.items()):\n",
    "    dup_dict_flat.append(DNN_Stats2(keys, dnns.yprob, dnns.ypred, dnns.ytrue, dnns.loss, dnns.yconf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_confident = 0\n",
    "n_correct = 0\n",
    "id_tags = []\n",
    "for dnns in tqdm_notebook(sorted(dup_dict_flat, key=operator.attrgetter('yconf'), reverse=False)):\n",
    "\n",
    "    # Skip invalids, but print them out so we know which ones are.\n",
    "    if dnns.loss == np.nan:\n",
    "        print('nan ', dnns)\n",
    "        continue\n",
    "    if dnns.loss == np.inf:\n",
    "        print('+inf', dnns)\n",
    "        continue\n",
    "    if dnns.loss == -np.inf:\n",
    "        print('-inf', dnns)\n",
    "        continue\n",
    "        \n",
    "#     Skip the ones the dnn was certain about.\n",
    "#     if dnns.yconf > 0.02:\n",
    "#         n_confident += 1\n",
    "#         continue\n",
    "\n",
    "    # Skip the ones the dnn got correct.\n",
    "    if dnns.ypred == dnns.ytrue:\n",
    "        n_correct += 1\n",
    "        continue\n",
    "        \n",
    "    id_tags.append(dnns.key)\n",
    "len(id_tags), n_confident, n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_counter = Counter()\n",
    "for img1_id, img2_id, img1_overlap_tag in id_tags:\n",
    "    for overlap_idx, (idx1, idx2) in enumerate(img_overlap_index_maps[img1_overlap_tag]):\n",
    "        tags_counter[(img1_id, idx1)] += 1\n",
    "        tags_counter[(img2_id, idx2)] += 1\n",
    "print(len(tags_counter))\n",
    "\n",
    "for k, v in sorted(tags_counter.items(), key=operator.itemgetter(1), reverse=True):\n",
    "    if v > 3:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aa = 0\n",
    "n_samples = 10\n",
    "use_median_shift = True\n",
    "shift_brightness = False\n",
    "\n",
    "test_files = id_tags[aa * n_samples: (aa + 1) * n_samples]#[::-1]\n",
    "for f in test_files:\n",
    "    print(f, '{:10.5} {} {} {:10.5} {:.5} {}'.format(*dup_dict[f]))\n",
    "\n",
    "dtick = 256\n",
    "n_ticks = 768 // dtick + 1\n",
    "ticks = [i * dtick for i in range(n_ticks)]\n",
    "\n",
    "fig, m_axs = plt.subplots(n_samples, 2, figsize = (16, 8 * n_samples))\n",
    "for ii, (img1_id, img2_id, img1_overlap_tag) in enumerate(test_files):\n",
    "    \n",
    "    (ax1, ax2) = m_axs[ii]\n",
    "    yprob, ypred, is_dup, loss, yconf = dup_dict[(img1_id, img2_id, img1_overlap_tag)]\n",
    "    \n",
    "    imgmod1 = ImgMod(os.path.join(train_image_dir, img1_id))\n",
    "    imgmod2 = ImgMod(os.path.join(train_image_dir, img2_id))\n",
    "\n",
    "    slice1 = overlap_tag_slices[img1_overlap_tag]\n",
    "    slice2 = overlap_tag_slices[overlap_tag_pairs[img1_overlap_tag]]\n",
    "\n",
    "    m12 = np.median(np.vstack([imgmod1.parent_rgb[slice1], imgmod2.parent_rgb[slice2]]), axis=(0, 1), keepdims=True).astype(np.uint8)\n",
    "    \n",
    "    if shift_brightness:\n",
    "        brightness_level = -100 if np.sum(m12) >= 384 else 100\n",
    "        img1 = imgmod1.brightness_shift('L', brightness_level)\n",
    "        img2 = imgmod2.brightness_shift('L', brightness_level)\n",
    "    else:\n",
    "        img1 = imgmod1.parent_rgb\n",
    "        img2 = imgmod2.parent_rgb\n",
    "\n",
    "    if use_median_shift:\n",
    "        img1_drop = imgmod1.parent_rgb - m12\n",
    "        img2_drop = imgmod2.parent_rgb - m12\n",
    "    else:        \n",
    "        img1_drop = imgmod1.parent_rgb\n",
    "        img2_drop = imgmod2.parent_rgb\n",
    "    \n",
    "    img1[slice1] = img1_drop[slice1]\n",
    "    img2[slice2] = img2_drop[slice2]\n",
    "\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(f'{img1_id}')\n",
    "    ax1.set_xticks(ticks)\n",
    "    ax1.set_yticks(ticks)\n",
    "\n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title(f'{img2_id}')\n",
    "    ax2.set_xticks(ticks)\n",
    "    ax2.set_yticks(ticks)\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(os.path.join('temp', BASE_MODEL, f\"{train_meta_filebase}_{score_str}_batch_{BATCH_NUM}_row_{aa+1}.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
