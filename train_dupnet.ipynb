{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "from tqdm import tnrange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from parse import parse\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "\n",
    "from sdcdup.utils import get_datetime_now\n",
    "from sdcdup.utils import channel_shift\n",
    "from sdcdup.utils import to_hls\n",
    "from sdcdup.utils import to_bgr\n",
    "from sdcdup.utils import create_dataset_from_tiles\n",
    "from sdcdup.utils import create_dataset_from_tiles_and_truth\n",
    "from sdcdup.utils import even_split\n",
    "from sdcdup.utils import CSVLogger\n",
    "\n",
    "sdcdup.features.image_features import SDCImageContainer\n",
    "# from datasets import create_dataset_from_truth\n",
    "from sdcdup.models.dupnet import save_checkpoint\n",
    "from sdcdup.models.dupnet import DupCNN\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# SENDTOENV\n",
    "train_768_dir = 'data/raw/train_768/'\n",
    "train_256_dir = 'data/processed/train_256/'\n",
    "image_md5hash_grids_file = 'data/interim/image_md5hash_grids.pkl'\n",
    "image_bm0hash_grids_file = 'data/interim/image_bm0hash_grids.pkl'\n",
    "image_cm0hash_grids_file = 'data/interim/image_cm0hash_grids.pkl'\n",
    "image_greycop_grids_file = 'data/interim/image_greycop_grids.pkl'\n",
    "image_entropy_grids_file = 'data/interim/image_entropy_grids.pkl'\n",
    "image_issolid_grids_file = 'data/interim/image_issolid_grids.pkl'\n",
    "duplicate_truth_file = os.path.join('data/processed/duplicate_truth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENDTOMODULE\n",
    "class RandomHorizontalFlip:\n",
    "    \"\"\"Horizontally flip the given numpy array randomly with a given probability.\n",
    "\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Image): Image to be flipped.\n",
    "\n",
    "        Returns:\n",
    "            Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if np.random.random() < self.p:\n",
    "            return cv2.flip(img, 1)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "\n",
    "\n",
    "class RandomTransformC4:\n",
    "    \"\"\"Rotate a n-D tensor by 90 degrees in the H x W plane.\n",
    "\n",
    "    Args:\n",
    "        with_identity (bool): whether or not to include 0 degrees as a probable rotation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, with_identity=True):\n",
    "        self.with_identity = with_identity\n",
    "        self.n90s = (0, 1, 2, 3) if self.with_identity else (1, 2, 3)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Image): Image to be rotated.\n",
    "\n",
    "        Returns:\n",
    "            Image: Randomly rotated image but in 90 degree increments.\n",
    "        \"\"\"\n",
    "        k = random.choice(self.n90s)\n",
    "        return torch.rot90(img, k, (1, 2))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(with_identity={})'.format(self.with_identity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "idx_chan_map = {0: 'H', 1: 'L', 2: 'S'}\n",
    "\n",
    "# SENDTOMODULE\n",
    "# ImgAugs = namedtuple('ImgAugs', 'idx3 chan gain')\n",
    "ImgAugs = namedtuple('ImgAugs', 'flip_img_order first_from_large second_from_large second_augment_hls hls_chan hls_gain flip_stacking_order')\n",
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, img_overlaps, train_or_valid, image_transform,\n",
    "                 in_shape=(6, 256, 256), \n",
    "                 out_shape=(1,)):\n",
    "        \n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.img_overlaps = img_overlaps\n",
    "        # TODO: handle case if train_or_valid == 'test'\n",
    "        self.valid = train_or_valid == 'valid'\n",
    "        self.image_transform = image_transform\n",
    "        self.ij = ((0, 0), (0, 1), (0, 2),\n",
    "                   (1, 0), (1, 1), (1, 2),\n",
    "                   (2, 0), (2, 1), (2, 2))\n",
    "        \n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        self.hls_limits = {'H': 10, 'L': 20, 'S': 20}\n",
    "        if self.valid:\n",
    "            self.img_augs = [self.get_random_augmentation() for _ in self.img_overlaps]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return len(self.img_overlaps)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one sample of data\"\"\"\n",
    "        if self.valid:\n",
    "            img_aug = self.img_augs[index]\n",
    "        else:\n",
    "            img_aug = self.get_random_augmentation()\n",
    "        return self.get_data_pair(self.img_overlaps[index], img_aug)  # X, y\n",
    "    \n",
    "    def get_random_augmentation(self):\n",
    "\n",
    "        # So, we aren't always biasing the second image with hls shifting...\n",
    "        flip_img_order = np.random.random() > 0.5\n",
    "        # The first tile will always come from either a slice of the image or from the saved slice.\n",
    "        first_from_large = np.random.random() > 0.5\n",
    "        second_from_large = np.random.random() > 0.5\n",
    "        second_augment_hls = np.random.random() > 0.25\n",
    "        flip_stacking_order = np.random.random() > 0.5\n",
    "        \n",
    "        hls_idx = np.random.choice(3)\n",
    "        hls_chan = idx_chan_map[hls_idx]\n",
    "        hls_gain = np.random.choice(self.hls_limits[hls_chan]) + 1\n",
    "        hls_gain = hls_gain if np.random.random() > 0.5 else -1 * hls_gain\n",
    "        \n",
    "        return ImgAugs(flip_img_order, first_from_large, second_from_large, second_augment_hls, hls_chan, hls_gain, flip_stacking_order)\n",
    "    \n",
    "    def color_shift(self, img, chan, gain):\n",
    "        hls = to_hls(img)\n",
    "        hls_shifted = channel_shift(hls, chan, gain)\n",
    "        return to_bgr(hls_shifted)\n",
    "    \n",
    "    def get_tile(self, img, idx, sz=256):\n",
    "        i, j = self.ij[idx]\n",
    "        return img[i * sz:(i + 1) * sz, j * sz:(j + 1) * sz, :]\n",
    "    \n",
    "    def read_from_large(self, img_id, idx):\n",
    "        img = cv2.imread(os.path.join(train_768_dir, img_id))\n",
    "        return self.get_tile(img, idx)\n",
    "    \n",
    "    def read_from_small(self, img_id, idx):\n",
    "        filebase, fileext = img_id.split('.')\n",
    "        tile_id = f'{filebase}_{idx}.{fileext}'\n",
    "        return cv2.imread(os.path.join(train_256_dir, tile_id))\n",
    "    \n",
    "    def get_data_pair(self, img_overlap, img_aug):\n",
    "\n",
    "        # diff img_id (img1_id != img2_id), random tile from overlap, where is_dup == 1 (from duplicate_truth.txt)\n",
    "            # img1_[i,j], img2_[k,l], 1, exact or fuzzy\n",
    "            # img1_[i,j], tile2_kl, 1, exact or fuzzy\n",
    "            # tile1_ij, img2_[k,l], 1, exact or fuzzy\n",
    "            # tile1_ij, tile2_kl, 1, exact or fuzzy\n",
    "        \n",
    "        # same img_id (img1_id == img2_id), same tile (ij == kl)\n",
    "            # img1_[i,j], img1_[i,j], 1, exact\n",
    "            # img1_[i,j], tile1_ij, 1, fuzzy\n",
    "            # tile1_ij, img1_[i,j], 1, fuzzy\n",
    "            # tile1_ij, tile1_ij, 1, exact\n",
    "            \n",
    "        # same img_id (img1_id == img2_id), diff tile (ij != kl)\n",
    "            # img1_[i,j], img1_[k,l], 0, similar but different\n",
    "            # img1_[i,j], tile1_kl, 0, similar but different\n",
    "            # tile1_ij, img1_[k,l], 0, similar but different\n",
    "            # tile1_ij, tile1_kl, 0, similar but different\n",
    "            \n",
    "        # diff img_id (img1_id != img2_id), same tile (ij == kl)\n",
    "            # img1_[i,j], img2_[i,j], 0, very different\n",
    "            # img1_[i,j], tile2_ij, 0, very different\n",
    "            # tile1_ij, img2_[i,j], 0, very different\n",
    "            # tile1_ij, tile2_ij, 0, very different\n",
    "            \n",
    "        # diff img_id (img1_id != img2_id), diff tile (ij != kl)\n",
    "            # img1_[i,j], img2_[k,l], 0, very different\n",
    "            # img1_[i,j], tile2_kl, 0, very different\n",
    "            # tile1_ij, img2_[k,l], 0, very different\n",
    "            # tile1_ij, tile2_kl, 0, very different\n",
    "        \n",
    "        # use image_md5hash_grids.pkl for equal image id pairs (img1_id == img2_id)\n",
    "        #--------------------------------------------------------------------\n",
    "        # ij == kl? | tile1? | tile2? | shift? | is_dup?\n",
    "        #--------------------------------------------------------------------\n",
    "        #   yes     |  768   |  768   |   yes  |    yes agro color shift \n",
    "        #   yes     |  768   |  768   |    no  |    yes\n",
    "        #   yes     |  768   |  256   |    no  |    yes \n",
    "        #   yes     |  256   |  768   |    no  |    yes \n",
    "        #   yes     |  256   |  256   |   yes  |    yes agro color shift \n",
    "        #   yes     |  256   |  256   |    no  |    yes \n",
    "        #    no     |  768   |  768   |   yes  |     no \n",
    "        #    no     |  768   |  768   |    no  |     no \n",
    "        #    no     |  256   |  256   |   yes  |     no \n",
    "        #    no     |  256   |  256   |    no  |     no \n",
    "        \n",
    "        # use duplicate_truth.txt for unequal image id pairs (img1_id != img2_id)\n",
    "        # NOTE: Be sure to use the overlap_map when comparing ij and kl\n",
    "        #--------------------------------------------------------------------\n",
    "        # ij == kl? | tile1? | tile2? | shift? | is_dup?\n",
    "        #--------------------------------------------------------------------\n",
    "        #   yes     |  768   |  768   |   yes  |    yes small color shift \n",
    "        #   yes     |  768   |  768   |    no  |    yes\n",
    "        #   yes     |  768   |  256   |    no  |    yes\n",
    "        #   yes     |  256   |  768   |    no  |    yes\n",
    "        #   yes     |  256   |  256   |   yes  |    yes\n",
    "        #   yes     |  256   |  256   |    no  |    yes\n",
    "        #    no     |  768   |  768   |   yes  |     no\n",
    "        #    no     |  768   |  768   |    no  |     no\n",
    "        #    no     |  256   |  256   |   yes  |     no \n",
    "        #    no     |  256   |  256   |    no  |     no\n",
    "\n",
    "        flip_img_order, first_from_large, second_from_large, aug_hls, chan, gain, flip_stacking_order = img_aug\n",
    "        if flip_img_order:\n",
    "            img2_id, img1_id, idx2, idx1, is_dup = img_overlap\n",
    "        else:\n",
    "            img1_id, img2_id, idx1, idx2, is_dup = img_overlap\n",
    "        \n",
    "        read1 = self.read_from_large if first_from_large else self.read_from_small\n",
    "        read2 = self.read_from_large if second_from_large else self.read_from_small\n",
    "        same_image = img1_id == img2_id\n",
    "        \n",
    "        if same_image:  # img1_id == img2_id\n",
    "            if is_dup:  # idx1 == idx2\n",
    "                tile1 = read1(img1_id, idx1)\n",
    "                if aug_hls:\n",
    "                    tile2 = self.color_shift(tile1, chan, gain)\n",
    "                else:\n",
    "                    tile2 = read2(img2_id, idx2)\n",
    "            else:  # idx1 != idx2\n",
    "                if first_from_large and second_from_large:\n",
    "                    img = cv2.imread(os.path.join(train_768_dir, img1_id))\n",
    "                    tile1 = self.get_tile(img, idx1)\n",
    "                    tile2 = self.get_tile(img, idx2)\n",
    "                else:\n",
    "                    tile1 = read1(img1_id, idx1)\n",
    "                    tile2 = read2(img2_id, idx2)\n",
    "        else: # img1_id != img2_id\n",
    "            tile1 = read1(img1_id, idx1)\n",
    "            tile2 = read2(img2_id, idx2)\n",
    "\n",
    "#         if is_dup == 0 and sdcic.tile_md5hash_grids[img1_id][idx1] == sdcic.tile_md5hash_grids[img2_id][idx2]:\n",
    "#             i, j = self.ij[idx1]\n",
    "#             k, l = self.ij[idx2]\n",
    "#             print(f'algo={idx3}; {img1_id} {idx1} -> ({i},{j}); {img2_id}, {idx2} -> ({k},{l}); correcting... {is_dup} -> 1')\n",
    "#             is_dup = 1\n",
    "            \n",
    "        tile1 = cv2.cvtColor(tile1, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        tile2 = cv2.cvtColor(tile2, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        \n",
    "        X = np.dstack([tile2, tile1]) if flip_stacking_order else np.dstack([tile1, tile2])        \n",
    "        X = self.image_transform(X)\n",
    "        y = np.array([is_dup], dtype=np.float32)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_chan_map = {0: 'H', 1: 'L', 2: 'S'}\n",
    "\n",
    "# SENDTOMODULE\n",
    "ImgAugs = namedtuple('ImgAugs', 'idx3 chan gain')\n",
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, img_overlaps, train_or_valid, image_transform,\n",
    "                 in_shape=(6, 256, 256), \n",
    "                 out_shape=(1,)):\n",
    "        \n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.img_overlaps = img_overlaps\n",
    "        # TODO: handle case if train_or_valid == 'test'\n",
    "        self.valid = train_or_valid == 'valid'\n",
    "        self.image_transform = image_transform\n",
    "        self.ij = ((0, 0), (0, 1), (0, 2),\n",
    "                   (1, 0), (1, 1), (1, 2),\n",
    "                   (2, 0), (2, 1), (2, 2))\n",
    "        \n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        self.hls_limits = {'H': 5, 'L': 10, 'S': 10}\n",
    "        if self.valid:\n",
    "            self.img_augs = [self.get_random_augmentation() for _ in self.img_overlaps]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return len(self.img_overlaps)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one sample of data\"\"\"\n",
    "        if self.valid:\n",
    "            img_aug = self.img_augs[index]\n",
    "        else:\n",
    "            img_aug = self.get_random_augmentation()\n",
    "        X, y = self.get_data_pair(self.img_overlaps[index], img_aug)\n",
    "        return X, y\n",
    "    \n",
    "    def get_random_augmentation(self):\n",
    "\n",
    "        p = [0.3, 0.2, 0.2, 0.3]\n",
    "        idx3 = np.random.choice(4, p=p)\n",
    "        \n",
    "        hls_idx = np.random.choice(3)\n",
    "        hls_chan = idx_chan_map[hls_idx]\n",
    "        hls_gain = np.random.choice(self.hls_limits[hls_chan]) + 1\n",
    "        hls_gain = hls_gain if np.random.random() > 0.5 else -1 * hls_gain\n",
    "        \n",
    "        return ImgAugs(idx3, hls_chan, hls_gain)\n",
    "    \n",
    "    def color_shift(self, img, chan, gain):\n",
    "        hls = to_hls(img)\n",
    "        hls_shifted = channel_shift(hls, chan, gain)\n",
    "        return to_bgr(hls_shifted)\n",
    "    \n",
    "    def get_tile(self, img, idx, sz=256):\n",
    "        i, j = self.ij[idx]\n",
    "        return img[i * sz:(i + 1) * sz, j * sz:(j + 1) * sz, :]\n",
    "    \n",
    "    def read_from_large(self, img_id, idx):\n",
    "        img = cv2.imread(img_id)\n",
    "        return self.get_tile(img, idx)\n",
    "    \n",
    "    def read_from_small(self, img_id, idx):\n",
    "        dup_truth_path, img_filename = img_id.rsplit('/images_768/')\n",
    "        row, col = parse('r{:3d}_c{:3d}.jpg', img_filename)\n",
    "        i, j = self.ij[idx]\n",
    "        tile_id = os.path.join(dup_truth_path, 'images_256', f'r{row + i:03d}_c{col + j:03d}.jpg')\n",
    "        return cv2.imread(tile_id)\n",
    "    \n",
    "    def get_data_pair(self, img_overlap, img_aug):\n",
    "\n",
    "        img1_id, img2_id, idx1, idx2, is_dup = img_overlap\n",
    "        idx3, chan, gain = img_aug\n",
    "        same_image = img1_id == img2_id\n",
    "        \n",
    "        if same_image:  # img1_id == img2_id\n",
    "            if is_dup:  # idx1 == idx2\n",
    "                if idx3 == 0:\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.color_shift(tile1, chan, gain)\n",
    "                elif idx3 == 1:\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                elif idx3 == 2:\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_large(img2_id, idx2)\n",
    "                elif idx3 == 3:\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.color_shift(tile1, chan, gain)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            else:  # idx1 != idx2\n",
    "                # idx3 = 3\n",
    "                if idx3 == 0: # fast\n",
    "                    img = cv2.imread(img1_id)\n",
    "                    tile1 = self.get_tile(img, idx1)\n",
    "                    tile2 = self.get_tile(img, idx2)\n",
    "                elif idx3 == 1: # slowest\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                elif idx3 == 2: # slowest\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_large(img2_id, idx2)\n",
    "                elif idx3 == 3: # fastest\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "        else:  # img1_id != img2_id\n",
    "            if is_dup:\n",
    "                if idx3 == 0: # slowest\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.read_from_large(img2_id, idx2)\n",
    "                elif idx3 == 1: # slow\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                elif idx3 == 2: # slow\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_large(img2_id, idx2)\n",
    "                elif idx3 == 3: # fast\n",
    "                    # These end up being the same tile.\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.color_shift(tile1, chan, gain)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            else:\n",
    "                if idx3 == 0: # slowest\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.read_from_large(img2_id, idx2)\n",
    "                elif idx3 == 1: # slow\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                elif idx3 == 2: # slow\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_large(img2_id, idx2)\n",
    "                elif idx3 == 3: # fast\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "\n",
    "#         i, j = self.ij[idx1]\n",
    "#         k, l = self.ij[idx2]\n",
    "#         print(f'same_image, is_dup, idx3: {same_image*1}, {is_dup}, {idx3}\\n{img1_id} {idx1} -> ({i},{j})\\n{img2_id} {idx2} -> ({k},{l})\\n')\n",
    "        tile1 = cv2.cvtColor(tile1, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        tile2 = cv2.cvtColor(tile2, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        \n",
    "        X = np.dstack([tile1, tile2]) if np.random.random() < 0.5 else np.dstack([tile2, tile1])\n",
    "        X = self.image_transform(X)\n",
    "        y = np.array([is_dup], dtype=np.float32)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdcic = SDCImageContainer()\n",
    "sdcic.preprocess_image_properties(\n",
    "    image_md5hash_grids_file,\n",
    "    image_bm0hash_grids_file,\n",
    "    image_cm0hash_grids_file,\n",
    "    image_greycop_grids_file,\n",
    "    image_entropy_grids_file,\n",
    "    image_issolid_grids_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "# full_dataset = create_dataset_from_tiles_and_truth(sdcic)\n",
    "full_dataset = create_dataset_from_tiles(sdcic)\n",
    "# full_dataset = create_dataset_from_truth()\n",
    "print(len(full_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame().append(full_dataset)\n",
    "df.to_csv('data/processed/full_SDC_dataset_from_tiles.csv', index=False)\n",
    "print(len(full_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/full_SDC_dataset_from_tiles.csv')\n",
    "full_dataset = list(zip(*[df[c].values.tolist() for c in df]))\n",
    "print(len(full_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch._six import int_classes as _int_classes\n",
    "\n",
    "# SENDTOMODULE\n",
    "class SubsetSampler(data.Sampler):\n",
    "    r\"\"\"Samples elements sequentially, always in the same order.\n",
    "\n",
    "    Arguments:\n",
    "        indices (sequence): a sequence of indices\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "\n",
    "class ImportanceSampler(data.Sampler):\n",
    "    r\"\"\"Samples elements from [0,..,len(weights)-1] with given probabilities (weights).\n",
    "\n",
    "    Arguments:\n",
    "        num_records (int): Total number of samples in the dataset.\n",
    "        num_samples (int): Number of samples to draw from the dataset.\n",
    "        batch_size (int): Size of mini-batch.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_records, num_samples, batch_size):\n",
    "        \n",
    "        if not isinstance(num_records, _int_classes) or isinstance(num_records, bool) or num_records <= 0:\n",
    "            raise ValueError('num_records should be a positive integeral value, but got num_records={}'.format(num_records))\n",
    "        if not isinstance(num_samples, _int_classes) or isinstance(num_samples, bool) or num_samples <= 0:\n",
    "            raise ValueError('num_samples should be a positive integeral value, but got num_samples={}'.format(num_samples))\n",
    "        if not isinstance(batch_size, _int_classes) or isinstance(batch_size, bool) or batch_size <= 0:\n",
    "            raise ValueError('batch_size should be a positive integeral value, but got batch_size={}'.format(batch_size))\n",
    "        if num_records < num_samples < batch_size:\n",
    "            raise ValueError('num_samples must be less than num_records and greater than batch_size')\n",
    "        if num_samples % batch_size != 0:\n",
    "            raise ValueError(f'batch_size ({batch_size}) must divide num_samples ({num_samples}) evenly.')\n",
    "            \n",
    "        self.num_steps = 0\n",
    "        self.num_epochs = 0\n",
    "        self.num_records = num_records\n",
    "        self.num_samples = num_samples\n",
    "        self.num_batches = num_samples // batch_size\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = True\n",
    "        \n",
    "        self.ages = np.zeros(num_records, dtype=int)\n",
    "        self.visits = np.zeros(num_records, dtype=int)\n",
    "#         self.losses = np.zeros(num_records) - np.log(0.5)  # dup or non-dup\n",
    "        self.losses = np.ones(num_records)\n",
    "        \n",
    "        self.epoch_losses = np.ones(num_samples) * -1.0\n",
    "        self._epoch_ages = None\n",
    "        \n",
    "        self.indices = np.random.choice(self.num_records, self.num_samples, replace=False)\n",
    "        self.sampler = SubsetSampler(self.indices)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        for idx in self.sampler:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.sampler) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    @property\n",
    "    def epoch_ages(self):\n",
    "        if self._epoch_ages is None:\n",
    "            # plus 1 since we're always lagging behind by 1 gradient step.\n",
    "            x = np.arange(self.num_batches)[::-1] + 1\n",
    "            self._epoch_ages = np.repeat(x, self.batch_size)\n",
    "            assert len(self._epoch_ages) == self.num_samples\n",
    "        return self._epoch_ages\n",
    "    \n",
    "    def update(self, batch_losses):\n",
    "        idx = self.num_steps * self.batch_size\n",
    "        self.epoch_losses[idx:idx + self.batch_size] = batch_losses[:, 0]\n",
    "        self.num_steps += 1\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Use losses, visits and ages to update weights for samples\"\"\"\n",
    "        \n",
    "        assert np.min(self.epoch_losses) >= 0, np.min(self.epoch_losses)\n",
    "        # age all records by the number of batches seen this epoch.\n",
    "        self.ages += self.num_batches\n",
    "        # only update the sampled records since their ages got reset.\n",
    "        self.ages[self.indices] = self.epoch_ages\n",
    "        # increment visits for samples by one.\n",
    "        self.visits[self.indices] += 1\n",
    "        # update losses\n",
    "        self.losses[self.indices] = self.epoch_losses\n",
    "        self.num_epochs += 1\n",
    "\n",
    "        # normalize\n",
    "#         log_ages = np.log(self.ages)\n",
    "        norm_ages = self.ages / np.sum(self.ages)\n",
    "        \n",
    "        non_visits = self.num_epochs - self.visits\n",
    "        norm_visits = non_visits / np.sum(non_visits)\n",
    "\n",
    "        norm_losses = self.losses / np.sum(self.losses)\n",
    "\n",
    "        weights = norm_ages + norm_visits + norm_losses\n",
    "#         weights = log_ages * (np.sum(self.losses) / np.sum(log_ages)) + self.losses\n",
    "\n",
    "#         norm_weights = weights / np.sum(weights)\n",
    "#         self.indices = np.random.choice(self.num_records, self.num_samples, replace=False, p=self.norm_weights)\n",
    "        self.indices = np.argsort(weights)[::-1][:self.num_samples]\n",
    "        np.random.shuffle(self.indices)\n",
    "        \n",
    "        self.sampler = SubsetSampler(self.indices)\n",
    "        self.num_steps = 0\n",
    "        self.epoch_losses *= -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (6, 256, 256)\n",
    "conv_layers = (16, 32, 64, 128, 256)\n",
    "fc_layers = (128,)\n",
    "output_size = 1\n",
    "\n",
    "model_basename = 'dup_model'\n",
    "date_time = get_datetime_now()\n",
    "\n",
    "# Parameters\n",
    "trainval_split = 0.9\n",
    "sample_rate = 0.05\n",
    "batch_size = 256\n",
    "max_epochs = 200\n",
    "num_workers = 18\n",
    "learning_rate = 0.0001\n",
    "best_loss = 9999.0\n",
    "max_datapoints = 200*2**15\n",
    "# lr_step_size = int(10 / sample_rate)\n",
    "# lr_gamma = 0.1\n",
    "print(max_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(full_dataset)\n",
    "trainval_dataset = full_dataset[:max_datapoints] if max_datapoints < len(full_dataset) else full_dataset\n",
    "print(len(trainval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_valid = even_split(len(trainval_dataset), batch_size, trainval_split)\n",
    "partition = {'train': trainval_dataset[:n_train], 'valid': trainval_dataset[-n_valid:]}\n",
    "n_samples = batch_size * (int(round(n_train * sample_rate)) // batch_size)\n",
    "print(n_train, n_valid, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['img_id'] = pd.Series(partition['train'])\n",
    "df.to_csv(os.path.join('models', f'{model_basename}.{date_time}.avl.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ImportanceSampler(n_train, n_samples, batch_size)\n",
    "\n",
    "loader_params = {\n",
    "    'train': {'batch_sampler': sampler, 'num_workers': num_workers},\n",
    "#     'train': {'batch_size': batch_size, 'shuffle': True, 'num_workers': num_workers},\n",
    "    'valid': {'batch_size': batch_size, 'shuffle': False, 'num_workers': num_workers}}\n",
    "\n",
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        RandomTransformC4(with_identity=False),\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        RandomHorizontalFlip(p=1),\n",
    "        transforms.ToTensor(),\n",
    "#         RandomTransformC4(with_identity=False),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: Dataset(partition[x], x, image_transforms[x]) for x in ['train', 'valid']}\n",
    "\n",
    "# Generators\n",
    "generators = {x: data.DataLoader(image_datasets[x], **loader_params[x]) for x in ['train', 'valid']}\n",
    "print(len(generators['train']), len(generators['valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DupCNN(input_shape, output_size, conv_layers, fc_layers)\n",
    "model.cuda()\n",
    "model.to(device)\n",
    "\n",
    "# loss = torch.nn.MSELoss()\n",
    "loss = torch.nn.BCELoss()\n",
    "# loss = torch.nn.BCEWithLogitsLoss()\n",
    "sample_loss = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENDTOMODULE\n",
    "class ReduceLROnPlateau2(ReduceLROnPlateau):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ReduceLROnPlateau2, self).__init__(*args, **kwargs)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return [pg['lr'] for pg in self.optimizer.param_groups]\n",
    "\n",
    "# scheduler = StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n",
    "scheduler = ReduceLROnPlateau2(optimizer, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"epoch\", \"time\", \"lr\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"train_time\", \"val_time\"]\n",
    "Stats = namedtuple('Stats', header)\n",
    "csv_filename = os.path.join('models', f'{model_basename}.{date_time}.metrics.csv')\n",
    "\n",
    "logger = CSVLogger(csv_filename, header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Training\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc = 0\n",
    "    model.train()\n",
    "    t = tnrange(len(generators['train']))\n",
    "    train_iterator = iter(generators['train'])\n",
    "    for i in t:\n",
    "        t.set_description(f'Epoch {epoch + 1:>02d}')\n",
    "        # Get next batch and push to GPU\n",
    "        inputs, labels = train_iterator.next()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        train_loss = loss(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Print statistics\n",
    "        sampler.update(sample_loss(outputs, labels).data.cpu().numpy())\n",
    "        total_train_loss += train_loss.data.item()\n",
    "        y_pred = outputs > 0.5\n",
    "        y_pred = y_pred.type_as(torch.cuda.FloatTensor())\n",
    "        equality = labels == y_pred\n",
    "        total_train_acc += equality.type_as(torch.FloatTensor()).numpy().mean()\n",
    "        \n",
    "        loss_str = f'{total_train_loss/(i + 1):.6f}'\n",
    "        acc_str = f'{total_train_acc/(i + 1):.5f}'\n",
    "        t.set_postfix(loss=loss_str, acc=acc_str)\n",
    "    \n",
    "    train_loss = total_train_loss/(i + 1)\n",
    "    train_acc = total_train_acc/(i + 1)\n",
    "    train_time = time.time() - t0\n",
    "    \n",
    "    # Validation\n",
    "    t1 = time.time()\n",
    "    total_val_loss = 0\n",
    "    total_val_acc = 0\n",
    "    t = tnrange(len(generators['valid']))\n",
    "    valid_iterator = iter(generators['valid'])\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i in t:\n",
    "            t.set_description(f'Validation')\n",
    "            # Get next batch and push to GPU\n",
    "            inputs, labels = valid_iterator.next()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            #Forward pass\n",
    "            val_outputs = model(inputs)\n",
    "            val_loss = loss(val_outputs, labels)\n",
    "            \n",
    "            total_val_loss += val_loss.data.item()\n",
    "            y_pred = val_outputs > 0.5\n",
    "            y_pred = y_pred.type_as(torch.cuda.FloatTensor())\n",
    "            equality = labels == y_pred\n",
    "            total_val_acc += equality.type_as(torch.FloatTensor()).numpy().mean()\n",
    "        \n",
    "            loss_str = f'{total_val_loss/(i + 1):.6f}'\n",
    "            acc_str = f'{total_val_acc/(i + 1):.5f}'\n",
    "            t.set_postfix(loss=loss_str, acc=acc_str)\n",
    "\n",
    "    val_loss = total_val_loss/(i + 1)\n",
    "    val_acc = total_val_acc/(i + 1)\n",
    "    val_time = time.time() - t1\n",
    "    \n",
    "    sampler.on_epoch_end()\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['ages'] = pd.Series(sampler.ages)\n",
    "    df['visits'] = pd.Series(sampler.visits)\n",
    "    df['losses'] = pd.Series(sampler.losses)\n",
    "    df.to_csv(os.path.join('models', f'{model_basename}.{date_time}.{epoch + 1:02d}.{val_loss:.6f}.avl.csv'), index=False)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        save_checkpoint(os.path.join('models', f'{model_basename}.{date_time}.{epoch + 1:02d}.{val_loss:.6f}.pth'), model)\n",
    "        save_checkpoint(os.path.join('models', f'{model_basename}.{date_time}.best.pth'), model)\n",
    "        save_checkpoint(os.path.join('models', f'{model_basename}.best.pth'), model)\n",
    "        best_loss = val_loss\n",
    "    \n",
    "    stats = Stats(epoch+1, total_time, scheduler.get_lr()[0], train_loss, train_acc, val_loss, val_acc, train_time, val_time)\n",
    "    logger.on_epoch_end(stats)\n",
    "    \n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immediate post-processing section here in case we want to look at model before shutting down notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sdcdup.utils import fuzzy_diff\n",
    "from sdcdup.utils import fuzzy_join\n",
    "from sdcdup.utils import get_hamming_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = Counter(sampler.visits)\n",
    "\n",
    "np.min(sampler.losses), np.max(sampler.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ages = sampler.ages / np.sum(sampler.ages)\n",
    "norm_losses = sampler.losses / np.sum(sampler.losses)\n",
    "log_ages = np.log(sampler.ages)\n",
    "scaled_ages = log_ages * (np.sum(sampler.losses) / np.sum(log_ages))\n",
    "weights = scaled_ages + sampler.losses\n",
    "norm_weights = weights / np.sum(weights)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['ages'] = pd.Series(sampler.ages, dtype=int)\n",
    "df['visits'] = pd.Series(sampler.visits, dtype=int)\n",
    "df['losses'] = pd.Series(sampler.losses)\n",
    "df['norm_ages'] = pd.Series(norm_ages)\n",
    "df['norm_losses'] = pd.Series(norm_losses)\n",
    "df['log_ages'] = pd.Series(log_ages)\n",
    "df['scaled_ages'] = pd.Series(scaled_ages)\n",
    "df['weights'] = pd.Series(weights)\n",
    "df['norm_weights'] = pd.Series(norm_weights)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['losses', 'scaled_ages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_loss_indices = np.where(sampler.losses > 0.16)[0]\n",
    "sampler.losses[bad_loss_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_overlaps = []\n",
    "for i in np.where(sampler.losses > 0.16)[0]:\n",
    "    bad_overlaps.append(partition['train'][i])\n",
    "len(bad_overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in bad_loss_indices:\n",
    "    bol = partition['train'][i]\n",
    "    \n",
    "    bmh1 = sdcic.tile_bm0hash_grids[bol[0]][bol[2]]\n",
    "    bmh2 = sdcic.tile_bm0hash_grids[bol[1]][bol[3]]\n",
    "    score = get_hamming_distance(bmh1, bmh2, as_score=True)\n",
    "\n",
    "    tile1 = sdcic.get_tile(sdcic.get_img(bol[0]), bol[2])\n",
    "    tile2 = sdcic.get_tile(sdcic.get_img(bol[1]), bol[3])\n",
    "    tile3 = fuzzy_join(tile1, tile2)\n",
    "    pix3, cts3 = np.unique(tile3.flatten(), return_counts=True)\n",
    "\n",
    "    print(bol, f'{np.max(cts3 / (256*256*3)):>.4f}', f'{sampler.losses[i]:>.6f}', np.sum(tile1 != tile2), fuzzy_diff(tile1, tile2))\n",
    "    for chan in range(3):\n",
    "        pix1, cts1 = np.unique(tile1[:, :, chan].flatten(), return_counts=True)\n",
    "        pix2, cts2 = np.unique(tile2[:, :, chan].flatten(), return_counts=True)\n",
    "        pix3, cts3 = np.unique(tile3[:, :, chan].flatten(), return_counts=True)\n",
    "\n",
    "        max_idx1 = np.argmax(cts1)\n",
    "        max_pix1 = pix1[max_idx1]\n",
    "        max_cts1 = cts1[max_idx1]\n",
    "#         print(f'{max_pix1:>3}', max_cts1, f'{max_cts1/65536:.4f}')\n",
    "        max_idx2 = np.argmax(cts2)\n",
    "        max_pix2 = pix2[max_idx2]\n",
    "        max_cts2 = cts2[max_idx2]\n",
    "#         print(f'{max_pix2:>3}', max_cts2, f'{max_cts2/65536:.4f}')\n",
    "        max_idx3 = np.argmax(cts3)\n",
    "        max_pix3 = pix3[max_idx3]\n",
    "        max_cts3 = cts3[max_idx3]\n",
    "#         print(f'{max_pix3:>3}', max_cts3, f'{max_cts3/65536:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0\n",
    "for bol in sorted(full_dataset):\n",
    "    bmh1 = sdcic.tile_bm0hash_grids[bol[0]][bol[2]]\n",
    "    bmh2 = sdcic.tile_bm0hash_grids[bol[1]][bol[3]]\n",
    "    score = get_hamming_distance(bmh1, bmh2, as_score=True)\n",
    "\n",
    "    if not (score == 256 and bol[4] == 0):\n",
    "        continue\n",
    "        \n",
    "    tile1 = sdcic.get_tile(sdcic.get_img(bol[0]), bol[2])\n",
    "    tile2 = sdcic.get_tile(sdcic.get_img(bol[1]), bol[3])\n",
    "    tile3 = fuzzy_join(tile1, tile2)\n",
    "    pix3, cts3 = np.unique(tile3.flatten(), return_counts=True)\n",
    "    \n",
    "    if np.max(cts3 / (256*256*3)) > 0.97:\n",
    "        ii += 1\n",
    "        print(ii, bol, f'{np.max(cts3 / (256*256*3)):>.4f}', np.sum(tile1 != tile2), fuzzy_diff(tile1, tile2))\n",
    "    \n",
    "    continue\n",
    "    \n",
    "    for chan in range(3):\n",
    "        pix1, cts1 = np.unique(tile1[:, :, chan].flatten(), return_counts=True)\n",
    "        pix2, cts2 = np.unique(tile2[:, :, chan].flatten(), return_counts=True)\n",
    "        pix3, cts3 = np.unique(tile3[:, :, chan].flatten(), return_counts=True)\n",
    "\n",
    "        max_idx1 = np.argmax(cts1)\n",
    "        max_idx2 = np.argmax(cts2)\n",
    "        max_idx3 = np.argmax(cts3)\n",
    "\n",
    "        max_pix1 = pix1[max_idx1]\n",
    "        max_pix2 = pix2[max_idx2]\n",
    "        max_pix3 = pix3[max_idx3]\n",
    "        \n",
    "        max_cts1 = cts1[max_idx1]\n",
    "        max_cts2 = cts2[max_idx2]\n",
    "        max_cts3 = cts3[max_idx3]\n",
    "        \n",
    "        if min([max_cts1, max_cts2, max_cts3])/65536 >= 0.95:\n",
    "            continue\n",
    "        \n",
    "        ii += 1\n",
    "        print(ii, bol)\n",
    "        print(f'{max_pix1:>3}', max_cts1, f'{max_cts1/65536:.4f}')\n",
    "        print(f'{max_pix2:>3}', max_cts2, f'{max_cts2/65536:.4f}')\n",
    "        print(f'{max_pix3:>3}', max_cts3, f'{max_cts3/65536:.4f}')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
