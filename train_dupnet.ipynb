{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "from tqdm import tnrange\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from utils import channel_shift\n",
    "from utils import to_hls\n",
    "from utils import to_bgr\n",
    "from utils import read_duplicate_truth\n",
    "from utils import read_image_duplicate_tiles\n",
    "from utils import even_split\n",
    "from utils import create_dataset_from_tiles_and_truth\n",
    "from dupnet import create_loss_and_optimizer\n",
    "from dupnet import save_checkpoint\n",
    "from dupnet import DupCNN\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ship_dir = \"data/input/\"\n",
    "train_768_dir = os.path.join(\"data\", \"train_768\")\n",
    "train_256_dir = os.path.join(ship_dir, \"train_256\")\n",
    "image_duplicate_tiles_file = os.path.join(\"data\", \"image_duplicate_tiles.txt\")\n",
    "duplicate_truth_file = os.path.join(\"data\", \"duplicate_truth.txt\")\n",
    "os.makedirs(train_256_dir, exist_ok=True)\n",
    "\n",
    "img_ids = os.listdir(train_768_dir)\n",
    "len(img_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_large(img, ij):\n",
    "    i, j = ij_pairs[ij]\n",
    "    tile = img[i * 256:(i + 1) * 256, j * 256:(j + 1) * 256, :]\n",
    "    tile = cv2.cvtColor(tile, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    return tile\n",
    "\n",
    "def read_from_small(img_id, ij):\n",
    "    filebase, fileext = img_id.split('.')\n",
    "    tile_id = f'{filebase}_{ij}.{fileext}'\n",
    "    tile = cv2.imread(os.path.join(train_256_dir, tile_id))\n",
    "    tile = cv2.cvtColor(tile, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    return tile\n",
    "\n",
    "def from_large(img_id, ij, kl):\n",
    "    img = cv2.imread(os.path.join(train_768_dir, img_id))\n",
    "    tile1 = read_from_large(img, ij)\n",
    "    tile2 = read_from_large(img, kl)\n",
    "    return np.dstack([tile1, tile2])\n",
    "\n",
    "def from_small(img_id, ij, kl):\n",
    "    tile1 = read_from_small(img_id, ij)\n",
    "    tile2 = read_from_small(img_id, kl)\n",
    "    return np.dstack([tile1, tile2])\n",
    "\n",
    "def from_both(img_id, ij, kl):\n",
    "    img = cv2.imread(os.path.join(train_768_dir, img_id))\n",
    "    tile1 = read_from_large(img, ij)\n",
    "    tile2 = read_from_small(img_id, kl)\n",
    "    return np.dstack([tile1, tile2])\n",
    "\n",
    "n_steps = 500\n",
    "\n",
    "ij_pairs = ((0, 0), (0, 1), (0, 2),\n",
    "            (1, 0), (1, 1), (1, 2),\n",
    "            (2, 0), (2, 1), (2, 2))\n",
    "ijkl = []\n",
    "for i in range(n_steps):\n",
    "    ij, kl = np.random.choice(len(ij_pairs), 2, replace=False)\n",
    "    ijkl.append((ij, kl))\n",
    "\n",
    "img_id_list = np.random.choice(img_ids, n_steps)\n",
    "t0 = time.time()\n",
    "for (ij, kl), img_id in zip(ijkl, img_id_list):\n",
    "    _ = from_large(img_id, ij, kl)\n",
    "print('from_large:', time.time() - t0)\n",
    "\n",
    "img_id_list = np.random.choice(img_ids, n_steps)\n",
    "t0 = time.time()\n",
    "for (ij, kl), img_id in zip(ijkl, img_id_list):\n",
    "    _ = from_small(img_id, ij, kl)\n",
    "print('from_small:', time.time() - t0)\n",
    "\n",
    "img_id_list = np.random.choice(img_ids, n_steps)\n",
    "t0 = time.time()\n",
    "for (ij, kl), img_id in zip(ijkl, img_id_list):\n",
    "    _ = from_both(img_id, ij, kl)\n",
    "print('from_both: ', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomHorizontalFlip:\n",
    "    \"\"\"Horizontally flip the given numpy array randomly with a given probability.\n",
    "\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Image): Image to be flipped.\n",
    "\n",
    "        Returns:\n",
    "            Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if np.random.random() < self.p:\n",
    "            return cv2.flip(img, 1)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "\n",
    "\n",
    "class RandomTransformC4:\n",
    "    \"\"\"Rotate a n-D tensor by 90 degrees in the H x W plane.\n",
    "\n",
    "    Args:\n",
    "        with_identity (bool): whether or not to include 0 degrees as a probable rotation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, with_identity=True):\n",
    "        self.with_identity = with_identity\n",
    "        self.n90s = (0, 1, 2, 3) if self.with_identity else (1, 2, 3)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Image): Image to be rotated.\n",
    "\n",
    "        Returns:\n",
    "            Image: Randomly rotated image but in 90 degree increments.\n",
    "        \"\"\"\n",
    "        k = random.choice(self.n90s)\n",
    "        return torch.rot90(img, k, (1, 2))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(with_identity={})'.format(self.with_identity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# dup_tiles = read_image_duplicate_tiles(image_duplicate_tiles_file)\n",
    "\n",
    "idx_chan_map = {0: 'H', 1: 'L', 2: 'S'}\n",
    "\n",
    "ImgAugs = namedtuple('ImgAugs', 'idx1 idx2 idx3 is_dup chan gain')\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, img_overlaps, train_768_dir, train_256_dir, \n",
    "                 in_shape=(6, 256, 256), \n",
    "                 out_shape=(1,), \n",
    "                 valid=False):\n",
    "        \n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.img_overlaps = img_overlaps\n",
    "        self.train_768_dir = train_768_dir\n",
    "        self.train_256_dir = train_256_dir\n",
    "        self.ij = ((0, 0), (0, 1), (0, 2),\n",
    "                   (1, 0), (1, 1), (1, 2),\n",
    "                   (2, 0), (2, 1), (2, 2))\n",
    "        \n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        self.hls_limits = {'H': 5, 'L': 10, 'S': 10}\n",
    "        \n",
    "        self.valid = valid\n",
    "        if self.valid:\n",
    "            self.img_augs = {}\n",
    "            for img_overlap in self.img_overlaps:\n",
    "                self.img_augs[img_overlap] = self.get_random_mapping(img_overlap)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return len(self.img_overlaps)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates one sample of data\"\"\"\n",
    "        img_overlap = self.img_overlaps[index]\n",
    "        if self.valid:\n",
    "            img_aug = self.img_augs[img_overlap]\n",
    "        else:\n",
    "            img_aug = self.get_random_mapping(img_overlap)\n",
    "        X, y = self.get_data_pair(img_overlap, img_aug)\n",
    "        return X, y\n",
    "    \n",
    "    def get_random_mapping(self, img_overlap):\n",
    "        \n",
    "        img1_id, img2_id, img1_overlap_tag = img_overlap\n",
    "        # get a list of 2-tuples for the indices of the overlapping tiles.\n",
    "        # e.g. [(1, 0), (2, 1), (4, 3), (5, 4), (7, 6), (8, 7)]\n",
    "        overlap_index_pairs = img_overlap_index_maps[img_overlap]\n",
    "        # get a random index into the pairs list. e.g. 3\n",
    "        overlap_index = np.random.choice(len(overlap_index_pairs))\n",
    "        # now use the overlap_index to retreive the actual values from the index pairs. e.g. (5, 4)\n",
    "        idx1, idx2 = overlap_index_pairs[overlap_index]\n",
    "\n",
    "        is_dup = 1 if img1_id != img2_id else (np.random.random() > 0.5) * 1\n",
    "        if not is_dup:\n",
    "            temp = np.random.choice(len(self.ij), 2, replace=False) # grab 2 in case we randomly pick up kl again.\n",
    "            idx2 = temp[0] if idx2 != temp[0] else temp[1]\n",
    "            \n",
    "        idx3 = np.random.choice(4, p=[0.4, 0.1, 0.1, 0.4])\n",
    "        \n",
    "        hls_idx = np.random.choice(3)\n",
    "        hls_chan = idx_chan_map[hls_idx]\n",
    "        hls_gain = np.random.choice(self.hls_limits[hls_chan]) + 1\n",
    "        hls_gain = hls_gain if np.random.random() > 0.5 else -1 * hls_gain\n",
    "        \n",
    "        return ImgAugs(idx1, idx2, idx3, is_dup, hls_chan, hls_gain)\n",
    "    \n",
    "    def color_shift(self, img, chan, gain):\n",
    "        hls = to_hls(img)\n",
    "        hls_shifted = channel_shift(hls, chan, gain)\n",
    "        return to_bgr(hls_shifted)\n",
    "    \n",
    "    def get_tile(self, img, ij, sz=256):\n",
    "        i, j = self.ij[ij]\n",
    "        return img[i * sz:(i + 1) * sz, j * sz:(j + 1) * sz, :]\n",
    "    \n",
    "    def read_from_large(self, img_id, ij):\n",
    "        img = cv2.imread(os.path.join(self.train_768_dir, img_id))\n",
    "        return self.get_tile(img, ij)\n",
    "    \n",
    "    def read_from_small(self, img_id, ij):\n",
    "        filebase, fileext = img_id.split('.')\n",
    "        tile_id = f'{filebase}_{ij}.{fileext}'\n",
    "        return cv2.imread(os.path.join(self.train_256_dir, tile_id))\n",
    "    \n",
    "    def get_data_pair(self, img_overlap, img_aug):\n",
    "\n",
    "        # diff img_id (img1_id != img2_id), random tile from overlap, where is_dup == 1 (from duplicate_truth.txt)\n",
    "            # img1_[i,j], img2_[k,l], 1, exact or fuzzy\n",
    "            # img1_[i,j], tile2_kl, 1, exact or fuzzy\n",
    "            # tile1_ij, img2_[k,l], 1, exact or fuzzy\n",
    "            # tile1_ij, tile2_kl, 1, exact or fuzzy\n",
    "        \n",
    "        # same img_id (img1_id == img2_id), same tile (ij == kl)\n",
    "            # img1_[i,j], img1_[i,j], 1, exact\n",
    "            # img1_[i,j], tile1_ij, 1, fuzzy\n",
    "            # tile1_ij, img1_[i,j], 1, fuzzy\n",
    "            # tile1_ij, tile1_ij, 1, exact\n",
    "            \n",
    "        # same img_id (img1_id == img2_id), diff tile (ij != kl)\n",
    "            # img1_[i,j], img1_[k,l], 0, similar but different\n",
    "            # img1_[i,j], tile1_kl, 0, similar but different\n",
    "            # tile1_ij, img1_[k,l], 0, similar but different\n",
    "            # tile1_ij, tile1_kl, 0, similar but different\n",
    "            \n",
    "        # diff img_id (img1_id != img2_id), same tile (ij == kl)\n",
    "            # img1_[i,j], img2_[i,j], 0, very different\n",
    "            # img1_[i,j], tile2_ij, 0, very different\n",
    "            # tile1_ij, img2_[i,j], 0, very different\n",
    "            # tile1_ij, tile2_ij, 0, very different\n",
    "            \n",
    "        # diff img_id (img1_id != img2_id), diff tile (ij != kl)\n",
    "            # img1_[i,j], img2_[k,l], 0, very different\n",
    "            # img1_[i,j], tile2_kl, 0, very different\n",
    "            # tile1_ij, img2_[k,l], 0, very different\n",
    "            # tile1_ij, tile2_kl, 0, very different\n",
    "        \n",
    "        # use image_duplicate_tiles.txt for equal image id pairs (img1_id == img2_id)\n",
    "        #--------------------------------------------------------------------\n",
    "        # ij == kl? | tile1? | tile2? | shift? | is_dup?\n",
    "        #--------------------------------------------------------------------\n",
    "        #   yes     |  768   |  768   |   yes  |    yes agro color shift \n",
    "        #   yes     |  768   |  768   |    no  |    yes\n",
    "        #   yes     |  768   |  256   |    no  |    yes \n",
    "        #   yes     |  256   |  768   |    no  |    yes \n",
    "        #   yes     |  256   |  256   |   yes  |    yes agro color shift \n",
    "        #   yes     |  256   |  256   |    no  |    yes \n",
    "        #    no     |  768   |  768   |   yes  |     no \n",
    "        #    no     |  768   |  768   |    no  |     no \n",
    "        #    no     |  256   |  256   |   yes  |     no \n",
    "        #    no     |  256   |  256   |    no  |     no \n",
    "        \n",
    "        # use duplicate_truth.txt for unequal image id pairs (img1_id != img2_id)\n",
    "        # NOTE: Be sure to use the overlap_map when comparing ij and kl\n",
    "        #--------------------------------------------------------------------\n",
    "        # ij == kl? | tile1? | tile2? | shift? | is_dup?\n",
    "        #--------------------------------------------------------------------\n",
    "        #   yes     |  768   |  768   |   yes  |    yes small color shift \n",
    "        #   yes     |  768   |  768   |    no  |    yes\n",
    "        #   yes     |  768   |  256   |    no  |    yes\n",
    "        #   yes     |  256   |  768   |    no  |    yes\n",
    "        #   yes     |  256   |  256   |   yes  |    yes\n",
    "        #   yes     |  256   |  256   |    no  |    yes\n",
    "        #    no     |  768   |  768   |   yes  |     no\n",
    "        #    no     |  768   |  768   |    no  |     no\n",
    "        #    no     |  256   |  256   |   yes  |     no \n",
    "        #    no     |  256   |  256   |    no  |     no\n",
    "\n",
    "        img1_id, img2_id, img1_overlap_tag = img_overlap\n",
    "        idx1, idx2, idx3, is_dup, chan, gain = img_aug\n",
    "\n",
    "        if img1_id == img2_id:\n",
    "            if is_dup:  # ij == kl\n",
    "                if idx3 == 0:\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.color_shift(tile1, chan, gain)\n",
    "                elif idx3 == 1:\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                elif idx3 == 2:\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_large(img2_id, idx2)\n",
    "                elif idx3 == 3:\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.color_shift(tile1, chan, gain)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            else:  # ij != kl\n",
    "                # These 4 have pretty much the same effect.\n",
    "                # The last one (2 256x256 tiles vs 1 768x768 tile) is the fastest.\n",
    "                # idx3 = np.random.choice(4, p=[0.1, 0.1, 0.1, 1.7])\n",
    "                # idx3 = 3\n",
    "                if idx3 == 0: # fast\n",
    "                    img = cv2.imread(os.path.join(self.train_768_dir, img1_id))\n",
    "                    tile1 = self.get_tile(img, idx1)\n",
    "                    tile2 = self.get_tile(img, idx2)\n",
    "                elif idx3 == 1: # slowest\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                elif idx3 == 2: # slowest\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_large(img2_id, idx2)\n",
    "                elif idx3 == 3: # fastest\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "        else: # img1_id != img2_id\n",
    "            if is_dup:  # ij == kl\n",
    "                if idx3 == 0: # slowest\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.read_from_large(img2_id, idx2)\n",
    "                elif idx3 == 1: # slow\n",
    "                    tile1 = self.read_from_large(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                elif idx3 == 2: # slow\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_large(img2_id, idx2)\n",
    "                elif idx3 == 3: # fast\n",
    "                    tile1 = self.read_from_small(img1_id, idx1)\n",
    "                    tile2 = self.read_from_small(img2_id, idx2)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            else:  # ij != kl\n",
    "                tile1 = self.read_from_large(img1_id, idx1)\n",
    "                tile2 = self.read_from_large(img2_id, idx2)\n",
    "#                 if idx3 == 0: # slowest\n",
    "#                     tile1 = self.read_from_large(img1_id, i, j)\n",
    "#                     tile2 = self.read_from_large(img2_id, k, l)\n",
    "#                 elif idx3 == 1: # slow\n",
    "#                     tile1 = self.read_from_large(img1_id, i, j)\n",
    "#                     tile2 = self.read_from_small(img2_id, k, l)\n",
    "#                 elif idx3 == 2: # slow\n",
    "#                     tile1 = self.read_from_small(img1_id, i, j)\n",
    "#                     tile2 = self.read_from_large(img2_id, k, l)\n",
    "#                 elif idx3 == 3: # fast\n",
    "#                     tile1 = self.read_from_small(img1_id, i, j)\n",
    "#                     tile2 = self.read_from_small(img2_id, k, l)\n",
    "#                 else:\n",
    "#                     raise ValueError\n",
    "\n",
    "        if is_dup == 0 and np.all(tile1 == tile2):\n",
    "            i, j = self.ij[idx1]\n",
    "            k, l = self.ij[idx2]\n",
    "            print(f'algo={idx3}; {img1_id} {idx1} -> ({i},{j}); {img2_id}, {idx2} -> ({k},{l}); {img1_overlap_tag}; correcting... {is_dup} -> 1')\n",
    "            is_dup = 1\n",
    "            \n",
    "        tile1 = cv2.cvtColor(tile1, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        tile2 = cv2.cvtColor(tile2, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        \n",
    "        X = np.dstack([tile1, tile2])\n",
    "        X = X.transpose((2, 0, 1))\n",
    "        y = np.array([is_dup], dtype=np.float32)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "input_shape = (6, 256, 256)\n",
    "conv_layers = (16, 32, 64, 128, 256)\n",
    "fc_layers = (128,)\n",
    "output_size = 1\n",
    "\n",
    "# Parameters\n",
    "split = 80\n",
    "batch_size = 256\n",
    "max_epochs = 30\n",
    "num_workers = 12\n",
    "learning_rate = 0.0001\n",
    "\n",
    "train_params = {'batch_size': batch_size,\n",
    "                'shuffle': True,\n",
    "                'num_workers': num_workers}\n",
    "\n",
    "valid_params = {'batch_size': batch_size,\n",
    "                'shuffle': False,\n",
    "                'num_workers': num_workers}\n",
    "\n",
    "# Datasets\n",
    "dup_tiles = read_image_duplicate_tiles(image_duplicate_tiles_file)\n",
    "dup_truth = read_duplicate_truth(duplicate_truth_file)\n",
    "img_overlap_index_maps = create_dataset_from_tiles_and_truth(dup_tiles, dup_truth)\n",
    "img_overlap_index_keys = list(img_overlap_index_maps)\n",
    "np.random.shuffle(img_overlap_index_keys)\n",
    "n_train, n_valid = even_split(len(img_overlap_index_keys), batch_size, split)\n",
    "partition = {'train': img_overlap_index_keys[:n_train], 'valid': img_overlap_index_keys[-n_valid:]}\n",
    "print(n_train, n_valid)\n",
    "\n",
    "\n",
    "# Generators\n",
    "train_set = Dataset(partition['train'], train_768_dir, train_256_dir)\n",
    "train_generator = data.DataLoader(train_set, **train_params)\n",
    "\n",
    "valid_set = Dataset(partition['valid'], train_768_dir, train_256_dir, valid=True)\n",
    "valid_generator = data.DataLoader(valid_set, **valid_params)\n",
    "print(len(train_generator), len(valid_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = DupCNN(input_shape, output_size, conv_layers, fc_layers)\n",
    "model.cuda()\n",
    "\n",
    "loss, optimizer = create_loss_and_optimizer(model, learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.05)\n",
    "\n",
    "n_batches = len(train_generator)\n",
    "best_loss = 9999.0\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Training\n",
    "    total_train_loss = 0\n",
    "    total_train_acc = 0\n",
    "    model.train()\n",
    "    t = tnrange(len(train_generator))\n",
    "    train_iterator = iter(train_generator)\n",
    "    for i in t:\n",
    "        t.set_description(f'Epoch {epoch + 1:>3}')\n",
    "        inputs, labels = train_iterator.next()\n",
    "        # Transfer to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        #Set the parameter gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass, backward pass, optimize\n",
    "        outputs = model(inputs)\n",
    "        train_loss = loss(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        #Print statistics\n",
    "        total_train_loss += train_loss.data.item()\n",
    "        \n",
    "        y_pred = outputs > 0.5\n",
    "        y_pred = y_pred.type_as(torch.cuda.FloatTensor())\n",
    "        equality = labels == y_pred\n",
    "        total_train_acc += equality.type_as(torch.FloatTensor()).mean()\n",
    "        \n",
    "        loss_str = f'{total_train_loss/(i + 1):.6f}'\n",
    "        acc_str = f'{total_train_acc/(i + 1):.5f}'\n",
    "        t.set_postfix(loss=loss_str, acc=acc_str)\n",
    "    \n",
    "    # Validation\n",
    "    total_val_loss = 0\n",
    "    total_val_acc = 0\n",
    "    t = tnrange(len(valid_generator))\n",
    "    valid_iterator = iter(valid_generator)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i in t:\n",
    "            t.set_description(f'Validation')\n",
    "            inputs, labels = valid_iterator.next()\n",
    "            # Transfer to GPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            #Forward pass\n",
    "            val_outputs = model(inputs)\n",
    "            val_loss = loss(val_outputs, labels)\n",
    "            total_val_loss += val_loss.data.item()\n",
    "\n",
    "            y_pred = val_outputs > 0.5\n",
    "            y_pred = y_pred.type_as(torch.cuda.FloatTensor())\n",
    "            equality = labels == y_pred\n",
    "            total_val_acc += equality.type_as(torch.FloatTensor()).mean()\n",
    "        \n",
    "            loss_str = f'{total_val_loss/(i + 1):.6f}'\n",
    "            acc_str = f'{total_val_acc/(i + 1):.5f}'\n",
    "            t.set_postfix(loss=loss_str, acc=acc_str)\n",
    "\n",
    "        val_loss = total_val_loss/(i + 1)\n",
    "        if val_loss < best_loss:\n",
    "            save_checkpoint(os.path.join(\"out\", f\"dup_model.{epoch + 1:03d}-{val_loss:.6f}.pth\"), model)\n",
    "            save_checkpoint(os.path.join(\"out\", \"dup_model.last.pth\"), model)\n",
    "#             save_checkpoint(''.join(['out/checkpoint_', acc_str, '.pth']), model)\n",
    "            best_loss = val_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
